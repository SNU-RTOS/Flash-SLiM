Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

Number of nodes executed: 0
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called

Timings (microseconds): count=0
Memory (bytes): count=0
0 nodes observed


Operator-wise Profiling Info for Regular Benchmark Runs:
Primary graph (name: decode) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.004,0.00234375,0.000606742%,0.000606742%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;]:0
EMBEDDING_LOOKUP,0.006,6.502,1.68322%,1.68382%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
CAST,0.002,0.0015,0.000388315%,1.68421%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;]:3
LESS,0.002,0.0024375,0.000631012%,1.68484%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:8
ADD,0.002,0.0025625,0.000663371%,1.68551%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:9
SELECT,0.002,0.00115625,0.000299326%,1.6858%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:10
RESHAPE,0,0.00034375,8.89889e-05%,1.68589%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:11
CAST,0.001,0.00040625,0.000105169%,1.686%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:12
GREATER_EQUAL,0.001,0.0011875,0.000307416%,1.68631%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:13
LESS_EQUAL,0.002,0.00125,0.000323596%,1.68663%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;11]:14
LOGICAL_AND,0.001,0.00103125,0.000266967%,1.6869%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:15
REDUCE_ALL,0.004,0.0036875,0.000954608%,1.68785%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:16
GATHER_ND,0.002,0.0281875,0.00729709%,1.69515%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;14]:17
RESHAPE,0,0.000375,9.70787e-05%,1.69525%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;15]:18
SELECT_V2,0.003,0.00253125,0.000655282%,1.6959%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;16]:19
RESHAPE,0.001,0.0001875,4.85394e-05%,1.69595%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:54
PACK,0.003,0.00190625,0.000493484%,1.69644%,0,1,[tfl.pack]:55
Static Reshape (NC),0.023,0.140563,0.0363884%,1.73283%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0,0.000125,3.23596e-05%,1.73286%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.011,0.0625938,0.0162041%,1.74907%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0,0.00046875,0.000121348%,1.74919%,0,1,Delegate/Cosine (NC):3
Sine (NC),0,0.0001875,4.85394e-05%,1.74924%,0,1,Delegate/Sine (NC):4
Multiply (ND),0.012,0.05125,0.0132674%,1.76251%,0,1,Delegate/Multiply (ND):5
Sum (ND) Reduce,0.001,0.001125,0.000291236%,1.7628%,0,1,Delegate/Sum (ND) Reduce:6
Multiply (ND),0,0,0%,1.7628%,0,1,Delegate/Multiply (ND):7
Add (ND),0,0,0%,1.7628%,0,1,Delegate/Add (ND):8
Reciprocal Square Root (NC),0,3.125e-05,8.0899e-06%,1.7628%,0,1,Delegate/Reciprocal Square Root (NC):9
Multiply (ND),0.011,0.049,0.012685%,1.77549%,0,1,Delegate/Multiply (ND):10
Multiply (ND),0.007,0.032125,0.00831641%,1.78381%,0,1,Delegate/Multiply (ND):11
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.155,1.14034,0.295208%,2.07901%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
Static Reshape (NC),0.014,0.0019903,0.014942%,2.09396%,0,29,Delegate/Static Reshape (NC):13
"Slice (ND, X32)",0.011,0.0465313,0.0120459%,2.106%,0,1,Delegate/Slice (ND	 X32):14
"Slice (ND, X32)",0.01,0.02625,0.00679551%,2.1128%,0,1,Delegate/Slice (ND	 X32):15
"Slice (ND, X32)",0.025,0.0249375,0.00645574%,2.11925%,0,1,Delegate/Slice (ND	 X32):16
Static Reshape (NC),0.01,0.025375,0.006569%,2.12582%,0,1,Delegate/Static Reshape (NC):17
"Slice (ND, X32)",0.006,0.0173125,0.0044818%,2.1303%,0,1,Delegate/Slice (ND	 X32):18
"Slice (ND, X32)",0.009,0.0124375,0.00321978%,2.13352%,0,1,Delegate/Slice (ND	 X32):19
Multiply (ND),0.01,0.000653017,0.00490248%,2.13843%,0,29,Delegate/Multiply (ND):20
Multiply (ND),0.01,0.0123438,0.00319551%,2.14162%,0,1,Delegate/Multiply (ND):21
Subtract (ND),0.011,0.0124063,0.00321169%,2.14483%,0,1,Delegate/Subtract (ND):22
Multiply (ND),0.01,0.0113093,0.0849035%,2.22974%,0,29,Delegate/Multiply (ND):23
Multiply (ND),0.011,0.00795474,0.0597196%,2.28946%,0,29,Delegate/Multiply (ND):24
Add (ND),0.01,0.0115,0.00297708%,2.29243%,0,1,Delegate/Add (ND):25
"Copy (NC, X32)",0.02,0.0240313,0.00622113%,2.29865%,0,1,Delegate/Copy (NC	 X32):26
Static Reshape (NC),0.013,0.0118125,0.00305798%,2.30171%,0,1,Delegate/Static Reshape (NC):27
Static Reshape (NC),0,6.25e-05,1.61798e-05%,2.30173%,0,1,Delegate/Static Reshape (NC):28
"Slice (ND, X32)",0.01,0.0136562,0.00353528%,2.30526%,0,1,Delegate/Slice (ND	 X32):29
"Slice (ND, X32)",0.01,0.0114687,0.00296899%,2.30823%,0,1,Delegate/Slice (ND	 X32):30
Multiply (ND),0.01,0.0113437,0.00293663%,2.31117%,0,1,Delegate/Multiply (ND):31
Multiply (ND),0.01,0.0112091,0.0841511%,2.39532%,0,29,Delegate/Multiply (ND):32
Subtract (ND),0.01,0.011375,0.00294472%,2.39827%,0,1,Delegate/Subtract (ND):33
Multiply (ND),0.01,0.000424569,0.00318742%,2.40145%,0,29,Delegate/Multiply (ND):34
Multiply (ND),0.01,0.0113125,0.00292854%,2.40438%,0,1,Delegate/Multiply (ND):35
Add (ND),0.01,0.0180312,0.00466787%,2.40905%,0,1,Delegate/Add (ND):36
"Copy (NC, X32)",0.021,0.0274063,0.00709484%,2.41614%,0,1,Delegate/Copy (NC	 X32):37
Static Reshape (NC),0,6.25e-05,1.61798e-05%,2.41616%,0,1,Delegate/Static Reshape (NC):38
DYNAMIC_UPDATE_SLICE,0.003,0.0038125,0.000986967%,2.41715%,0,1,[StatefulPartitionedCall:0]:56
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000355955%,2.4175%,0,1,[StatefulPartitionedCall:28]:57
Multiply (ND),0.007,0.0100156,0.0725987%,2.4901%,0,28,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.001,0.000958705,0.00694922%,2.49705%,0,28,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",0.929,0.82807,6.00231%,8.49936%,0,28,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000184152,0.00133483%,8.50069%,0,28,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,4.46429e-06,3.23596e-05%,8.50072%,0,28,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",1.415,1.34396,9.74173%,18.2425%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0.001,7.8125e-05,0.000566293%,18.243%,0,28,Delegate/Static Reshape (NC):6
Add (ND),0.017,0.0214699,0.155625%,18.3986%,0,28,Delegate/Add (ND):7
"Softmax (NC, F32)",0.017,0.0205045,0.148628%,18.5473%,0,28,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.386,1.4311,10.3734%,28.9207%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0.001,0.000166295,0.00120539%,28.9219%,0,28,Delegate/Static Reshape (NC):10
Static Reshape (NC),0,6.69643e-06,4.85394e-05%,28.9219%,0,28,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",1.321,1.36406,9.88744%,38.8094%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Transpose (ND, X32) Transpose",0.002,0.00147768,0.010711%,38.8201%,0,28,Delegate/Transpose (ND	 X32) Transpose:14
Static Reshape (NC),0,1.11607e-06,8.0899e-06%,38.8201%,0,28,Delegate/Static Reshape (NC):15
"Fully Connected (NC, QD8, F32, QC8W) GEMM",0.673,0.688036,4.98726%,43.8073%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.018,0.0129375,0.0937781%,43.9011%,0,28,Delegate/Add (ND):17
Multiply (ND),0.013,0.00948326,0.0687398%,43.9699%,0,28,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.001,0.00108929,0.00789574%,43.9778%,0,28,Delegate/Sum (ND) Reduce:19
Add (ND),0,6.47321e-05,0.000469214%,43.9782%,0,28,Delegate/Add (ND):21
Reciprocal Square Root (NC),0,1.11607e-06,8.0899e-06%,43.9782%,0,28,Delegate/Reciprocal Square Root (NC):22
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.657,1.74226,12.6288%,56.6071%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
Sigmoid (NC),0.019,0.0166049,0.120361%,56.7274%,0,28,Delegate/Sigmoid (NC):26
Multiply (ND),0.008,0.00953237,0.0690958%,56.7965%,0,28,Delegate/Multiply (ND):27
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.651,1.6849,12.2131%,69.0096%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
Multiply (ND),0.019,0.0124799,0.0904612%,69.1001%,0,28,Delegate/Multiply (ND):29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.663,1.67939,12.1731%,81.2732%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
Add (ND),0.03,0.0146049,0.105864%,81.3791%,0,28,Delegate/Add (ND):31
Sum (ND) Reduce,0.001,0.00103013,0.00746697%,81.3865%,0,28,Delegate/Sum (ND) Reduce:33
Add (ND),0,3.34821e-06,2.42697e-05%,81.3866%,0,28,Delegate/Add (ND):35
Reciprocal Square Root (NC),0,4.46429e-06,3.23596e-05%,81.3866%,0,28,Delegate/Reciprocal Square Root (NC):36
Multiply (ND),0.012,0.0110379,0.0800091%,81.4666%,0,28,Delegate/Multiply (ND):37
Multiply (ND),0.007,0.00754687,0.0547039%,81.5213%,0,28,Delegate/Multiply (ND):38
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.029,2.29368,16.6258%,98.1471%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
Static Reshape (NC),0.016,0.0135174,0.0944819%,98.2416%,0,27,Delegate/Static Reshape (NC):40
"Slice (ND, X32)",0.012,0.0109074,0.0762392%,98.3179%,0,27,Delegate/Slice (ND	 X32):41
"Slice (ND, X32)",0.011,0.0102269,0.0714823%,98.3893%,0,27,Delegate/Slice (ND	 X32):42
"Slice (ND, X32)",0.014,0.00984606,0.0688207%,98.4582%,0,27,Delegate/Slice (ND	 X32):43
Static Reshape (NC),0.013,0.00998843,0.0698158%,98.528%,0,27,Delegate/Static Reshape (NC):44
"Slice (ND, X32)",0.011,0.00986921,0.0689825%,98.597%,0,27,Delegate/Slice (ND	 X32):45
"Slice (ND, X32)",0.011,0.00968519,0.0676962%,98.6646%,0,27,Delegate/Slice (ND	 X32):46
Multiply (ND),0.011,0.0100532,0.0702688%,98.7349%,0,27,Delegate/Multiply (ND):47
Multiply (ND),0.01,0.0099294,0.0694032%,98.8043%,0,27,Delegate/Multiply (ND):48
Subtract (ND),0.01,0.0100405,0.0701798%,98.8745%,0,27,Delegate/Subtract (ND):49
Multiply (ND),0.01,0.0099456,0.0695165%,98.944%,0,27,Delegate/Multiply (ND):50
Multiply (ND),0.01,0.00974421,0.0681088%,99.0121%,0,27,Delegate/Multiply (ND):51
Add (ND),0.01,0.00976157,0.0682302%,99.0804%,0,27,Delegate/Add (ND):52
"Copy (NC, X32)",0.02,0.0197419,0.137989%,99.2183%,0,27,Delegate/Copy (NC	 X32):53
Static Reshape (NC),0.011,0.00977199,0.068303%,99.2867%,0,27,Delegate/Static Reshape (NC):54
Static Reshape (NC),0,2.43056e-05,0.000169888%,99.2868%,0,27,Delegate/Static Reshape (NC):55
"Slice (ND, X32)",0.01,0.00975926,0.068214%,99.355%,0,27,Delegate/Slice (ND	 X32):56
"Slice (ND, X32)",0.01,0.00961458,0.0672028%,99.4222%,0,27,Delegate/Slice (ND	 X32):57
Multiply (ND),0.011,0.0096412,0.0673888%,99.4896%,0,27,Delegate/Multiply (ND):58
Multiply (ND),0.01,0.00960532,0.067138%,99.5568%,0,27,Delegate/Multiply (ND):59
Subtract (ND),0.01,0.00959954,0.0670976%,99.6239%,0,27,Delegate/Subtract (ND):60
Multiply (ND),0.011,0.00963657,0.0673565%,99.6912%,0,27,Delegate/Multiply (ND):61
Multiply (ND),0.011,0.0095463,0.0667255%,99.7579%,0,27,Delegate/Multiply (ND):62
Add (ND),0.01,0.00952199,0.0665556%,99.8245%,0,27,Delegate/Add (ND):63
"Copy (NC, X32)",0.021,0.0191644,0.133952%,99.9585%,0,27,Delegate/Copy (NC	 X32):64
Static Reshape (NC),0,1.96759e-05,0.000137528%,99.9586%,0,27,Delegate/Static Reshape (NC):65
DYNAMIC_UPDATE_SLICE,0.005,0.0046875,0.00121348%,99.9598%,0,1,[StatefulPartitionedCall:1]:110
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000339776%,99.9601%,0,1,[StatefulPartitionedCall:29]:111
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00118921%,99.9613%,0,1,[StatefulPartitionedCall:12]:164
DYNAMIC_UPDATE_SLICE,0.002,0.0014375,0.000372135%,99.9617%,0,1,[StatefulPartitionedCall:40]:165
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00118112%,99.9629%,0,1,[StatefulPartitionedCall:21]:218
DYNAMIC_UPDATE_SLICE,0.001,0.00125,0.000323596%,99.9632%,0,1,[StatefulPartitionedCall:49]:219
DYNAMIC_UPDATE_SLICE,0.005,0.00475,0.00122966%,99.9644%,0,1,[StatefulPartitionedCall:22]:272
DYNAMIC_UPDATE_SLICE,0.002,0.00140625,0.000364045%,99.9648%,0,1,[StatefulPartitionedCall:50]:273
DYNAMIC_UPDATE_SLICE,0.004,0.00453125,0.00117303%,99.966%,0,1,[StatefulPartitionedCall:23]:326
DYNAMIC_UPDATE_SLICE,0.002,0.00109375,0.000283146%,99.9663%,0,1,[StatefulPartitionedCall:51]:327
DYNAMIC_UPDATE_SLICE,0.005,0.00453125,0.00117303%,99.9674%,0,1,[StatefulPartitionedCall:24]:380
DYNAMIC_UPDATE_SLICE,0.002,0.0013125,0.000339776%,99.9678%,0,1,[StatefulPartitionedCall:52]:381
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00118112%,99.9689%,0,1,[StatefulPartitionedCall:25]:434
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000299326%,99.9692%,0,1,[StatefulPartitionedCall:53]:435
DYNAMIC_UPDATE_SLICE,0.005,0.004375,0.00113259%,99.9704%,0,1,[StatefulPartitionedCall:26]:488
DYNAMIC_UPDATE_SLICE,0.002,0.00125,0.000323596%,99.9707%,0,1,[StatefulPartitionedCall:54]:489
DYNAMIC_UPDATE_SLICE,0.004,0.00446875,0.00115686%,99.9719%,0,1,[StatefulPartitionedCall:27]:542
DYNAMIC_UPDATE_SLICE,0.001,0.001125,0.000291236%,99.9722%,0,1,[StatefulPartitionedCall:55]:543
DYNAMIC_UPDATE_SLICE,0.005,0.00446875,0.00115686%,99.9733%,0,1,[StatefulPartitionedCall:2]:596
DYNAMIC_UPDATE_SLICE,0.002,0.00146875,0.000380225%,99.9737%,0,1,[StatefulPartitionedCall:30]:597
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00118112%,99.9749%,0,1,[StatefulPartitionedCall:3]:650
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000299326%,99.9752%,0,1,[StatefulPartitionedCall:31]:651
DYNAMIC_UPDATE_SLICE,0.006,0.00465625,0.00120539%,99.9764%,0,1,[StatefulPartitionedCall:4]:704
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000315506%,99.9767%,0,1,[StatefulPartitionedCall:32]:705
DYNAMIC_UPDATE_SLICE,0.005,0.00453125,0.00117303%,99.9779%,0,1,[StatefulPartitionedCall:5]:758
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000299326%,99.9782%,0,1,[StatefulPartitionedCall:33]:759
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00118921%,99.9794%,0,1,[StatefulPartitionedCall:6]:812
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000355955%,99.9797%,0,1,[StatefulPartitionedCall:34]:813
DYNAMIC_UPDATE_SLICE,0.006,0.00459375,0.00118921%,99.9809%,0,1,[StatefulPartitionedCall:7]:866
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.000307416%,99.9812%,0,1,[StatefulPartitionedCall:35]:867
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00118921%,99.9824%,0,1,[StatefulPartitionedCall:8]:920
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000355955%,99.9827%,0,1,[StatefulPartitionedCall:36]:921
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00118921%,99.9839%,0,1,[StatefulPartitionedCall:9]:974
DYNAMIC_UPDATE_SLICE,0.002,0.0013125,0.000339776%,99.9843%,0,1,[StatefulPartitionedCall:37]:975
DYNAMIC_UPDATE_SLICE,0.005,0.00475,0.00122966%,99.9855%,0,1,[StatefulPartitionedCall:10]:1028
DYNAMIC_UPDATE_SLICE,0.001,0.00140625,0.000364045%,99.9859%,0,1,[StatefulPartitionedCall:38]:1029
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00120539%,99.9871%,0,1,[StatefulPartitionedCall:11]:1082
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000315506%,99.9874%,0,1,[StatefulPartitionedCall:39]:1083
DYNAMIC_UPDATE_SLICE,0.005,0.00471875,0.00122157%,99.9886%,0,1,[StatefulPartitionedCall:13]:1136
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000355955%,99.989%,0,1,[StatefulPartitionedCall:41]:1137
DYNAMIC_UPDATE_SLICE,0.006,0.0046875,0.00121348%,99.9902%,0,1,[StatefulPartitionedCall:14]:1190
DYNAMIC_UPDATE_SLICE,0.001,0.00140625,0.000364045%,99.9905%,0,1,[StatefulPartitionedCall:42]:1191
DYNAMIC_UPDATE_SLICE,0.004,0.0046875,0.00121348%,99.9918%,0,1,[StatefulPartitionedCall:15]:1244
DYNAMIC_UPDATE_SLICE,0.002,0.0015,0.000388315%,99.9922%,0,1,[StatefulPartitionedCall:43]:1245
DYNAMIC_UPDATE_SLICE,0.004,0.00459375,0.00118921%,99.9933%,0,1,[StatefulPartitionedCall:16]:1298
DYNAMIC_UPDATE_SLICE,0.001,0.00125,0.000323596%,99.9937%,0,1,[StatefulPartitionedCall:44]:1299
DYNAMIC_UPDATE_SLICE,0.005,0.004625,0.0011973%,99.9949%,0,1,[StatefulPartitionedCall:17]:1352
DYNAMIC_UPDATE_SLICE,0.001,0.00140625,0.000364045%,99.9952%,0,1,[StatefulPartitionedCall:45]:1353
DYNAMIC_UPDATE_SLICE,0.005,0.00478125,0.00123775%,99.9965%,0,1,[StatefulPartitionedCall:18]:1406
DYNAMIC_UPDATE_SLICE,0.001,0.00134375,0.000347866%,99.9968%,0,1,[StatefulPartitionedCall:46]:1407
DYNAMIC_UPDATE_SLICE,0.006,0.00475,0.00122966%,99.998%,0,1,[StatefulPartitionedCall:19]:1460
DYNAMIC_UPDATE_SLICE,0.001,0.0015625,0.000404495%,99.9985%,0,1,[StatefulPartitionedCall:47]:1461
DYNAMIC_UPDATE_SLICE,0.005,0.0046875,0.00121348%,99.9997%,0,1,[StatefulPartitionedCall:20]:1514
DYNAMIC_UPDATE_SLICE,0.002,0.0013125,0.000339776%,100%,0,1,[StatefulPartitionedCall:48]:1515

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
EMBEDDING_LOOKUP,0.006,6.502,1.68322%,1.68322%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.029,2.29368,16.6258%,18.3091%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.657,1.74226,12.6288%,30.9379%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.651,1.6849,12.2131%,43.151%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.663,1.67939,12.1731%,55.3241%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
"Transpose (ND, X32) Transpose",1.386,1.4311,10.3734%,65.6975%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
"Batch Matrix Multiply (NC, F32) GEMM",1.321,1.36406,9.88744%,75.5849%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Batch Matrix Multiply (NC, F32) GEMM",1.415,1.34396,9.74173%,85.3267%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.155,1.14034,0.295208%,85.6219%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
"Transpose (ND, X32) Transpose",0.929,0.82807,6.00231%,91.6242%,0,28,Delegate/Transpose (ND	 X32) Transpose:2

Number of nodes executed: 172
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,227.61,58.934%,58.934%,0,141
"Batch Matrix Multiply (NC, F32) GEMM",2,75.823,19.6325%,78.5664%,0,56
"Transpose (ND, X32) Transpose",4,63.322,16.3957%,94.9621%,0,112
EMBEDDING_LOOKUP,1,6.502,1.68353%,96.6456%,0,1
Multiply (ND),27,4.926,1.27547%,97.9211%,0,537
"Slice (ND, X32)",14,2.033,0.526395%,98.4475%,0,196
Add (ND),10,1.921,0.497395%,98.9449%,0,197
Static Reshape (NC),18,1.14,0.295175%,99.2401%,0,338
"Copy (NC, X32)",4,1.101,0.285077%,99.5251%,0,56
"Softmax (NC, F32)",1,0.574,0.148623%,99.6738%,0,28
Subtract (ND),4,0.553,0.143186%,99.817%,0,56
Sigmoid (NC),1,0.464,0.120141%,99.9371%,0,28
DYNAMIC_UPDATE_SLICE,56,0.139,0.0359906%,99.9731%,0,56
Sum (ND) Reduce,3,0.059,0.0152766%,99.9884%,0,57
GATHER_ND,1,0.028,0.0072499%,99.9956%,0,1
REDUCE_ALL,1,0.003,0.000776775%,99.9964%,0,1
SELECT_V2,1,0.002,0.00051785%,99.9969%,0,1
RESHAPE,4,0.002,0.00051785%,99.9974%,0,4
LESS,1,0.002,0.00051785%,99.9979%,0,1
ADD,1,0.002,0.00051785%,99.9985%,0,1
SELECT,1,0.001,0.000258925%,99.9987%,0,1
PACK,1,0.001,0.000258925%,99.999%,0,1
LOGICAL_AND,1,0.001,0.000258925%,99.9992%,0,1
LESS_EQUAL,1,0.001,0.000258925%,99.9995%,0,1
GREATER_EQUAL,1,0.001,0.000258925%,99.9998%,0,1
CAST,2,0.001,0.000258925%,100%,0,2
Sine (NC),1,0,0%,100%,0,1
Reciprocal Square Root (NC),3,0,0%,100%,0,57
Cosine (NC),1,0,0%,100%,0,1

Timings (microseconds): count=32 first=840638 curr=370394 min=363213 max=840638 avg=386284 std=87951
Memory (bytes): count=0
172 nodes observed

Subgraph (index: 1, name: prefill_128) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.002,0.002,4.14105e-05%,4.14105e-05%,0,1,[arith.constant222]:0
EMBEDDING_LOOKUP,86.996,86.996,1.80127%,1.80132%,0,1,[arith.constant223]:1
CAST,0.12,0.12,0.00248463%,1.8038%,0,1,[arith.constant225]:3
LESS,0.016,0.016,0.000331284%,1.80413%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;1]:8
ADD,0.005,0.005,0.000103526%,1.80424%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;2]:9
SELECT,0.002,0.002,4.14105e-05%,1.80428%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;3]:10
RESHAPE,0.001,0.001,2.07053e-05%,1.8043%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;4]:11
CAST,0.001,0.001,2.07053e-05%,1.80432%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:12
GREATER_EQUAL,0.002,0.002,4.14105e-05%,1.80436%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:13
LESS_EQUAL,0.002,0.002,4.14105e-05%,1.8044%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:14
LOGICAL_AND,0.002,0.002,4.14105e-05%,1.80444%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:15
REDUCE_ALL,0.014,0.014,0.000289874%,1.80473%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:16
GATHER_ND,1.491,1.491,0.0308715%,1.8356%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17
RESHAPE,0.002,0.002,4.14105e-05%,1.83565%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:19
SLICE,0.003,0.003,6.21158e-05%,1.83571%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;18]:57
RESHAPE,0,0,0%,1.83571%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:58
PACK,0.003,0.003,6.21158e-05%,1.83577%,0,1,[tfl.pack]:59
Static Reshape (NC),0.267,0.267,0.0055283%,1.8413%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0.001,0.001,2.07053e-05%,1.84132%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.035,0.035,0.000724684%,1.84204%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.061,0.061,0.00126302%,1.84331%,0,1,Delegate/Cosine (NC):3
Sine (NC),0.042,0.042,0.000869621%,1.84418%,0,1,Delegate/Sine (NC):4
Static Reshape (NC),0.08,0.08,0.00165642%,1.84583%,0,1,Delegate/Static Reshape (NC):5
Multiply (ND),0.349,0.349,0.00722614%,1.85306%,0,1,Delegate/Multiply (ND):6
Sum (ND) Reduce,0.14,0.14,0.00289874%,1.85596%,0,1,Delegate/Sum (ND) Reduce:7
Multiply (ND),0.039,0.039,0.000807505%,1.85676%,0,1,Delegate/Multiply (ND):8
Add (ND),0.028,0.028,0.000579747%,1.85734%,0,1,Delegate/Add (ND):9
Static Reshape (NC),0,0.00025,0.000144937%,1.85749%,0,28,Delegate/Static Reshape (NC):10
Reciprocal Square Root (NC),0.001,0.001,2.07053e-05%,1.85751%,0,1,Delegate/Reciprocal Square Root (NC):11
Multiply (ND),0.222,0.222,0.00459657%,1.86211%,0,1,Delegate/Multiply (ND):12
Multiply (ND),0.13,0.13,0.00269168%,1.8648%,0,1,Delegate/Multiply (ND):13
"Fully Connected (NC, QD8, F32, QC8W) GEMM",21.149,21.149,0.437896%,2.30269%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
Static Reshape (NC),0.25,0.009,0.00521773%,2.30791%,0,28,Delegate/Static Reshape (NC):15
"Slice (ND, X32)",0.286,0.286,0.0059217%,2.31383%,0,1,Delegate/Slice (ND	 X32):16
"Slice (ND, X32)",0.164,0.164,0.00339566%,2.31723%,0,1,Delegate/Slice (ND	 X32):17
"Slice (ND, X32)",0.099,0.099,0.00204982%,2.31928%,0,1,Delegate/Slice (ND	 X32):18
Static Reshape (NC),0,0,0%,2.31928%,0,1,Delegate/Static Reshape (NC):19
"Transpose (ND, X32) Transpose",0.372,0.372,0.00770236%,2.32698%,0,1,Delegate/Transpose (ND	 X32) Transpose:20
"Slice (ND, X32)",0.176,0.176,0.00364413%,2.33063%,0,1,Delegate/Slice (ND	 X32):21
"Slice (ND, X32)",0.143,0.143,0.00296085%,2.33359%,0,1,Delegate/Slice (ND	 X32):22
Multiply (ND),0.135,0.135,0.00279521%,2.33638%,0,1,Delegate/Multiply (ND):23
Multiply (ND),0.111,0.1145,0.0663811%,2.40276%,0,28,Delegate/Multiply (ND):24
Subtract (ND),0.054,0.054,0.00111808%,2.40388%,0,1,Delegate/Subtract (ND):25
Multiply (ND),0.105,0.105,0.00217405%,2.40605%,0,1,Delegate/Multiply (ND):26
Multiply (ND),0.16,0.16,0.00331284%,2.40937%,0,1,Delegate/Multiply (ND):27
Add (ND),0.08,0.08,0.00165642%,2.41102%,0,1,Delegate/Add (ND):28
"Copy (NC, X32)",0.438,0.438,0.0090689%,2.42009%,0,1,Delegate/Copy (NC	 X32):29
"Transpose (ND, X32) Transpose",0.272,0.272,0.00563183%,2.42572%,0,1,Delegate/Transpose (ND	 X32) Transpose:30
"Transpose (ND, X32) Transpose",0.137,0.137,0.00283662%,2.42856%,0,1,Delegate/Transpose (ND	 X32) Transpose:31
"Slice (ND, X32)",0.053,0.053,0.00109738%,2.42966%,0,1,Delegate/Slice (ND	 X32):32
"Slice (ND, X32)",0.03,0.03,0.000621158%,2.43028%,0,1,Delegate/Slice (ND	 X32):33
Multiply (ND),0.066,0.066,0.00136655%,2.43165%,0,1,Delegate/Multiply (ND):34
Multiply (ND),0.042,0.0226071,0.0131064%,2.44475%,0,28,Delegate/Multiply (ND):35
Subtract (ND),0.04,0.04,0.00082821%,2.44558%,0,1,Delegate/Subtract (ND):36
Multiply (ND),0.027,0.027,0.000559042%,2.44614%,0,1,Delegate/Multiply (ND):37
Multiply (ND),0.026,0.026,0.000538337%,2.44668%,0,1,Delegate/Multiply (ND):38
Add (ND),0.032,0.032,0.000662568%,2.44734%,0,1,Delegate/Add (ND):39
"Copy (NC, X32)",0.078,0.078,0.00161501%,2.44896%,0,1,Delegate/Copy (NC	 X32):40
"Transpose (ND, X32) Transpose",0.034,0.034,0.000703979%,2.44966%,0,1,Delegate/Transpose (ND	 X32) Transpose:41
SELECT_V2,0.325,0.325,0.00672921%,2.45639%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:20
DYNAMIC_UPDATE_SLICE,0.095,0.095,0.001967%,2.45836%,0,1,[StatefulPartitionedCall:0]:60
DYNAMIC_UPDATE_SLICE,0.095,0.095,0.001967%,2.46032%,0,1,[StatefulPartitionedCall:28]:61
Multiply (ND),0.31,0.210259,0.117544%,2.57787%,0,27,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.235,0.257074,0.143715%,2.72158%,0,27,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",1.095,1.13256,0.633146%,3.35473%,0,27,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0.001,0.000185185,0.000103526%,3.35483%,0,27,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,0.000111111,6.21158e-05%,3.35489%,0,27,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",14.36,10.4169,5.82346%,9.17835%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,0.000111111,6.21158e-05%,9.17841%,0,27,Delegate/Static Reshape (NC):6
Add (ND),1.922,1.91048,1.06804%,10.2465%,0,27,Delegate/Add (ND):7
"Softmax (NC, F32)",1.855,1.86707,1.04377%,11.2902%,0,27,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.772,1.74444,0.975218%,12.2654%,0,27,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0.000148148,8.2821e-05%,12.2655%,0,27,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",10.305,10.2804,5.74718%,18.0127%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Static Reshape (NC),0,0.000555556,0.000310579%,18.013%,0,27,Delegate/Static Reshape (NC):13
"Transpose (ND, X32) Transpose",0.242,0.247704,0.138477%,18.1515%,0,27,Delegate/Transpose (ND	 X32) Transpose:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.901,10.535,5.88949%,24.041%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.264,0.277778,0.155289%,24.1963%,0,27,Delegate/Add (ND):17
Multiply (ND),0.122,0.130333,0.0728618%,24.2691%,0,27,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.094,0.0871481,0.0487195%,24.3178%,0,27,Delegate/Sum (ND) Reduce:19
Multiply (ND),0.016,0.0204444,0.0114293%,24.3293%,0,27,Delegate/Multiply (ND):20
Add (ND),0.012,0.0146667,0.00819928%,24.3375%,0,27,Delegate/Add (ND):21
Static Reshape (NC),0,0,0%,24.3375%,0,27,Delegate/Static Reshape (NC):22
Reciprocal Square Root (NC),0,0.000296296,0.000165642%,24.3376%,0,27,Delegate/Reciprocal Square Root (NC):23
Multiply (ND),0.148,0.148481,0.0830074%,24.4207%,0,27,Delegate/Multiply (ND):25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.232,25.3919,14.1951%,38.6158%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
Sigmoid (NC),0.554,0.579333,0.323872%,38.9397%,0,27,Delegate/Sigmoid (NC):27
Multiply (ND),0.83,0.834778,0.466676%,39.4063%,0,27,Delegate/Multiply (ND):28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.339,25.4598,14.2331%,53.6394%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
Multiply (ND),0.881,0.847778,0.473943%,54.1134%,0,27,Delegate/Multiply (ND):30
"Fully Connected (NC, QD8, F32, QC8W) GEMM",66.856,61.5946,34.4339%,88.5473%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
Add (ND),0.262,0.258556,0.144543%,88.6919%,0,27,Delegate/Add (ND):32
Multiply (ND),0.139,0.126593,0.0707706%,88.7626%,0,27,Delegate/Multiply (ND):33
Sum (ND) Reduce,0.061,0.0822222,0.0459657%,88.8086%,0,27,Delegate/Sum (ND) Reduce:34
Add (ND),0.014,0.0138889,0.00776447%,88.8164%,0,27,Delegate/Add (ND):36
Static Reshape (NC),0,0,0%,88.8164%,0,27,Delegate/Static Reshape (NC):37
Reciprocal Square Root (NC),0,0.000444444,0.000248463%,88.8166%,0,27,Delegate/Reciprocal Square Root (NC):38
Multiply (ND),0.216,0.187889,0.105038%,88.9217%,0,27,Delegate/Multiply (ND):39
Multiply (ND),0.069,0.0741852,0.0414726%,88.9631%,0,27,Delegate/Multiply (ND):40
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.497,16.4101,9.17394%,98.1371%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
Static Reshape (NC),0.243,0.263519,0.147318%,98.2844%,0,27,Delegate/Static Reshape (NC):42
"Slice (ND, X32)",0.251,0.250889,0.140257%,98.4246%,0,27,Delegate/Slice (ND	 X32):43
"Slice (ND, X32)",0.14,0.137593,0.07692%,98.5016%,0,27,Delegate/Slice (ND	 X32):44
"Slice (ND, X32)",0.113,0.108308,0.058306%,98.5599%,0,26,Delegate/Slice (ND	 X32):45
Static Reshape (NC),0,0,0%,98.5599%,0,26,Delegate/Static Reshape (NC):46
"Transpose (ND, X32) Transpose",0.378,0.385,0.20726%,98.7671%,0,26,Delegate/Transpose (ND	 X32) Transpose:47
"Slice (ND, X32)",0.195,0.189038,0.101766%,98.8689%,0,26,Delegate/Slice (ND	 X32):48
"Slice (ND, X32)",0.18,0.170846,0.0919728%,98.9609%,0,26,Delegate/Slice (ND	 X32):49
Multiply (ND),0.15,0.153115,0.0824276%,99.0433%,0,26,Delegate/Multiply (ND):50
Multiply (ND),0.122,0.111593,0.0623849%,99.1057%,0,27,Delegate/Multiply (ND):51
Subtract (ND),0.052,0.0551538,0.0296913%,99.1354%,0,26,Delegate/Subtract (ND):52
Multiply (ND),0.069,0.0608462,0.0327557%,99.1681%,0,26,Delegate/Multiply (ND):53
Multiply (ND),0.117,0.116038,0.0624678%,99.2306%,0,26,Delegate/Multiply (ND):54
Add (ND),0.059,0.0628846,0.0338531%,99.2645%,0,26,Delegate/Add (ND):55
"Copy (NC, X32)",0.425,0.403192,0.217053%,99.4815%,0,26,Delegate/Copy (NC	 X32):56
"Transpose (ND, X32) Transpose",0.238,0.2425,0.130547%,99.612%,0,26,Delegate/Transpose (ND	 X32) Transpose:57
"Transpose (ND, X32) Transpose",0.131,0.1345,0.0724063%,99.6844%,0,26,Delegate/Transpose (ND	 X32) Transpose:58
"Slice (ND, X32)",0.057,0.0584615,0.031472%,99.7159%,0,26,Delegate/Slice (ND	 X32):59
"Slice (ND, X32)",0.039,0.0364231,0.0196079%,99.7355%,0,26,Delegate/Slice (ND	 X32):60
Multiply (ND),0.047,0.0403462,0.0217198%,99.7573%,0,26,Delegate/Multiply (ND):61
Multiply (ND),0.043,0.0389231,0.0209537%,99.7782%,0,26,Delegate/Multiply (ND):62
Subtract (ND),0.018,0.0193846,0.0104355%,99.7886%,0,26,Delegate/Subtract (ND):63
Multiply (ND),0.024,0.0244615,0.0131685%,99.8018%,0,26,Delegate/Multiply (ND):64
Multiply (ND),0.034,0.0308077,0.0165849%,99.8184%,0,26,Delegate/Multiply (ND):65
Add (ND),0.017,0.0185,0.00995923%,99.8284%,0,26,Delegate/Add (ND):66
"Copy (NC, X32)",0.083,0.0821538,0.0442264%,99.8726%,0,26,Delegate/Copy (NC	 X32):67
"Transpose (ND, X32) Transpose",0.102,0.0521538,0.0280763%,99.9007%,0,26,Delegate/Transpose (ND	 X32) Transpose:68
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149078%,99.9022%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:117
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.904%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:118
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149078%,99.9054%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:174
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9072%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:175
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149078%,99.9087%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:231
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184277%,99.9106%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:232
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00151148%,99.9121%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:288
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00182206%,99.9139%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:289
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144937%,99.9154%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:345
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9172%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:346
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149078%,99.9186%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:402
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9204%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6;1]:403
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140796%,99.9219%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:459
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9237%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:460
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147007%,99.9251%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;4]:516
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00178065%,99.9269%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;5]:517
DYNAMIC_UPDATE_SLICE,0.074,0.074,0.00153219%,99.9284%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:573
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173924%,99.9302%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;1]:574
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147007%,99.9317%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:630
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175995%,99.9334%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:631
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138725%,99.9348%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;4]:687
DYNAMIC_UPDATE_SLICE,0.116,0.116,0.00240181%,99.9372%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;5]:688
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142866%,99.9386%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:744
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9404%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;6]:745
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142866%,99.9419%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;3]:801
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175995%,99.9436%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;7]:802
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144937%,99.9451%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;9]:858
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175995%,99.9468%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;10]:859
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138725%,99.9482%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;12]:915
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00178065%,99.95%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;]:916
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149078%,99.9515%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;13]:972
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173924%,99.9532%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:973
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147007%,99.9547%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;14]:1029
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9565%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;15]:1030
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140796%,99.9579%,0,1,[StatefulPartitionedCall:11]:1086
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00182206%,99.9597%,0,1,[StatefulPartitionedCall:39]:1087
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147007%,99.9612%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:1143
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175995%,99.963%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1144
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144937%,99.9644%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:1200
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184277%,99.9663%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1201
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00151148%,99.9678%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:1257
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00178065%,99.9695%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:1258
DYNAMIC_UPDATE_SLICE,0.074,0.074,0.00153219%,99.9711%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:1314
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00182206%,99.9729%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1315
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149078%,99.9744%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:1371
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184277%,99.9762%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1372
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00151148%,99.9777%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1428
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180136%,99.9795%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25;1]:1429
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147007%,99.981%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1485
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00182206%,99.9828%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:1486
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00151148%,99.9843%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;4]:1542
DYNAMIC_UPDATE_SLICE,0.091,0.091,0.00188418%,99.9862%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;5]:1543
"Transpose (ND, X32) Transpose",0.118,0.118,0.00244322%,99.9887%,0,1,Delegate/Transpose (ND	 X32) Transpose:45
"Slice (ND, X32)",0.066,0.066,0.00136655%,99.99%,0,1,Delegate/Slice (ND	 X32):46
"Slice (ND, X32)",0.041,0.041,0.000848916%,99.9909%,0,1,Delegate/Slice (ND	 X32):47
Multiply (ND),0.047,0.047,0.000973147%,99.9919%,0,1,Delegate/Multiply (ND):48
Multiply (ND),0.043,0.043,0.000890326%,99.9928%,0,1,Delegate/Multiply (ND):49
Subtract (ND),0.017,0.017,0.000351989%,99.9931%,0,1,Delegate/Subtract (ND):50
Multiply (ND),0.028,0.028,0.000579747%,99.9937%,0,1,Delegate/Multiply (ND):52
Add (ND),0.018,0.018,0.000372695%,99.9941%,0,1,Delegate/Add (ND):53
"Copy (NC, X32)",0.091,0.091,0.00188418%,99.9959%,0,1,Delegate/Copy (NC	 X32):54
"Transpose (ND, X32) Transpose",0.046,0.046,0.000952442%,99.9969%,0,1,Delegate/Transpose (ND	 X32) Transpose:55
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144937%,99.9983%,0,1,[Unknown]:1586
DYNAMIC_UPDATE_SLICE,0.08,0.08,0.00165642%,100%,0,1,[Unknown]:1587

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
EMBEDDING_LOOKUP,86.996,86.996,1.80127%,1.80127%,0,1,[arith.constant223]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",66.856,61.5946,34.4339%,36.2352%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.339,25.4598,14.2331%,50.4683%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.232,25.3919,14.1951%,64.6635%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
"Fully Connected (NC, QD8, F32, QC8W) GEMM",21.149,21.149,0.437896%,65.1013%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.497,16.4101,9.17394%,74.2753%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.901,10.535,5.88949%,80.1648%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
"Batch Matrix Multiply (NC, F32) GEMM",14.36,10.4169,5.82346%,85.9882%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
"Batch Matrix Multiply (NC, F32) GEMM",10.305,10.2804,5.74718%,91.7354%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Add (ND),1.922,1.91048,1.06804%,92.8035%,0,27,Delegate/Add (ND):7

Number of nodes executed: 191
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,3784.72,78.3635%,78.3635%,0,136
"Batch Matrix Multiply (NC, F32) GEMM",2,558.826,11.5706%,89.9341%,0,54
"Transpose (ND, X32) Transpose",14,113.455,2.34912%,92.2833%,0,218
Multiply (ND),33,90.022,1.86393%,94.1472%,0,522
EMBEDDING_LOOKUP,1,86.996,1.80127%,95.9485%,0,1
Add (ND),11,69.109,1.43092%,97.3794%,0,191
"Softmax (NC, F32)",1,50.411,1.04377%,98.4231%,0,27
"Slice (ND, X32)",16,26.187,0.542209%,98.9654%,0,193
Sigmoid (NC),1,15.642,0.323872%,99.2892%,0,27
"Copy (NC, X32)",5,13.226,0.273848%,99.5631%,0,55
Static Reshape (NC),15,7.752,0.160507%,99.7236%,0,302
Sum (ND) Reduce,3,4.713,0.0975839%,99.8212%,0,55
DYNAMIC_UPDATE_SLICE,56,4.473,0.0926146%,99.9138%,0,56
Subtract (ND),5,2.049,0.0424251%,99.9562%,0,55
GATHER_ND,1,1.491,0.0308715%,99.9871%,0,1
SELECT_V2,1,0.325,0.00672921%,99.9938%,0,1
CAST,2,0.121,0.00250534%,99.9963%,0,2
Cosine (NC),1,0.061,0.00126302%,99.9976%,0,1
Sine (NC),1,0.042,0.000869621%,99.9985%,0,1
Reciprocal Square Root (NC),3,0.021,0.00043481%,99.9989%,0,55
LESS,1,0.016,0.000331284%,99.9992%,0,1
REDUCE_ALL,1,0.014,0.000289874%,99.9995%,0,1
RESHAPE,4,0.005,0.000103526%,99.9996%,0,4
ADD,1,0.005,0.000103526%,99.9997%,0,1
SLICE,1,0.003,6.21158e-05%,99.9998%,0,1
PACK,1,0.003,6.21158e-05%,99.9998%,0,1
SELECT,1,0.002,4.14105e-05%,99.9999%,0,1
LOGICAL_AND,1,0.002,4.14105e-05%,99.9999%,0,1
LESS_EQUAL,1,0.002,4.14105e-05%,100%,0,1
GREATER_EQUAL,1,0.002,4.14105e-05%,100%,0,1

Subgraph (index: 1, name: prefill_128) Timings (microseconds): count=1 curr=4829691
Memory (bytes): count=0
191 nodes observed


