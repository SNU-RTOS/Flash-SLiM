Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

Number of nodes executed: 0
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called

Timings (microseconds): count=0
Memory (bytes): count=0
0 nodes observed


Operator-wise Profiling Info for Regular Benchmark Runs:
Primary graph (name: decode) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.007,0.0024375,0.000613756%,0.000613756%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;]:0
EMBEDDING_LOOKUP,0.007,1.43562,0.361487%,0.3621%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
CAST,0.003,0.0015625,0.000393433%,0.362494%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;]:3
LESS,0.002,0.00240625,0.000605887%,0.3631%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:8
ADD,0.003,0.00246875,0.000621625%,0.363721%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:9
SELECT,0.001,0.00146875,0.000369827%,0.364091%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:10
RESHAPE,0.001,0.0003125,7.86867e-05%,0.36417%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:11
CAST,0.003,0.00046875,0.00011803%,0.364288%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:12
GREATER_EQUAL,0.002,0.001125,0.000283272%,0.364571%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:13
LESS_EQUAL,0.001,0.0013125,0.000330484%,0.364902%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;11]:14
LOGICAL_AND,0.001,0.0011875,0.000299009%,0.365201%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:15
REDUCE_ALL,0.003,0.00371875,0.000936371%,0.366137%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:16
GATHER_ND,0.003,0.0109375,0.00275403%,0.368891%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;14]:17
RESHAPE,0,0.00028125,7.0818e-05%,0.368962%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;15]:18
SELECT_V2,0.004,0.00259375,0.000653099%,0.369615%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;16]:19
RESHAPE,0.001,0.0005,0.000125899%,0.369741%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:54
PACK,0.003,0.002,0.000503595%,0.370244%,0,1,[tfl.pack]:55
Static Reshape (NC),0.036,0.2305,0.0580393%,0.428284%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0,0.00021875,5.50807e-05%,0.428339%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.013,0.1285,0.032356%,0.460695%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0,0.0006875,0.000173111%,0.460868%,0,1,Delegate/Cosine (NC):3
Sine (NC),0,0.0001875,4.7212e-05%,0.460915%,0,1,Delegate/Sine (NC):4
Multiply (ND),0.015,0.108781,0.0273908%,0.488306%,0,1,Delegate/Multiply (ND):5
Sum (ND) Reduce,0.001,0.00134375,0.000338353%,0.488644%,0,1,Delegate/Sum (ND) Reduce:6
Multiply (ND),0,0.00015625,3.93433e-05%,0.488684%,0,1,Delegate/Multiply (ND):7
Add (ND),0,6.25e-05,1.57373e-05%,0.488699%,0,1,Delegate/Add (ND):8
Reciprocal Square Root (NC),0,6.25e-05,1.57373e-05%,0.488715%,0,1,Delegate/Reciprocal Square Root (NC):9
Multiply (ND),0.013,0.127406,0.0320806%,0.520796%,0,1,Delegate/Multiply (ND):10
Multiply (ND),0.007,0.08975,0.0225988%,0.543394%,0,1,Delegate/Multiply (ND):11
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.144,1.11228,0.280069%,0.823464%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
Static Reshape (NC),0.062,0.00321767,0.0234958%,0.84696%,0,29,Delegate/Static Reshape (NC):13
"Slice (ND, X32)",0.046,0.100594,0.0253292%,0.872289%,0,1,Delegate/Slice (ND	 X32):14
"Slice (ND, X32)",0.015,0.0898125,0.0226146%,0.894904%,0,1,Delegate/Slice (ND	 X32):15
"Slice (ND, X32)",0.036,0.105,0.0264387%,0.921342%,0,1,Delegate/Slice (ND	 X32):16
Static Reshape (NC),0.012,0.0894375,0.0225201%,0.943862%,0,1,Delegate/Static Reshape (NC):17
"Slice (ND, X32)",0.013,0.07525,0.0189478%,0.96281%,0,1,Delegate/Slice (ND	 X32):18
"Slice (ND, X32)",0.015,0.0638438,0.0160757%,0.978886%,0,1,Delegate/Slice (ND	 X32):19
Multiply (ND),0.013,0.00165733,0.012102%,0.990988%,0,29,Delegate/Multiply (ND):20
Multiply (ND),0.013,0.0430313,0.0108352%,1.00182%,0,1,Delegate/Multiply (ND):21
Subtract (ND),0.013,0.0574375,0.0144626%,1.01629%,0,1,Delegate/Subtract (ND):22
Multiply (ND),0.012,0.0145808,0.106471%,1.12276%,0,29,Delegate/Multiply (ND):23
Multiply (ND),0.013,0.0106261,0.0775929%,1.20035%,0,29,Delegate/Multiply (ND):24
Add (ND),0.013,0.0263125,0.00662542%,1.20697%,0,1,Delegate/Add (ND):25
"Copy (NC, X32)",0.027,0.0595313,0.0149898%,1.22196%,0,1,Delegate/Copy (NC	 X32):26
Static Reshape (NC),0.018,0.02975,0.00749097%,1.22946%,0,1,Delegate/Static Reshape (NC):27
Static Reshape (NC),0,0.000375,9.4424e-05%,1.22955%,0,1,Delegate/Static Reshape (NC):28
"Slice (ND, X32)",0.013,0.0352188,0.00886799%,1.23842%,0,1,Delegate/Slice (ND	 X32):29
"Slice (ND, X32)",0.012,0.032375,0.00815194%,1.24657%,0,1,Delegate/Slice (ND	 X32):30
Multiply (ND),0.013,0.0324687,0.00817555%,1.25475%,0,1,Delegate/Multiply (ND):31
Multiply (ND),0.012,0.013028,0.0951322%,1.34988%,0,29,Delegate/Multiply (ND):32
Subtract (ND),0.012,0.0283438,0.00713688%,1.35701%,0,1,Delegate/Subtract (ND):33
Multiply (ND),0.012,0.00103017,0.00752245%,1.36454%,0,29,Delegate/Multiply (ND):34
Multiply (ND),0.012,0.0349687,0.00880504%,1.37334%,0,1,Delegate/Multiply (ND):35
Add (ND),0.012,0.0421562,0.0106148%,1.38396%,0,1,Delegate/Add (ND):36
"Copy (NC, X32)",0.025,0.12125,0.0305304%,1.41449%,0,1,Delegate/Copy (NC	 X32):37
Static Reshape (NC),0,0.0003125,7.86867e-05%,1.41457%,0,1,Delegate/Static Reshape (NC):38
DYNAMIC_UPDATE_SLICE,0.004,0.00471875,0.00118817%,1.41575%,0,1,[StatefulPartitionedCall:0]:56
DYNAMIC_UPDATE_SLICE,0.002,0.0015,0.000377696%,1.41613%,0,1,[StatefulPartitionedCall:28]:57
Multiply (ND),0.019,0.0134799,0.0950378%,1.51117%,0,28,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.001,0.000991071,0.00698738%,1.51816%,0,28,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",0.921,0.906689,6.39245%,7.91061%,0,28,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000198661,0.00140062%,7.91201%,0,28,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,8.92857e-06,6.29493e-05%,7.91207%,0,28,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",1.481,1.48881,10.4966%,18.4087%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,3.34821e-05,0.00023606%,18.4089%,0,28,Delegate/Static Reshape (NC):6
Add (ND),0.036,0.024125,0.170089%,18.579%,0,28,Delegate/Add (ND):7
"Softmax (NC, F32)",0.024,0.0217455,0.153313%,18.7323%,0,28,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.593,1.58713,11.1898%,29.9221%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0.00021317,0.00150292%,29.9236%,0,28,Delegate/Static Reshape (NC):10
Static Reshape (NC),0,4.46429e-06,3.14747e-05%,29.9237%,0,28,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",1.489,1.50152,10.5862%,40.5099%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Transpose (ND, X32) Transpose",0.002,0.00173438,0.0122279%,40.5221%,0,28,Delegate/Transpose (ND	 X32) Transpose:14
Static Reshape (NC),0,2.23214e-06,1.57373e-05%,40.5221%,0,28,Delegate/Static Reshape (NC):15
"Fully Connected (NC, QD8, F32, QC8W) GEMM",0.668,0.667391,4.70532%,45.2274%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.012,0.0139699,0.0984921%,45.3259%,0,28,Delegate/Add (ND):17
Multiply (ND),0.014,0.0103504,0.072974%,45.3989%,0,28,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.001,0.0013125,0.00925355%,45.4081%,0,28,Delegate/Sum (ND) Reduce:19
Add (ND),0,1.11607e-05,7.86867e-05%,45.4082%,0,28,Delegate/Add (ND):21
Reciprocal Square Root (NC),0,6.69643e-06,4.7212e-05%,45.4083%,0,28,Delegate/Reciprocal Square Root (NC):22
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.794,1.69462,11.9476%,57.3559%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
Sigmoid (NC),0.015,0.0177087,0.124852%,57.4807%,0,28,Delegate/Sigmoid (NC):26
Multiply (ND),0.012,0.00986049,0.0695197%,57.5502%,0,28,Delegate/Multiply (ND):27
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.726,1.69193,11.9287%,69.4789%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
Multiply (ND),0.012,0.0144319,0.10175%,69.5807%,0,28,Delegate/Multiply (ND):29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.758,1.68635,11.8893%,81.4699%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
Add (ND),0.041,0.0166094,0.117102%,81.5871%,0,28,Delegate/Add (ND):31
Sum (ND) Reduce,0.002,0.00110045,0.00775851%,81.5948%,0,28,Delegate/Sum (ND) Reduce:33
Add (ND),0,1.33929e-05,9.4424e-05%,81.5949%,0,28,Delegate/Add (ND):35
Reciprocal Square Root (NC),0,1.11607e-06,7.86867e-06%,81.5949%,0,28,Delegate/Reciprocal Square Root (NC):36
Multiply (ND),0.012,0.012731,0.0897579%,81.6847%,0,28,Delegate/Multiply (ND):37
Multiply (ND),0.013,0.00892411,0.0629179%,81.7476%,0,28,Delegate/Multiply (ND):38
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.093,2.29756,16.1985%,97.9461%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
Static Reshape (NC),0.016,0.015206,0.103379%,98.0495%,0,27,Delegate/Static Reshape (NC):40
"Slice (ND, X32)",0.012,0.0125718,0.0854695%,98.135%,0,27,Delegate/Slice (ND	 X32):41
"Slice (ND, X32)",0.012,0.0113993,0.0774985%,98.2125%,0,27,Delegate/Slice (ND	 X32):42
"Slice (ND, X32)",0.021,0.0110521,0.0751379%,98.2876%,0,27,Delegate/Slice (ND	 X32):43
Static Reshape (NC),0.012,0.0113611,0.0772388%,98.3648%,0,27,Delegate/Static Reshape (NC):44
"Slice (ND, X32)",0.012,0.0109745,0.0746107%,98.4395%,0,27,Delegate/Slice (ND	 X32):45
"Slice (ND, X32)",0.012,0.0108449,0.0737294%,98.5132%,0,27,Delegate/Slice (ND	 X32):46
Multiply (ND),0.011,0.0112755,0.0766566%,98.5898%,0,27,Delegate/Multiply (ND):47
Multiply (ND),0.011,0.011353,0.0771838%,98.667%,0,27,Delegate/Multiply (ND):48
Subtract (ND),0.011,0.0113252,0.0769949%,98.744%,0,27,Delegate/Subtract (ND):49
Multiply (ND),0.011,0.0110961,0.0754369%,98.8195%,0,27,Delegate/Multiply (ND):50
Multiply (ND),0.01,0.0108993,0.0740992%,98.8936%,0,27,Delegate/Multiply (ND):51
Add (ND),0.011,0.0111181,0.0755864%,98.9691%,0,27,Delegate/Add (ND):52
"Copy (NC, X32)",0.023,0.0223727,0.152101%,99.1212%,0,27,Delegate/Copy (NC	 X32):53
Static Reshape (NC),0.011,0.0111863,0.0760507%,99.1973%,0,27,Delegate/Static Reshape (NC):54
Static Reshape (NC),0,3.58796e-05,0.000243929%,99.1975%,0,27,Delegate/Static Reshape (NC):55
"Slice (ND, X32)",0.011,0.0109248,0.0742724%,99.2718%,0,27,Delegate/Slice (ND	 X32):56
"Slice (ND, X32)",0.01,0.0106933,0.0726986%,99.3445%,0,27,Delegate/Slice (ND	 X32):57
Multiply (ND),0.01,0.010706,0.0727852%,99.4173%,0,27,Delegate/Multiply (ND):58
Multiply (ND),0.01,0.0109919,0.0747287%,99.492%,0,27,Delegate/Multiply (ND):59
Subtract (ND),0.01,0.0112639,0.0765779%,99.5686%,0,27,Delegate/Subtract (ND):60
Multiply (ND),0.011,0.0117523,0.0798985%,99.6485%,0,27,Delegate/Multiply (ND):61
Multiply (ND),0.01,0.0117419,0.0798276%,99.7283%,0,27,Delegate/Multiply (ND):62
Add (ND),0.01,0.0120243,0.0817476%,99.8101%,0,27,Delegate/Add (ND):63
"Copy (NC, X32)",0.02,0.0220278,0.149756%,99.9598%,0,27,Delegate/Copy (NC	 X32):64
Static Reshape (NC),0,1.85185e-05,0.000125899%,99.96%,0,27,Delegate/Static Reshape (NC):65
DYNAMIC_UPDATE_SLICE,0.004,0.0048125,0.00121177%,99.9612%,0,1,[StatefulPartitionedCall:1]:110
DYNAMIC_UPDATE_SLICE,0.002,0.00134375,0.000338353%,99.9615%,0,1,[StatefulPartitionedCall:29]:111
DYNAMIC_UPDATE_SLICE,0.005,0.0046875,0.0011803%,99.9627%,0,1,[StatefulPartitionedCall:12]:164
DYNAMIC_UPDATE_SLICE,0.002,0.00115625,0.000291141%,99.963%,0,1,[StatefulPartitionedCall:40]:165
DYNAMIC_UPDATE_SLICE,0.006,0.00475,0.00119604%,99.9642%,0,1,[StatefulPartitionedCall:21]:218
DYNAMIC_UPDATE_SLICE,0.001,0.00125,0.000314747%,99.9645%,0,1,[StatefulPartitionedCall:49]:219
DYNAMIC_UPDATE_SLICE,0.005,0.0048125,0.00121177%,99.9657%,0,1,[StatefulPartitionedCall:22]:272
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.000299009%,99.966%,0,1,[StatefulPartitionedCall:50]:273
DYNAMIC_UPDATE_SLICE,0.004,0.00475,0.00119604%,99.9672%,0,1,[StatefulPartitionedCall:23]:326
DYNAMIC_UPDATE_SLICE,0.002,0.00109375,0.000275403%,99.9675%,0,1,[StatefulPartitionedCall:51]:327
DYNAMIC_UPDATE_SLICE,0.004,0.00465625,0.00117243%,99.9686%,0,1,[StatefulPartitionedCall:24]:380
DYNAMIC_UPDATE_SLICE,0.002,0.00128125,0.000322615%,99.969%,0,1,[StatefulPartitionedCall:52]:381
DYNAMIC_UPDATE_SLICE,0.005,0.0046875,0.0011803%,99.9701%,0,1,[StatefulPartitionedCall:25]:434
DYNAMIC_UPDATE_SLICE,0.002,0.00128125,0.000322615%,99.9705%,0,1,[StatefulPartitionedCall:53]:435
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00115669%,99.9716%,0,1,[StatefulPartitionedCall:26]:488
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000330484%,99.972%,0,1,[StatefulPartitionedCall:54]:489
DYNAMIC_UPDATE_SLICE,0.004,0.004625,0.00116456%,99.9731%,0,1,[StatefulPartitionedCall:27]:542
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000330484%,99.9734%,0,1,[StatefulPartitionedCall:55]:543
DYNAMIC_UPDATE_SLICE,0.005,0.0045,0.00113309%,99.9746%,0,1,[StatefulPartitionedCall:2]:596
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.000299009%,99.9749%,0,1,[StatefulPartitionedCall:30]:597
DYNAMIC_UPDATE_SLICE,0.004,0.0046875,0.0011803%,99.9761%,0,1,[StatefulPartitionedCall:3]:650
DYNAMIC_UPDATE_SLICE,0.001,0.001125,0.000283272%,99.9763%,0,1,[StatefulPartitionedCall:31]:651
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00117243%,99.9775%,0,1,[StatefulPartitionedCall:4]:704
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000291141%,99.9778%,0,1,[StatefulPartitionedCall:32]:705
DYNAMIC_UPDATE_SLICE,0.005,0.00471875,0.00118817%,99.979%,0,1,[StatefulPartitionedCall:5]:758
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000330484%,99.9793%,0,1,[StatefulPartitionedCall:33]:759
DYNAMIC_UPDATE_SLICE,0.005,0.00475,0.00119604%,99.9805%,0,1,[StatefulPartitionedCall:6]:812
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000306878%,99.9808%,0,1,[StatefulPartitionedCall:34]:813
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00117243%,99.982%,0,1,[StatefulPartitionedCall:7]:866
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.000299009%,99.9823%,0,1,[StatefulPartitionedCall:35]:867
DYNAMIC_UPDATE_SLICE,0.005,0.00490625,0.00123538%,99.9835%,0,1,[StatefulPartitionedCall:8]:920
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000306878%,99.9838%,0,1,[StatefulPartitionedCall:36]:921
DYNAMIC_UPDATE_SLICE,0.006,0.0046875,0.0011803%,99.985%,0,1,[StatefulPartitionedCall:9]:974
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000306878%,99.9853%,0,1,[StatefulPartitionedCall:37]:975
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00117243%,99.9865%,0,1,[StatefulPartitionedCall:10]:1028
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000306878%,99.9868%,0,1,[StatefulPartitionedCall:38]:1029
DYNAMIC_UPDATE_SLICE,0.005,0.004625,0.00116456%,99.988%,0,1,[StatefulPartitionedCall:11]:1082
DYNAMIC_UPDATE_SLICE,0.001,0.0010625,0.000267535%,99.9883%,0,1,[StatefulPartitionedCall:39]:1083
DYNAMIC_UPDATE_SLICE,0.005,0.0045,0.00113309%,99.9894%,0,1,[StatefulPartitionedCall:13]:1136
DYNAMIC_UPDATE_SLICE,0.001,0.0014375,0.000361959%,99.9897%,0,1,[StatefulPartitionedCall:41]:1137
DYNAMIC_UPDATE_SLICE,0.005,0.004625,0.00116456%,99.9909%,0,1,[StatefulPartitionedCall:14]:1190
DYNAMIC_UPDATE_SLICE,0.001,0.00125,0.000314747%,99.9912%,0,1,[StatefulPartitionedCall:42]:1191
DYNAMIC_UPDATE_SLICE,0.004,0.004625,0.00116456%,99.9924%,0,1,[StatefulPartitionedCall:15]:1244
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000330484%,99.9927%,0,1,[StatefulPartitionedCall:43]:1245
DYNAMIC_UPDATE_SLICE,0.006,0.00465625,0.00117243%,99.9939%,0,1,[StatefulPartitionedCall:16]:1298
DYNAMIC_UPDATE_SLICE,0.002,0.0011875,0.000299009%,99.9942%,0,1,[StatefulPartitionedCall:44]:1299
DYNAMIC_UPDATE_SLICE,0.005,0.0045,0.00113309%,99.9953%,0,1,[StatefulPartitionedCall:17]:1352
DYNAMIC_UPDATE_SLICE,0.002,0.00128125,0.000322615%,99.9956%,0,1,[StatefulPartitionedCall:45]:1353
DYNAMIC_UPDATE_SLICE,0.005,0.00453125,0.00114096%,99.9968%,0,1,[StatefulPartitionedCall:18]:1406
DYNAMIC_UPDATE_SLICE,0.001,0.0010625,0.000267535%,99.9971%,0,1,[StatefulPartitionedCall:46]:1407
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00117243%,99.9982%,0,1,[StatefulPartitionedCall:19]:1460
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000346221%,99.9986%,0,1,[StatefulPartitionedCall:47]:1461
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00114883%,99.9997%,0,1,[StatefulPartitionedCall:20]:1514
DYNAMIC_UPDATE_SLICE,0.001,0.001125,0.000283272%,100%,0,1,[StatefulPartitionedCall:48]:1515

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.093,2.29756,16.1985%,16.1985%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.794,1.69462,11.9476%,28.1461%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.726,1.69193,11.9287%,40.0748%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.758,1.68635,11.8893%,51.9641%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
"Transpose (ND, X32) Transpose",1.593,1.58713,11.1898%,63.1539%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
"Batch Matrix Multiply (NC, F32) GEMM",1.489,1.50152,10.5862%,73.7401%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Batch Matrix Multiply (NC, F32) GEMM",1.481,1.48881,10.4966%,84.2367%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
EMBEDDING_LOOKUP,0.007,1.43562,0.361487%,84.5982%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.144,1.11228,0.280069%,84.8783%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
"Transpose (ND, X32) Transpose",0.921,0.906689,6.39245%,91.2707%,0,28,Delegate/Transpose (ND	 X32) Transpose:2

Number of nodes executed: 172
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,226.169,56.9601%,56.9601%,0,141
"Batch Matrix Multiply (NC, F32) GEMM",2,83.728,21.0867%,78.0467%,0,56
"Transpose (ND, X32) Transpose",4,69.901,17.6044%,95.6511%,0,112
Multiply (ND),27,6.118,1.5408%,97.1919%,0,537
"Slice (ND, X32)",14,2.613,0.658077%,97.85%,0,196
Add (ND),10,2.223,0.559857%,98.4098%,0,197
Static Reshape (NC),18,1.469,0.369964%,98.7798%,0,338
EMBEDDING_LOOKUP,1,1.435,0.361401%,99.1412%,0,1
"Copy (NC, X32)",4,1.378,0.347046%,99.4883%,0,56
Subtract (ND),4,0.694,0.174782%,99.663%,0,56
"Softmax (NC, F32)",1,0.608,0.153123%,99.8162%,0,28
Sigmoid (NC),1,0.495,0.124664%,99.9408%,0,28
DYNAMIC_UPDATE_SLICE,56,0.14,0.0352586%,99.9761%,0,56
Sum (ND) Reduce,3,0.067,0.0168738%,99.993%,0,57
GATHER_ND,1,0.01,0.00251847%,99.9955%,0,1
REDUCE_ALL,1,0.003,0.000755542%,99.9962%,0,1
SELECT_V2,1,0.002,0.000503695%,99.9967%,0,1
RESHAPE,4,0.002,0.000503695%,99.9972%,0,4
PACK,1,0.002,0.000503695%,99.9977%,0,1
LESS,1,0.002,0.000503695%,99.9982%,0,1
ADD,1,0.002,0.000503695%,99.9987%,0,1
SELECT,1,0.001,0.000251847%,99.999%,0,1
LOGICAL_AND,1,0.001,0.000251847%,99.9992%,0,1
LESS_EQUAL,1,0.001,0.000251847%,99.9995%,0,1
GREATER_EQUAL,1,0.001,0.000251847%,99.9997%,0,1
CAST,2,0.001,0.000251847%,100%,0,2
Sine (NC),1,0,0%,100%,0,1
Reciprocal Square Root (NC),3,0,0%,100%,0,57
Cosine (NC),1,0,0%,100%,0,1

Timings (microseconds): count=32 first=783760 curr=380816 min=379261 max=783760 avg=397145 std=69731
Memory (bytes): count=0
172 nodes observed

Subgraph (index: 1, name: prefill_128) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.002,0.002,4.12529e-05%,4.12529e-05%,0,1,[arith.constant222]:0
EMBEDDING_LOOKUP,93.702,93.702,1.93274%,1.93278%,0,1,[arith.constant223]:1
CAST,0.23,0.23,0.00474408%,1.93752%,0,1,[arith.constant225]:3
LESS,0.035,0.035,0.000721925%,1.93825%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;1]:8
ADD,0.007,0.007,0.000144385%,1.93839%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;2]:9
SELECT,0.003,0.003,6.18793e-05%,1.93845%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;3]:10
RESHAPE,0.001,0.001,2.06264e-05%,1.93847%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;4]:11
CAST,0.001,0.001,2.06264e-05%,1.93849%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:12
GREATER_EQUAL,0.005,0.005,0.000103132%,1.9386%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:13
LESS_EQUAL,0.005,0.005,0.000103132%,1.9387%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:14
LOGICAL_AND,0.003,0.003,6.18793e-05%,1.93876%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:15
REDUCE_ALL,0.028,0.028,0.00057754%,1.93934%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:16
GATHER_ND,2.218,2.218,0.0457494%,1.98509%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17
RESHAPE,0.001,0.001,2.06264e-05%,1.98511%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:19
SLICE,0.004,0.004,8.25057e-05%,1.98519%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;18]:57
RESHAPE,0,0,0%,1.98519%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:58
PACK,0.004,0.004,8.25057e-05%,1.98527%,0,1,[tfl.pack]:59
Static Reshape (NC),0.437,0.437,0.00901375%,1.99429%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0.001,0.001,2.06264e-05%,1.99431%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.027,0.027,0.000556914%,1.99487%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.042,0.042,0.00086631%,1.99573%,0,1,Delegate/Cosine (NC):3
Sine (NC),0.04,0.04,0.000825057%,1.99656%,0,1,Delegate/Sine (NC):4
Static Reshape (NC),0.058,0.058,0.00119633%,1.99775%,0,1,Delegate/Static Reshape (NC):5
Multiply (ND),0.326,0.326,0.00672422%,2.00448%,0,1,Delegate/Multiply (ND):6
Sum (ND) Reduce,0.091,0.091,0.00187701%,2.00635%,0,1,Delegate/Sum (ND) Reduce:7
Multiply (ND),0.024,0.024,0.000495034%,2.00685%,0,1,Delegate/Multiply (ND):8
Add (ND),0.033,0.033,0.000680672%,2.00753%,0,1,Delegate/Add (ND):9
Static Reshape (NC),0,0.000285714,0.000165011%,2.00769%,0,28,Delegate/Static Reshape (NC):10
Reciprocal Square Root (NC),0.002,0.002,4.12529e-05%,2.00774%,0,1,Delegate/Reciprocal Square Root (NC):11
Multiply (ND),0.23,0.23,0.00474408%,2.01248%,0,1,Delegate/Multiply (ND):12
Multiply (ND),0.071,0.071,0.00146448%,2.01394%,0,1,Delegate/Multiply (ND):13
"Fully Connected (NC, QD8, F32, QC8W) GEMM",22.405,22.405,0.462135%,2.47608%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
Static Reshape (NC),0.277,0.00992857,0.00573415%,2.48181%,0,28,Delegate/Static Reshape (NC):15
"Slice (ND, X32)",0.296,0.296,0.00610543%,2.48792%,0,1,Delegate/Slice (ND	 X32):16
"Slice (ND, X32)",0.139,0.139,0.00286707%,2.49079%,0,1,Delegate/Slice (ND	 X32):17
"Slice (ND, X32)",0.112,0.112,0.00231016%,2.4931%,0,1,Delegate/Slice (ND	 X32):18
Static Reshape (NC),0,0,0%,2.4931%,0,1,Delegate/Static Reshape (NC):19
"Transpose (ND, X32) Transpose",0.488,0.488,0.0100657%,2.50316%,0,1,Delegate/Transpose (ND	 X32) Transpose:20
"Slice (ND, X32)",0.172,0.172,0.00354775%,2.50671%,0,1,Delegate/Slice (ND	 X32):21
"Slice (ND, X32)",0.158,0.158,0.00325898%,2.50997%,0,1,Delegate/Slice (ND	 X32):22
Multiply (ND),0.19,0.19,0.00391902%,2.51389%,0,1,Delegate/Multiply (ND):23
Multiply (ND),0.114,0.122107,0.0705218%,2.58441%,0,28,Delegate/Multiply (ND):24
Subtract (ND),0.104,0.104,0.00214515%,2.58656%,0,1,Delegate/Subtract (ND):25
Multiply (ND),0.071,0.071,0.00146448%,2.58802%,0,1,Delegate/Multiply (ND):26
Multiply (ND),0.113,0.113,0.00233079%,2.59035%,0,1,Delegate/Multiply (ND):27
Add (ND),0.068,0.068,0.0014026%,2.59175%,0,1,Delegate/Add (ND):28
"Copy (NC, X32)",0.412,0.412,0.00849809%,2.60025%,0,1,Delegate/Copy (NC	 X32):29
"Transpose (ND, X32) Transpose",0.396,0.396,0.00816807%,2.60842%,0,1,Delegate/Transpose (ND	 X32) Transpose:30
"Transpose (ND, X32) Transpose",0.107,0.107,0.00220703%,2.61063%,0,1,Delegate/Transpose (ND	 X32) Transpose:31
"Slice (ND, X32)",0.053,0.053,0.0010932%,2.61172%,0,1,Delegate/Slice (ND	 X32):32
"Slice (ND, X32)",0.027,0.027,0.000556914%,2.61228%,0,1,Delegate/Slice (ND	 X32):33
Multiply (ND),0.024,0.024,0.000495034%,2.61277%,0,1,Delegate/Multiply (ND):34
Multiply (ND),0.034,0.0260357,0.0150367%,2.62781%,0,28,Delegate/Multiply (ND):35
Subtract (ND),0.022,0.022,0.000453782%,2.62826%,0,1,Delegate/Subtract (ND):36
Multiply (ND),0.03,0.03,0.000618793%,2.62888%,0,1,Delegate/Multiply (ND):37
Multiply (ND),0.043,0.043,0.000886937%,2.62977%,0,1,Delegate/Multiply (ND):38
Add (ND),0.041,0.041,0.000845684%,2.63061%,0,1,Delegate/Add (ND):39
"Copy (NC, X32)",0.107,0.107,0.00220703%,2.63282%,0,1,Delegate/Copy (NC	 X32):40
"Transpose (ND, X32) Transpose",0.052,0.052,0.00107257%,2.63389%,0,1,Delegate/Transpose (ND	 X32) Transpose:41
SELECT_V2,0.315,0.315,0.00649733%,2.64039%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:20
DYNAMIC_UPDATE_SLICE,0.124,0.124,0.00255768%,2.64295%,0,1,[StatefulPartitionedCall:0]:60
DYNAMIC_UPDATE_SLICE,0.126,0.126,0.00259893%,2.64555%,0,1,[StatefulPartitionedCall:28]:61
Multiply (ND),0.227,0.212667,0.118437%,2.76398%,0,27,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.242,0.255556,0.142322%,2.90631%,0,27,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",1.145,1.1257,0.62692%,3.53323%,0,27,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0.001,7.40741e-05,4.12529e-05%,3.53327%,0,27,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,3.7037e-05,2.06264e-05%,3.53329%,0,27,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",10.51,10.4731,5.83262%,9.36591%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,7.40741e-05,4.12529e-05%,9.36595%,0,27,Delegate/Static Reshape (NC):6
Add (ND),2.159,2.18063,1.21442%,10.5804%,0,27,Delegate/Add (ND):7
"Softmax (NC, F32)",2.093,2.13241,1.18757%,11.7679%,0,27,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.821,1.83644,1.02274%,12.7907%,0,27,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0,0%,12.7907%,0,27,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",10.259,10.3534,5.76598%,18.5567%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Static Reshape (NC),0,3.7037e-05,2.06264e-05%,18.5567%,0,27,Delegate/Static Reshape (NC):13
"Transpose (ND, X32) Transpose",0.249,0.244074,0.135928%,18.6926%,0,27,Delegate/Transpose (ND	 X32) Transpose:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.484,10.5979,5.90211%,24.5947%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.346,0.289667,0.161319%,24.756%,0,27,Delegate/Add (ND):17
Multiply (ND),0.124,0.14163,0.0788755%,24.8349%,0,27,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.109,0.0969259,0.0539794%,24.8889%,0,27,Delegate/Sum (ND) Reduce:19
Multiply (ND),0.023,0.0242963,0.0135309%,24.9024%,0,27,Delegate/Multiply (ND):20
Add (ND),0.018,0.0163333,0.00909626%,24.9115%,0,27,Delegate/Add (ND):21
Static Reshape (NC),0,0,0%,24.9115%,0,27,Delegate/Static Reshape (NC):22
Reciprocal Square Root (NC),0,0.00196296,0.0010932%,24.9126%,0,27,Delegate/Reciprocal Square Root (NC):23
Multiply (ND),0.179,0.164556,0.0916433%,25.0043%,0,27,Delegate/Multiply (ND):25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.645,25.522,14.2135%,39.2178%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
Sigmoid (NC),0.64,0.625333,0.348257%,39.566%,0,27,Delegate/Sigmoid (NC):27
Multiply (ND),0.902,0.923519,0.51432%,40.0804%,0,27,Delegate/Multiply (ND):28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.322,25.5453,14.2265%,54.3069%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
Multiply (ND),0.931,0.91437,0.509225%,54.8161%,0,27,Delegate/Multiply (ND):30
"Fully Connected (NC, QD8, F32, QC8W) GEMM",67.304,60.0771,33.4578%,88.2739%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
Add (ND),0.272,0.272333,0.151666%,88.4256%,0,27,Delegate/Add (ND):32
Multiply (ND),0.1,0.127519,0.0710168%,88.4966%,0,27,Delegate/Multiply (ND):33
Sum (ND) Reduce,0.069,0.0855556,0.0476471%,88.5442%,0,27,Delegate/Sum (ND) Reduce:34
Add (ND),0.032,0.0162593,0.00905501%,88.5533%,0,27,Delegate/Add (ND):36
Static Reshape (NC),0,0,0%,88.5533%,0,27,Delegate/Static Reshape (NC):37
Reciprocal Square Root (NC),0.001,0.000740741,0.000412529%,88.5537%,0,27,Delegate/Reciprocal Square Root (NC):38
Multiply (ND),0.229,0.196852,0.10963%,88.6633%,0,27,Delegate/Multiply (ND):39
Multiply (ND),0.069,0.0953333,0.0530924%,88.7164%,0,27,Delegate/Multiply (ND):40
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.996,16.6022,9.24601%,97.9624%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
Static Reshape (NC),0.288,0.295963,0.164826%,98.1272%,0,27,Delegate/Static Reshape (NC):42
"Slice (ND, X32)",0.286,0.279481,0.155647%,98.2829%,0,27,Delegate/Slice (ND	 X32):43
"Slice (ND, X32)",0.174,0.156963,0.0874148%,98.3703%,0,27,Delegate/Slice (ND	 X32):44
"Slice (ND, X32)",0.126,0.119808,0.0642514%,98.4346%,0,26,Delegate/Slice (ND	 X32):45
Static Reshape (NC),0,7.69231e-05,4.12529e-05%,98.4346%,0,26,Delegate/Static Reshape (NC):46
"Transpose (ND, X32) Transpose",0.459,0.451538,0.242154%,98.6768%,0,26,Delegate/Transpose (ND	 X32) Transpose:47
"Slice (ND, X32)",0.216,0.212,0.113693%,98.7904%,0,26,Delegate/Slice (ND	 X32):48
"Slice (ND, X32)",0.204,0.182846,0.0980581%,98.8885%,0,26,Delegate/Slice (ND	 X32):49
Multiply (ND),0.191,0.1785,0.0957273%,98.9842%,0,26,Delegate/Multiply (ND):50
Multiply (ND),0.133,0.119926,0.0667884%,99.051%,0,27,Delegate/Multiply (ND):51
Subtract (ND),0.056,0.0594231,0.0318678%,99.0829%,0,26,Delegate/Subtract (ND):52
Multiply (ND),0.061,0.064,0.0343224%,99.1172%,0,26,Delegate/Multiply (ND):53
Multiply (ND),0.111,0.125038,0.0670565%,99.1843%,0,26,Delegate/Multiply (ND):54
Add (ND),0.057,0.0663846,0.0356012%,99.2199%,0,26,Delegate/Add (ND):55
"Copy (NC, X32)",0.444,0.445462,0.238895%,99.4588%,0,26,Delegate/Copy (NC	 X32):56
"Transpose (ND, X32) Transpose",0.305,0.265385,0.142322%,99.6011%,0,26,Delegate/Transpose (ND	 X32) Transpose:57
"Transpose (ND, X32) Transpose",0.14,0.140846,0.075534%,99.6766%,0,26,Delegate/Transpose (ND	 X32) Transpose:58
"Slice (ND, X32)",0.063,0.0613846,0.0329198%,99.7095%,0,26,Delegate/Slice (ND	 X32):59
"Slice (ND, X32)",0.037,0.0332308,0.0178212%,99.7274%,0,26,Delegate/Slice (ND	 X32):60
Multiply (ND),0.044,0.0414231,0.0222147%,99.7496%,0,26,Delegate/Multiply (ND):61
Multiply (ND),0.04,0.0418462,0.0224416%,99.772%,0,26,Delegate/Multiply (ND):62
Subtract (ND),0.017,0.0222692,0.0119427%,99.784%,0,26,Delegate/Subtract (ND):63
Multiply (ND),0.027,0.0249615,0.0133866%,99.7973%,0,26,Delegate/Multiply (ND):64
Multiply (ND),0.025,0.0301154,0.0161505%,99.8135%,0,26,Delegate/Multiply (ND):65
Add (ND),0.02,0.0222308,0.0119221%,99.8254%,0,26,Delegate/Add (ND):66
"Copy (NC, X32)",0.088,0.0856538,0.0459351%,99.8714%,0,26,Delegate/Copy (NC	 X32):67
"Transpose (ND, X32) Transpose",0.13,0.0555769,0.0298052%,99.9012%,0,26,Delegate/Transpose (ND	 X32) Transpose:68
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144385%,99.9026%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:117
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9044%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:118
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144385%,99.9058%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:174
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9076%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:175
DYNAMIC_UPDATE_SLICE,0.08,0.08,0.00165011%,99.9092%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:231
DYNAMIC_UPDATE_SLICE,0.092,0.092,0.00189763%,99.9111%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:232
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138197%,99.9125%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:288
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177387%,99.9143%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:289
DYNAMIC_UPDATE_SLICE,0.066,0.066,0.00136134%,99.9156%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:345
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9174%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:346
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138197%,99.9188%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:402
DYNAMIC_UPDATE_SLICE,0.08,0.08,0.00165011%,99.9204%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6;1]:403
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.0014026%,99.9218%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:459
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177387%,99.9236%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:460
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.0014026%,99.925%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;4]:516
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9267%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;5]:517
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.0014851%,99.9282%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:573
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017945%,99.93%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;1]:574
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144385%,99.9315%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:630
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177387%,99.9332%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:631
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.0014851%,99.9347%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;4]:687
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017945%,99.9365%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;5]:688
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144385%,99.938%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:744
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9397%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;6]:745
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142322%,99.9411%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;3]:801
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173262%,99.9429%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;7]:802
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.0014026%,99.9443%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;9]:858
DYNAMIC_UPDATE_SLICE,0.083,0.083,0.00171199%,99.946%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;10]:859
DYNAMIC_UPDATE_SLICE,0.065,0.065,0.00134072%,99.9473%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;12]:915
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00181513%,99.9491%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;]:916
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142322%,99.9506%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;13]:972
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177387%,99.9523%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:973
DYNAMIC_UPDATE_SLICE,0.078,0.078,0.00160886%,99.9539%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;14]:1029
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00181513%,99.9558%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;15]:1030
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00150573%,99.9573%,0,1,[StatefulPartitionedCall:11]:1086
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00181513%,99.9591%,0,1,[StatefulPartitionedCall:39]:1087
DYNAMIC_UPDATE_SLICE,0.076,0.076,0.00156761%,99.9606%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:1143
DYNAMIC_UPDATE_SLICE,0.091,0.091,0.00187701%,99.9625%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1144
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146448%,99.964%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:1200
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9657%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1201
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138197%,99.9671%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:1257
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173262%,99.9689%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:1258
DYNAMIC_UPDATE_SLICE,0.074,0.074,0.00152636%,99.9704%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:1314
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177387%,99.9722%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1315
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144385%,99.9736%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:1371
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175325%,99.9753%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1372
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00150573%,99.9769%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1428
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173262%,99.9786%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25;1]:1429
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146448%,99.9801%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1485
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017945%,99.9818%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:1486
DYNAMIC_UPDATE_SLICE,0.097,0.097,0.00200076%,99.9838%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;4]:1542
DYNAMIC_UPDATE_SLICE,0.093,0.093,0.00191826%,99.9858%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;5]:1543
"Transpose (ND, X32) Transpose",0.116,0.116,0.00239267%,99.9882%,0,1,Delegate/Transpose (ND	 X32) Transpose:45
"Slice (ND, X32)",0.066,0.066,0.00136134%,99.9895%,0,1,Delegate/Slice (ND	 X32):46
"Slice (ND, X32)",0.035,0.035,0.000721925%,99.9902%,0,1,Delegate/Slice (ND	 X32):47
Multiply (ND),0.057,0.057,0.00117571%,99.9914%,0,1,Delegate/Multiply (ND):48
Multiply (ND),0.049,0.049,0.0010107%,99.9924%,0,1,Delegate/Multiply (ND):49
Subtract (ND),0.016,0.016,0.000330023%,99.9928%,0,1,Delegate/Subtract (ND):50
Multiply (ND),0.034,0.034,0.000701299%,99.9935%,0,1,Delegate/Multiply (ND):52
Add (ND),0.024,0.024,0.000495034%,99.994%,0,1,Delegate/Add (ND):53
"Copy (NC, X32)",0.102,0.102,0.0021039%,99.9961%,0,1,Delegate/Copy (NC	 X32):54
"Transpose (ND, X32) Transpose",0.039,0.039,0.000804431%,99.9969%,0,1,Delegate/Transpose (ND	 X32) Transpose:55
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146448%,99.9983%,0,1,[Unknown]:1586
DYNAMIC_UPDATE_SLICE,0.081,0.081,0.00167074%,100%,0,1,[Unknown]:1587

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
EMBEDDING_LOOKUP,93.702,93.702,1.93274%,1.93274%,0,1,[arith.constant223]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",67.304,60.0771,33.4578%,35.3905%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.322,25.5453,14.2265%,49.617%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.645,25.522,14.2135%,63.8306%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
"Fully Connected (NC, QD8, F32, QC8W) GEMM",22.405,22.405,0.462135%,64.2927%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.996,16.6022,9.24601%,73.5387%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.484,10.5979,5.90211%,79.4408%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
"Batch Matrix Multiply (NC, F32) GEMM",10.51,10.4731,5.83262%,85.2734%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
"Batch Matrix Multiply (NC, F32) GEMM",10.259,10.3534,5.76598%,91.0394%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
GATHER_ND,2.218,2.218,0.0457494%,91.0852%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17

Number of nodes executed: 191
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,3757.71,77.5081%,77.5081%,0,136
"Batch Matrix Multiply (NC, F32) GEMM",2,562.317,11.5986%,89.1067%,0,54
"Transpose (ND, X32) Transpose",14,118.413,2.44244%,91.5491%,0,218
Multiply (ND),33,97.448,2.01%,93.5591%,0,522
EMBEDDING_LOOKUP,1,93.702,1.93274%,95.4919%,0,1
Add (ND),11,77.401,1.59651%,97.0884%,0,191
"Softmax (NC, F32)",1,57.575,1.18757%,98.2759%,0,27
"Slice (ND, X32)",16,28.683,0.591628%,98.8676%,0,193
Sigmoid (NC),1,16.884,0.348257%,99.2158%,0,27
"Copy (NC, X32)",5,14.43,0.297639%,99.5135%,0,55
Static Reshape (NC),15,8.781,0.181121%,99.6946%,0,302
Sum (ND) Reduce,3,5.018,0.103503%,99.7981%,0,55
DYNAMIC_UPDATE_SLICE,56,4.504,0.0929015%,99.891%,0,56
Subtract (ND),5,2.266,0.0467395%,99.9377%,0,55
GATHER_ND,1,2.218,0.0457494%,99.9835%,0,1
SELECT_V2,1,0.315,0.00649733%,99.99%,0,1
CAST,2,0.231,0.00476471%,99.9947%,0,2
Reciprocal Square Root (NC),3,0.075,0.00154698%,99.9963%,0,55
Cosine (NC),1,0.042,0.00086631%,99.9972%,0,1
Sine (NC),1,0.04,0.000825058%,99.998%,0,1
LESS,1,0.035,0.000721925%,99.9987%,0,1
REDUCE_ALL,1,0.028,0.00057754%,99.9993%,0,1
ADD,1,0.007,0.000144385%,99.9994%,0,1
LESS_EQUAL,1,0.005,0.000103132%,99.9995%,0,1
GREATER_EQUAL,1,0.005,0.000103132%,99.9996%,0,1
SLICE,1,0.004,8.25058e-05%,99.9997%,0,1
RESHAPE,4,0.004,8.25058e-05%,99.9998%,0,4
PACK,1,0.004,8.25058e-05%,99.9999%,0,1
SELECT,1,0.003,6.18793e-05%,100%,0,1
LOGICAL_AND,1,0.003,6.18793e-05%,100%,0,1

Subgraph (index: 1, name: prefill_128) Timings (microseconds): count=1 curr=4848147
Memory (bytes): count=0
191 nodes observed


