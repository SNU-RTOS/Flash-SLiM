Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

Number of nodes executed: 0
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called

Timings (microseconds): count=0
Memory (bytes): count=0
0 nodes observed


Operator-wise Profiling Info for Regular Benchmark Runs:
Primary graph (name: decode) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.004,0.00240625,0.000618178%,0.000618178%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;]:0
EMBEDDING_LOOKUP,0.006,1.46184,0.375555%,0.376174%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
CAST,0.002,0.00134375,0.000345216%,0.376519%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;]:3
LESS,0.002,0.00240625,0.000618178%,0.377137%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:8
ADD,0.002,0.00240625,0.000618178%,0.377755%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:9
SELECT,0.002,0.00140625,0.000361273%,0.378116%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:10
RESHAPE,0,0.0001875,4.81697e-05%,0.378165%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:11
CAST,0.001,0.0004375,0.000112396%,0.378277%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:12
GREATER_EQUAL,0.001,0.00109375,0.00028099%,0.378558%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:13
LESS_EQUAL,0.002,0.0011875,0.000305075%,0.378863%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;11]:14
LOGICAL_AND,0.001,0.00115625,0.000297047%,0.37916%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:15
REDUCE_ALL,0.004,0.00375,0.000963395%,0.380123%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:16
GATHER_ND,0.003,0.0426875,0.0109666%,0.39109%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;14]:17
RESHAPE,0,0.000125,3.21132e-05%,0.391122%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;15]:18
SELECT_V2,0.005,0.00246875,0.000634235%,0.391756%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;16]:19
RESHAPE,0,0.0001875,4.81697e-05%,0.391805%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:54
PACK,0.003,0.00215625,0.000553952%,0.392359%,0,1,[tfl.pack]:55
Static Reshape (NC),0.024,0.204313,0.052489%,0.444848%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0,0.000125,3.21132e-05%,0.44488%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.015,0.116,0.029801%,0.474681%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.001,0.00075,0.000192679%,0.474873%,0,1,Delegate/Cosine (NC):3
Sine (NC),0,0.00015625,4.01414e-05%,0.474913%,0,1,Delegate/Sine (NC):4
Multiply (ND),0.013,0.103438,0.0265736%,0.501487%,0,1,Delegate/Multiply (ND):5
Sum (ND) Reduce,0.001,0.0011875,0.000305075%,0.501792%,0,1,Delegate/Sum (ND) Reduce:6
Multiply (ND),0.001,0.00015625,4.01414e-05%,0.501832%,0,1,Delegate/Multiply (ND):7
Add (ND),0,3.125e-05,8.02829e-06%,0.50184%,0,1,Delegate/Add (ND):8
Reciprocal Square Root (NC),0,3.125e-05,8.02829e-06%,0.501848%,0,1,Delegate/Reciprocal Square Root (NC):9
Multiply (ND),0.012,0.119281,0.030644%,0.532492%,0,1,Delegate/Multiply (ND):10
Multiply (ND),0.007,0.145844,0.037468%,0.56996%,0,1,Delegate/Multiply (ND):11
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.148,1.14562,0.294317%,0.864277%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
Static Reshape (NC),0.016,0.00363578,0.0270874%,0.891365%,0,29,Delegate/Static Reshape (NC):13
"Slice (ND, X32)",0.012,0.0907188,0.0233061%,0.914671%,0,1,Delegate/Slice (ND	 X32):14
"Slice (ND, X32)",0.011,0.124281,0.0319285%,0.9466%,0,1,Delegate/Slice (ND	 X32):15
"Slice (ND, X32)",0.023,0.12875,0.0330766%,0.979676%,0,1,Delegate/Slice (ND	 X32):16
Static Reshape (NC),0.011,0.108469,0.0278662%,1.00754%,0,1,Delegate/Static Reshape (NC):17
"Slice (ND, X32)",0.012,0.119906,0.0308045%,1.03835%,0,1,Delegate/Slice (ND	 X32):18
"Slice (ND, X32)",0.011,0.0918125,0.0235871%,1.06193%,0,1,Delegate/Slice (ND	 X32):19
Multiply (ND),0.011,0.00276724,0.0206166%,1.08255%,0,29,Delegate/Multiply (ND):20
Multiply (ND),0.01,0.0598438,0.0153742%,1.09792%,0,1,Delegate/Multiply (ND):21
Subtract (ND),0.01,0.0575937,0.0147961%,1.11272%,0,1,Delegate/Subtract (ND):22
Multiply (ND),0.01,0.0176175,0.131255%,1.24398%,0,29,Delegate/Multiply (ND):23
Multiply (ND),0.01,0.0131961,0.0983144%,1.34229%,0,29,Delegate/Multiply (ND):24
Add (ND),0.01,0.05875,0.0150932%,1.35738%,0,1,Delegate/Add (ND):25
"Copy (NC, X32)",0.021,0.128062,0.0328999%,1.39028%,0,1,Delegate/Copy (NC	 X32):26
Static Reshape (NC),0.006,0.0744062,0.0191154%,1.4094%,0,1,Delegate/Static Reshape (NC):27
Static Reshape (NC),0,0.00021875,5.6198e-05%,1.40945%,0,1,Delegate/Static Reshape (NC):28
"Slice (ND, X32)",0.01,0.0750625,0.019284%,1.42874%,0,1,Delegate/Slice (ND	 X32):29
"Slice (ND, X32)",0.012,0.0680313,0.0174776%,1.44622%,0,1,Delegate/Slice (ND	 X32):30
Multiply (ND),0.01,0.0703125,0.0180637%,1.46428%,0,1,Delegate/Multiply (ND):31
Multiply (ND),0.01,0.0160808,0.119806%,1.58409%,0,29,Delegate/Multiply (ND):32
Subtract (ND),0.01,0.0611563,0.0157114%,1.5998%,0,1,Delegate/Subtract (ND):33
Multiply (ND),0.011,0.00226401,0.0168674%,1.61666%,0,29,Delegate/Multiply (ND):34
Multiply (ND),0.01,0.109625,0.0281632%,1.64483%,0,1,Delegate/Multiply (ND):35
Add (ND),0.01,0.0853437,0.0219253%,1.66675%,0,1,Delegate/Add (ND):36
"Copy (NC, X32)",0.02,0.145813,0.03746%,1.70421%,0,1,Delegate/Copy (NC	 X32):37
Static Reshape (NC),0,0.0001875,4.81697e-05%,1.70426%,0,1,Delegate/Static Reshape (NC):38
DYNAMIC_UPDATE_SLICE,0.004,0.0038125,0.000979451%,1.70524%,0,1,[StatefulPartitionedCall:0]:56
DYNAMIC_UPDATE_SLICE,0.002,0.00153125,0.000393386%,1.70563%,0,1,[StatefulPartitionedCall:28]:57
Multiply (ND),0.007,0.0165469,0.119027%,1.82466%,0,28,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.001,0.000986607,0.00709701%,1.83176%,0,28,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",0.875,0.843128,6.06492%,7.89667%,0,28,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000262277,0.00188665%,7.89856%,0,28,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,5.58036e-06,4.01414e-05%,7.8986%,0,28,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",1.401,1.39711,10.0499%,17.9485%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,2.23214e-05,0.000160566%,17.9487%,0,28,Delegate/Static Reshape (NC):6
Add (ND),0.016,0.0240246,0.172817%,18.1215%,0,28,Delegate/Add (ND):7
"Softmax (NC, F32)",0.017,0.0238069,0.171251%,18.2927%,0,28,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.348,1.45112,10.4384%,28.7312%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0.001,0.000243304,0.00175017%,28.7329%,0,28,Delegate/Static Reshape (NC):10
Static Reshape (NC),0,6.69643e-06,4.81697e-05%,28.733%,0,28,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",1.384,1.39838,10.059%,38.792%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Transpose (ND, X32) Transpose",0.002,0.00159487,0.0114724%,38.8035%,0,28,Delegate/Transpose (ND	 X32) Transpose:14
Static Reshape (NC),0,2.23214e-06,1.60566e-05%,38.8035%,0,28,Delegate/Static Reshape (NC):15
"Fully Connected (NC, QD8, F32, QC8W) GEMM",0.675,0.664606,4.78074%,43.5842%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.018,0.0162098,0.116603%,43.7008%,0,28,Delegate/Add (ND):17
Multiply (ND),0.013,0.0139542,0.100378%,43.8012%,0,28,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.001,0.00135379,0.00973832%,43.811%,0,28,Delegate/Sum (ND) Reduce:19
Add (ND),0,1.33929e-05,9.63395e-05%,43.8111%,0,28,Delegate/Add (ND):21
Reciprocal Square Root (NC),0,5.58036e-06,4.01414e-05%,43.8111%,0,28,Delegate/Reciprocal Square Root (NC):22
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.659,1.6956,12.197%,56.0081%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
Sigmoid (NC),0.019,0.0215614,0.155099%,56.1632%,0,28,Delegate/Sigmoid (NC):26
Multiply (ND),0.01,0.0131429,0.0945411%,56.2578%,0,28,Delegate/Multiply (ND):27
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.65,1.69035,12.1592%,68.417%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
Multiply (ND),0.011,0.0183705,0.132146%,68.5492%,0,28,Delegate/Multiply (ND):29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.656,1.68067,12.0897%,80.6388%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
Add (ND),0.027,0.0189118,0.136039%,80.7749%,0,28,Delegate/Add (ND):31
Sum (ND) Reduce,0.001,0.00107589,0.00773927%,80.7826%,0,28,Delegate/Sum (ND) Reduce:33
Add (ND),0,1.22768e-05,8.83112e-05%,80.7827%,0,28,Delegate/Add (ND):35
Reciprocal Square Root (NC),0,6.69643e-06,4.81697e-05%,80.7827%,0,28,Delegate/Reciprocal Square Root (NC):36
Multiply (ND),0.013,0.0189933,0.136625%,80.9194%,0,28,Delegate/Multiply (ND):37
Multiply (ND),0.007,0.0114096,0.0820732%,81.0014%,0,28,Delegate/Multiply (ND):38
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.033,2.29552,16.5125%,97.5139%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
Static Reshape (NC),0.015,0.0191273,0.132676%,97.6466%,0,27,Delegate/Static Reshape (NC):40
"Slice (ND, X32)",0.012,0.0147361,0.102216%,97.7488%,0,27,Delegate/Slice (ND	 X32):41
"Slice (ND, X32)",0.011,0.0138831,0.0962993%,97.8451%,0,27,Delegate/Slice (ND	 X32):42
"Slice (ND, X32)",0.014,0.0131806,0.0914262%,97.9365%,0,27,Delegate/Slice (ND	 X32):43
Static Reshape (NC),0.012,0.0143368,0.0994464%,98.036%,0,27,Delegate/Static Reshape (NC):44
"Slice (ND, X32)",0.012,0.0140891,0.0977284%,98.1337%,0,27,Delegate/Slice (ND	 X32):45
"Slice (ND, X32)",0.011,0.0137211,0.0951754%,98.2289%,0,27,Delegate/Slice (ND	 X32):46
Multiply (ND),0.011,0.0146215,0.101421%,98.3303%,0,27,Delegate/Multiply (ND):47
Multiply (ND),0.01,0.0139572,0.0968131%,98.4271%,0,27,Delegate/Multiply (ND):48
Subtract (ND),0.01,0.0132894,0.0921808%,98.5193%,0,27,Delegate/Subtract (ND):49
Multiply (ND),0.01,0.0127674,0.0885601%,98.6078%,0,27,Delegate/Multiply (ND):50
Multiply (ND),0.011,0.0122581,0.0850276%,98.6929%,0,27,Delegate/Multiply (ND):51
Add (ND),0.011,0.0123322,0.0855414%,98.7784%,0,27,Delegate/Add (ND):52
"Copy (NC, X32)",0.02,0.0249606,0.173138%,98.9516%,0,27,Delegate/Copy (NC	 X32):53
Static Reshape (NC),0.011,0.0125093,0.0867698%,99.0383%,0,27,Delegate/Static Reshape (NC):54
Static Reshape (NC),0,4.39815e-05,0.000305075%,99.0386%,0,27,Delegate/Static Reshape (NC):55
"Slice (ND, X32)",0.011,0.013441,0.0932325%,99.1319%,0,27,Delegate/Slice (ND	 X32):56
"Slice (ND, X32)",0.01,0.0136412,0.0946214%,99.2265%,0,27,Delegate/Slice (ND	 X32):57
Multiply (ND),0.011,0.0132604,0.0919801%,99.3185%,0,27,Delegate/Multiply (ND):58
Multiply (ND),0.011,0.0128414,0.0890739%,99.4075%,0,27,Delegate/Multiply (ND):59
Subtract (ND),0.011,0.012184,0.0845138%,99.4921%,0,27,Delegate/Subtract (ND):60
Multiply (ND),0.01,0.0126076,0.0874522%,99.5795%,0,27,Delegate/Multiply (ND):61
Multiply (ND),0.011,0.0131609,0.0912897%,99.6708%,0,27,Delegate/Multiply (ND):62
Add (ND),0.01,0.013191,0.0914984%,99.7623%,0,27,Delegate/Add (ND):63
"Copy (NC, X32)",0.02,0.0281806,0.195473%,99.9578%,0,27,Delegate/Copy (NC	 X32):64
Static Reshape (NC),0,4.16667e-05,0.000289018%,99.958%,0,27,Delegate/Static Reshape (NC):65
DYNAMIC_UPDATE_SLICE,0.006,0.00496875,0.0012765%,99.9593%,0,1,[StatefulPartitionedCall:1]:110
DYNAMIC_UPDATE_SLICE,0.001,0.001375,0.000353245%,99.9597%,0,1,[StatefulPartitionedCall:29]:111
DYNAMIC_UPDATE_SLICE,0.005,0.00503125,0.00129255%,99.961%,0,1,[StatefulPartitionedCall:12]:164
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000337188%,99.9613%,0,1,[StatefulPartitionedCall:40]:165
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00119622%,99.9625%,0,1,[StatefulPartitionedCall:21]:218
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000297047%,99.9628%,0,1,[StatefulPartitionedCall:49]:219
DYNAMIC_UPDATE_SLICE,0.005,0.00478125,0.00122833%,99.964%,0,1,[StatefulPartitionedCall:22]:272
DYNAMIC_UPDATE_SLICE,0.002,0.00115625,0.000297047%,99.9643%,0,1,[StatefulPartitionedCall:50]:273
DYNAMIC_UPDATE_SLICE,0.004,0.00471875,0.00121227%,99.9655%,0,1,[StatefulPartitionedCall:23]:326
DYNAMIC_UPDATE_SLICE,0.002,0.0013125,0.000337188%,99.9659%,0,1,[StatefulPartitionedCall:51]:327
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00117213%,99.967%,0,1,[StatefulPartitionedCall:24]:380
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.000305075%,99.9674%,0,1,[StatefulPartitionedCall:52]:381
DYNAMIC_UPDATE_SLICE,0.004,0.0045625,0.00117213%,99.9685%,0,1,[StatefulPartitionedCall:25]:434
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000337188%,99.9689%,0,1,[StatefulPartitionedCall:53]:435
DYNAMIC_UPDATE_SLICE,0.005,0.00471875,0.00121227%,99.9701%,0,1,[StatefulPartitionedCall:26]:488
DYNAMIC_UPDATE_SLICE,0.001,0.001375,0.000353245%,99.9704%,0,1,[StatefulPartitionedCall:54]:489
DYNAMIC_UPDATE_SLICE,0.005,0.00453125,0.0011641%,99.9716%,0,1,[StatefulPartitionedCall:27]:542
DYNAMIC_UPDATE_SLICE,0.001,0.001375,0.000353245%,99.972%,0,1,[StatefulPartitionedCall:55]:543
DYNAMIC_UPDATE_SLICE,0.005,0.00471875,0.00121227%,99.9732%,0,1,[StatefulPartitionedCall:2]:596
DYNAMIC_UPDATE_SLICE,0.002,0.00128125,0.00032916%,99.9735%,0,1,[StatefulPartitionedCall:30]:597
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00118016%,99.9747%,0,1,[StatefulPartitionedCall:3]:650
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000337188%,99.975%,0,1,[StatefulPartitionedCall:31]:651
DYNAMIC_UPDATE_SLICE,0.004,0.00459375,0.00118016%,99.9762%,0,1,[StatefulPartitionedCall:4]:704
DYNAMIC_UPDATE_SLICE,0.001,0.00134375,0.000345216%,99.9765%,0,1,[StatefulPartitionedCall:32]:705
DYNAMIC_UPDATE_SLICE,0.004,0.00465625,0.00119622%,99.9777%,0,1,[StatefulPartitionedCall:5]:758
DYNAMIC_UPDATE_SLICE,0.002,0.00146875,0.00037733%,99.9781%,0,1,[StatefulPartitionedCall:33]:759
DYNAMIC_UPDATE_SLICE,0.005,0.0048125,0.00123636%,99.9793%,0,1,[StatefulPartitionedCall:6]:812
DYNAMIC_UPDATE_SLICE,0.002,0.00125,0.000321132%,99.9797%,0,1,[StatefulPartitionedCall:34]:813
DYNAMIC_UPDATE_SLICE,0.005,0.005,0.00128453%,99.9809%,0,1,[StatefulPartitionedCall:7]:866
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000353245%,99.9813%,0,1,[StatefulPartitionedCall:35]:867
DYNAMIC_UPDATE_SLICE,0.006,0.00465625,0.00119622%,99.9825%,0,1,[StatefulPartitionedCall:8]:920
DYNAMIC_UPDATE_SLICE,0.001,0.00134375,0.000345216%,99.9828%,0,1,[StatefulPartitionedCall:36]:921
DYNAMIC_UPDATE_SLICE,0.005,0.00475,0.0012203%,99.9841%,0,1,[StatefulPartitionedCall:9]:974
DYNAMIC_UPDATE_SLICE,0.002,0.00146875,0.00037733%,99.9844%,0,1,[StatefulPartitionedCall:37]:975
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00117213%,99.9856%,0,1,[StatefulPartitionedCall:10]:1028
DYNAMIC_UPDATE_SLICE,0.001,0.00134375,0.000345216%,99.986%,0,1,[StatefulPartitionedCall:38]:1029
DYNAMIC_UPDATE_SLICE,0.005,0.004625,0.00118819%,99.9871%,0,1,[StatefulPartitionedCall:11]:1082
DYNAMIC_UPDATE_SLICE,0.001,0.00125,0.000321132%,99.9875%,0,1,[StatefulPartitionedCall:39]:1083
DYNAMIC_UPDATE_SLICE,0.005,0.004875,0.00125241%,99.9887%,0,1,[StatefulPartitionedCall:13]:1136
DYNAMIC_UPDATE_SLICE,0.002,0.0015625,0.000401414%,99.9891%,0,1,[StatefulPartitionedCall:41]:1137
DYNAMIC_UPDATE_SLICE,0.005,0.0048125,0.00123636%,99.9904%,0,1,[StatefulPartitionedCall:14]:1190
DYNAMIC_UPDATE_SLICE,0.001,0.001375,0.000353245%,99.9907%,0,1,[StatefulPartitionedCall:42]:1191
DYNAMIC_UPDATE_SLICE,0.006,0.00475,0.0012203%,99.9919%,0,1,[StatefulPartitionedCall:15]:1244
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000337188%,99.9923%,0,1,[StatefulPartitionedCall:43]:1245
DYNAMIC_UPDATE_SLICE,0.005,0.00475,0.0012203%,99.9935%,0,1,[StatefulPartitionedCall:16]:1298
DYNAMIC_UPDATE_SLICE,0.001,0.00128125,0.00032916%,99.9938%,0,1,[StatefulPartitionedCall:44]:1299
DYNAMIC_UPDATE_SLICE,0.004,0.004625,0.00118819%,99.995%,0,1,[StatefulPartitionedCall:17]:1352
DYNAMIC_UPDATE_SLICE,0.002,0.00146875,0.00037733%,99.9954%,0,1,[StatefulPartitionedCall:45]:1353
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00117213%,99.9966%,0,1,[StatefulPartitionedCall:18]:1406
DYNAMIC_UPDATE_SLICE,0.001,0.0014375,0.000369301%,99.9969%,0,1,[StatefulPartitionedCall:46]:1407
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00119622%,99.9981%,0,1,[StatefulPartitionedCall:19]:1460
DYNAMIC_UPDATE_SLICE,0.002,0.00146875,0.00037733%,99.9985%,0,1,[StatefulPartitionedCall:47]:1461
DYNAMIC_UPDATE_SLICE,0.004,0.004625,0.00118819%,99.9997%,0,1,[StatefulPartitionedCall:20]:1514
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000313103%,100%,0,1,[StatefulPartitionedCall:48]:1515

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.033,2.29552,16.5125%,16.5125%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.659,1.6956,12.197%,28.7095%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.65,1.69035,12.1592%,40.8687%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.656,1.68067,12.0897%,52.9584%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
EMBEDDING_LOOKUP,0.006,1.46184,0.375555%,53.334%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
"Transpose (ND, X32) Transpose",1.348,1.45112,10.4384%,63.7724%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
"Batch Matrix Multiply (NC, F32) GEMM",1.384,1.39838,10.059%,73.8315%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Batch Matrix Multiply (NC, F32) GEMM",1.401,1.39711,10.0499%,83.8813%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.148,1.14562,0.294317%,84.1757%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
"Transpose (ND, X32) Transpose",0.875,0.843128,6.06492%,90.2406%,0,28,Delegate/Transpose (ND	 X32) Transpose:2

Number of nodes executed: 172
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,225.89,58.0448%,58.0448%,0,141
"Batch Matrix Multiply (NC, F32) GEMM",2,78.273,20.1131%,78.1579%,0,56
"Transpose (ND, X32) Transpose",4,64.309,16.5249%,94.6827%,0,112
Multiply (ND),27,7.652,1.96626%,96.649%,0,537
"Slice (ND, X32)",14,3.301,0.848226%,97.4972%,0,196
Add (ND),10,2.485,0.638547%,98.1358%,0,197
Static Reshape (NC),18,1.746,0.448653%,98.5844%,0,338
"Copy (NC, X32)",4,1.706,0.438374%,99.0228%,0,56
EMBEDDING_LOOKUP,1,1.461,0.375419%,99.3982%,0,1
Subtract (ND),4,0.804,0.206596%,99.6048%,0,56
"Softmax (NC, F32)",1,0.666,0.171136%,99.7759%,0,28
Sigmoid (NC),1,0.603,0.154947%,99.9309%,0,28
DYNAMIC_UPDATE_SLICE,56,0.141,0.0362314%,99.9671%,0,56
Sum (ND) Reduce,3,0.068,0.0174733%,99.9846%,0,57
GATHER_ND,1,0.042,0.0107923%,99.9954%,0,1
REDUCE_ALL,1,0.003,0.000770881%,99.9962%,0,1
SELECT_V2,1,0.002,0.000513921%,99.9967%,0,1
RESHAPE,4,0.002,0.000513921%,99.9972%,0,4
PACK,1,0.002,0.000513921%,99.9977%,0,1
LESS,1,0.002,0.000513921%,99.9982%,0,1
ADD,1,0.002,0.000513921%,99.9987%,0,1
SELECT,1,0.001,0.00025696%,99.999%,0,1
LOGICAL_AND,1,0.001,0.00025696%,99.9992%,0,1
LESS_EQUAL,1,0.001,0.00025696%,99.9995%,0,1
GREATER_EQUAL,1,0.001,0.00025696%,99.9998%,0,1
CAST,2,0.001,0.00025696%,100%,0,2
Sine (NC),1,0,0%,100%,0,1
Reciprocal Square Root (NC),3,0,0%,100%,0,57
Cosine (NC),1,0,0%,100%,0,1

Timings (microseconds): count=32 first=772397 curr=390917 min=367165 max=772397 avg=389249 std=69739
Memory (bytes): count=0
172 nodes observed

Subgraph (index: 1, name: prefill_128) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.002,0.002,4.14466e-05%,4.14466e-05%,0,1,[arith.constant222]:0
EMBEDDING_LOOKUP,105.609,105.609,2.18857%,2.18861%,0,1,[arith.constant223]:1
CAST,0.224,0.224,0.00464202%,2.19325%,0,1,[arith.constant225]:3
LESS,0.033,0.033,0.000683869%,2.19393%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;1]:8
ADD,0.007,0.007,0.000145063%,2.19408%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;2]:9
SELECT,0.003,0.003,6.21699e-05%,2.19414%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;3]:10
RESHAPE,0.001,0.001,2.07233e-05%,2.19416%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;4]:11
CAST,0.002,0.002,4.14466e-05%,2.1942%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:12
GREATER_EQUAL,0.005,0.005,0.000103616%,2.19431%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:13
LESS_EQUAL,0.005,0.005,0.000103616%,2.19441%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:14
LOGICAL_AND,0.003,0.003,6.21699e-05%,2.19447%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:15
REDUCE_ALL,0.025,0.025,0.000518082%,2.19499%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:16
GATHER_ND,2.012,2.012,0.0416953%,2.23669%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17
RESHAPE,0.002,0.002,4.14466e-05%,2.23673%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:19
SLICE,0.004,0.004,8.28932e-05%,2.23681%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;18]:57
RESHAPE,0,0,0%,2.23681%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:58
PACK,0.004,0.004,8.28932e-05%,2.23689%,0,1,[tfl.pack]:59
Static Reshape (NC),0.331,0.331,0.00685941%,2.24375%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0.001,0.001,2.07233e-05%,2.24377%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.029,0.029,0.000600975%,2.24437%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.053,0.053,0.00109833%,2.24547%,0,1,Delegate/Cosine (NC):3
Sine (NC),0.047,0.047,0.000973995%,2.24645%,0,1,Delegate/Sine (NC):4
Static Reshape (NC),0.079,0.079,0.00163714%,2.24808%,0,1,Delegate/Static Reshape (NC):5
Multiply (ND),0.334,0.334,0.00692158%,2.255%,0,1,Delegate/Multiply (ND):6
Sum (ND) Reduce,0.116,0.116,0.0024039%,2.25741%,0,1,Delegate/Sum (ND) Reduce:7
Multiply (ND),0.318,0.318,0.00659001%,2.264%,0,1,Delegate/Multiply (ND):8
Add (ND),0.037,0.037,0.000766762%,2.26477%,0,1,Delegate/Add (ND):9
Static Reshape (NC),0,0.000178571,0.000103616%,2.26487%,0,28,Delegate/Static Reshape (NC):10
Reciprocal Square Root (NC),0.001,0.001,2.07233e-05%,2.26489%,0,1,Delegate/Reciprocal Square Root (NC):11
Multiply (ND),0.202,0.202,0.0041861%,2.26908%,0,1,Delegate/Multiply (ND):12
Multiply (ND),0.135,0.135,0.00279764%,2.27187%,0,1,Delegate/Multiply (ND):13
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.952,25.952,0.537811%,2.80968%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
Static Reshape (NC),0.263,0.00946429,0.00549167%,2.81518%,0,28,Delegate/Static Reshape (NC):15
"Slice (ND, X32)",0.249,0.249,0.0051601%,2.82034%,0,1,Delegate/Slice (ND	 X32):16
"Slice (ND, X32)",0.151,0.151,0.00312922%,2.82347%,0,1,Delegate/Slice (ND	 X32):17
"Slice (ND, X32)",0.098,0.098,0.00203088%,2.8255%,0,1,Delegate/Slice (ND	 X32):18
Static Reshape (NC),0,0,0%,2.8255%,0,1,Delegate/Static Reshape (NC):19
"Transpose (ND, X32) Transpose",0.394,0.394,0.00816498%,2.83366%,0,1,Delegate/Transpose (ND	 X32) Transpose:20
"Slice (ND, X32)",0.189,0.189,0.0039167%,2.83758%,0,1,Delegate/Slice (ND	 X32):21
"Slice (ND, X32)",0.152,0.152,0.00314994%,2.84073%,0,1,Delegate/Slice (ND	 X32):22
Multiply (ND),0.204,0.204,0.00422755%,2.84496%,0,1,Delegate/Multiply (ND):23
Multiply (ND),0.127,0.121036,0.0702312%,2.91519%,0,28,Delegate/Multiply (ND):24
Subtract (ND),0.075,0.075,0.00155425%,2.91674%,0,1,Delegate/Subtract (ND):25
Multiply (ND),0.074,0.074,0.00153352%,2.91827%,0,1,Delegate/Multiply (ND):26
Multiply (ND),0.125,0.125,0.00259041%,2.92086%,0,1,Delegate/Multiply (ND):27
Add (ND),0.06,0.06,0.0012434%,2.92211%,0,1,Delegate/Add (ND):28
"Copy (NC, X32)",0.428,0.428,0.00886957%,2.93098%,0,1,Delegate/Copy (NC	 X32):29
"Transpose (ND, X32) Transpose",0.273,0.273,0.00565746%,2.93664%,0,1,Delegate/Transpose (ND	 X32) Transpose:30
"Transpose (ND, X32) Transpose",0.12,0.12,0.00248679%,2.93912%,0,1,Delegate/Transpose (ND	 X32) Transpose:31
"Slice (ND, X32)",0.052,0.052,0.00107761%,2.9402%,0,1,Delegate/Slice (ND	 X32):32
"Slice (ND, X32)",0.031,0.031,0.000642422%,2.94084%,0,1,Delegate/Slice (ND	 X32):33
Multiply (ND),0.04,0.04,0.000828932%,2.94167%,0,1,Delegate/Multiply (ND):34
Multiply (ND),0.04,0.0232857,0.0135116%,2.95518%,0,28,Delegate/Multiply (ND):35
Subtract (ND),0.023,0.023,0.000476636%,2.95566%,0,1,Delegate/Subtract (ND):36
Multiply (ND),0.023,0.023,0.000476636%,2.95614%,0,1,Delegate/Multiply (ND):37
Multiply (ND),0.03,0.03,0.000621699%,2.95676%,0,1,Delegate/Multiply (ND):38
Add (ND),0.027,0.027,0.000559529%,2.95732%,0,1,Delegate/Add (ND):39
"Copy (NC, X32)",0.078,0.078,0.00161642%,2.95893%,0,1,Delegate/Copy (NC	 X32):40
"Transpose (ND, X32) Transpose",0.044,0.044,0.000911825%,2.95985%,0,1,Delegate/Transpose (ND	 X32) Transpose:41
SELECT_V2,0.235,0.235,0.00486997%,2.96472%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:20
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184437%,2.96656%,0,1,[StatefulPartitionedCall:0]:60
DYNAMIC_UPDATE_SLICE,0.094,0.094,0.00194799%,2.96851%,0,1,[StatefulPartitionedCall:28]:61
Multiply (ND),0.308,0.214222,0.119863%,3.08837%,0,27,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.223,0.252296,0.141167%,3.22954%,0,27,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",1.087,1.08533,0.607275%,3.83681%,0,27,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000296296,0.000165786%,3.83698%,0,27,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,3.7037e-05,2.07233e-05%,3.837%,0,27,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",10.283,10.2144,5.71523%,9.55223%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,0.000111111,6.21699e-05%,9.5523%,0,27,Delegate/Static Reshape (NC):6
Add (ND),1.927,1.90607,1.0665%,10.6188%,0,27,Delegate/Add (ND):7
"Softmax (NC, F32)",1.827,1.8547,1.03776%,11.6566%,0,27,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.62,1.74052,0.97387%,12.6304%,0,27,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0,0%,12.6304%,0,27,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",10.192,10.3003,5.76333%,18.3938%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Static Reshape (NC),0,0,0%,18.3938%,0,27,Delegate/Static Reshape (NC):13
"Transpose (ND, X32) Transpose",0.246,0.246444,0.137893%,18.5317%,0,27,Delegate/Transpose (ND	 X32) Transpose:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.404,10.6569,5.96282%,24.4945%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.332,0.284222,0.159031%,24.6535%,0,27,Delegate/Add (ND):17
Multiply (ND),0.104,0.129963,0.072718%,24.7262%,0,27,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.086,0.0911852,0.0510207%,24.7772%,0,27,Delegate/Sum (ND) Reduce:19
Multiply (ND),0.019,0.0223704,0.0125169%,24.7898%,0,27,Delegate/Multiply (ND):20
Add (ND),0.02,0.0148889,0.00833076%,24.7981%,0,27,Delegate/Add (ND):21
Static Reshape (NC),0,0,0%,24.7981%,0,27,Delegate/Static Reshape (NC):22
Reciprocal Square Root (NC),0.001,0.000740741,0.000414466%,24.7985%,0,27,Delegate/Reciprocal Square Root (NC):23
Multiply (ND),0.191,0.159667,0.0893381%,24.8878%,0,27,Delegate/Multiply (ND):25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.585,25.5308,14.2852%,39.1731%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
Sigmoid (NC),0.559,0.57163,0.319843%,39.4929%,0,27,Delegate/Sigmoid (NC):27
Multiply (ND),0.882,0.862148,0.482397%,39.9753%,0,27,Delegate/Multiply (ND):28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.607,25.819,14.4465%,54.4218%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
Multiply (ND),0.828,0.825556,0.461922%,54.8837%,0,27,Delegate/Multiply (ND):30
"Fully Connected (NC, QD8, F32, QC8W) GEMM",55.703,59.9659,33.5526%,88.4363%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
Add (ND),0.247,0.25737,0.144006%,88.5803%,0,27,Delegate/Add (ND):32
Multiply (ND),0.135,0.121296,0.0678688%,88.6482%,0,27,Delegate/Multiply (ND):33
Sum (ND) Reduce,0.072,0.0875556,0.0489899%,88.6972%,0,27,Delegate/Sum (ND) Reduce:34
Add (ND),0.014,0.0145926,0.00816498%,88.7054%,0,27,Delegate/Add (ND):36
Static Reshape (NC),0,0,0%,88.7054%,0,27,Delegate/Static Reshape (NC):37
Reciprocal Square Root (NC),0.001,0.000555556,0.000310849%,88.7057%,0,27,Delegate/Reciprocal Square Root (NC):38
Multiply (ND),0.287,0.200037,0.111926%,88.8176%,0,27,Delegate/Multiply (ND):39
Multiply (ND),0.072,0.0770741,0.0431252%,88.8607%,0,27,Delegate/Multiply (ND):40
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.471,16.542,9.25575%,98.1165%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
Static Reshape (NC),0.282,0.279259,0.156254%,98.2727%,0,27,Delegate/Static Reshape (NC):42
"Slice (ND, X32)",0.237,0.25863,0.144711%,98.4174%,0,27,Delegate/Slice (ND	 X32):43
"Slice (ND, X32)",0.135,0.145741,0.0815461%,98.499%,0,27,Delegate/Slice (ND	 X32):44
"Slice (ND, X32)",0.093,0.103923,0.0559943%,98.555%,0,26,Delegate/Slice (ND	 X32):45
Static Reshape (NC),0,7.69231e-05,4.14466e-05%,98.555%,0,26,Delegate/Static Reshape (NC):46
"Transpose (ND, X32) Transpose",0.389,0.395538,0.213118%,98.7682%,0,26,Delegate/Transpose (ND	 X32) Transpose:47
"Slice (ND, X32)",0.184,0.188808,0.101731%,98.8699%,0,26,Delegate/Slice (ND	 X32):48
"Slice (ND, X32)",0.144,0.146577,0.0789765%,98.9489%,0,26,Delegate/Slice (ND	 X32):49
Multiply (ND),0.147,0.155538,0.083805%,99.0327%,0,26,Delegate/Multiply (ND):50
Multiply (ND),0.174,0.119556,0.0668948%,99.0996%,0,27,Delegate/Multiply (ND):51
Subtract (ND),0.055,0.0587692,0.0316652%,99.1312%,0,26,Delegate/Subtract (ND):52
Multiply (ND),0.068,0.0623846,0.0336132%,99.1648%,0,26,Delegate/Multiply (ND):53
Multiply (ND),0.119,0.128808,0.0694023%,99.2342%,0,26,Delegate/Multiply (ND):54
Add (ND),0.054,0.0659615,0.0355404%,99.2698%,0,26,Delegate/Add (ND):55
"Copy (NC, X32)",0.386,0.405115,0.218278%,99.4881%,0,26,Delegate/Copy (NC	 X32):56
"Transpose (ND, X32) Transpose",0.215,0.232154,0.125086%,99.6131%,0,26,Delegate/Transpose (ND	 X32) Transpose:57
"Transpose (ND, X32) Transpose",0.15,0.138731,0.0747489%,99.6879%,0,26,Delegate/Transpose (ND	 X32) Transpose:58
"Slice (ND, X32)",0.056,0.0560769,0.0302146%,99.7181%,0,26,Delegate/Slice (ND	 X32):59
"Slice (ND, X32)",0.029,0.0361154,0.0194592%,99.7376%,0,26,Delegate/Slice (ND	 X32):60
Multiply (ND),0.042,0.0406538,0.0219045%,99.7595%,0,26,Delegate/Multiply (ND):61
Multiply (ND),0.038,0.0387308,0.0208684%,99.7803%,0,26,Delegate/Multiply (ND):62
Subtract (ND),0.017,0.0216154,0.0116465%,99.792%,0,26,Delegate/Subtract (ND):63
Multiply (ND),0.024,0.0251538,0.013553%,99.8055%,0,26,Delegate/Multiply (ND):64
Multiply (ND),0.031,0.0306923,0.0165372%,99.8221%,0,26,Delegate/Multiply (ND):65
Add (ND),0.022,0.0216154,0.0116465%,99.8337%,0,26,Delegate/Add (ND):66
"Copy (NC, X32)",0.075,0.0771923,0.0415916%,99.8753%,0,26,Delegate/Copy (NC	 X32):67
"Transpose (ND, X32) Transpose",0.095,0.0496538,0.0267538%,99.9021%,0,26,Delegate/Transpose (ND	 X32) Transpose:68
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145063%,99.9035%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:117
DYNAMIC_UPDATE_SLICE,0.083,0.083,0.00172003%,99.9052%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:118
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149208%,99.9067%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:174
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180293%,99.9085%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:175
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140918%,99.9099%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:231
DYNAMIC_UPDATE_SLICE,0.083,0.083,0.00172003%,99.9117%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:232
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142991%,99.9131%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:288
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00176148%,99.9148%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:289
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140918%,99.9163%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:345
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180293%,99.9181%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:346
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147135%,99.9195%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:402
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00176148%,99.9213%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6;1]:403
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138846%,99.9227%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:459
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.0017822%,99.9245%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:460
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149208%,99.926%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;4]:516
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00176148%,99.9277%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;5]:517
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145063%,99.9292%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:573
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.0017822%,99.931%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;1]:574
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145063%,99.9324%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:630
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174076%,99.9341%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:631
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145063%,99.9356%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;4]:687
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.0017822%,99.9374%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;5]:688
DYNAMIC_UPDATE_SLICE,0.075,0.075,0.00155425%,99.9389%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:744
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00176148%,99.9407%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;6]:745
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149208%,99.9422%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;3]:801
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.0017822%,99.944%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;7]:802
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145063%,99.9454%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;9]:858
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00182365%,99.9472%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;10]:859
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145063%,99.9487%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;12]:915
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174076%,99.9504%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;]:916
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142991%,99.9519%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;13]:972
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180293%,99.9537%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:973
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142991%,99.9551%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;14]:1029
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.0017822%,99.9569%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;15]:1030
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.0015128%,99.9584%,0,1,[StatefulPartitionedCall:11]:1086
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180293%,99.9602%,0,1,[StatefulPartitionedCall:39]:1087
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138846%,99.9616%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:1143
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169931%,99.9633%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1144
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.0015128%,99.9648%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:1200
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184437%,99.9666%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1201
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138846%,99.968%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:1257
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180293%,99.9698%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:1258
DYNAMIC_UPDATE_SLICE,0.074,0.074,0.00153352%,99.9714%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:1314
DYNAMIC_UPDATE_SLICE,0.092,0.092,0.00190654%,99.9733%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1315
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142991%,99.9747%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:1371
DYNAMIC_UPDATE_SLICE,0.081,0.081,0.00167859%,99.9764%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1372
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147135%,99.9778%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1428
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180293%,99.9796%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25;1]:1429
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147135%,99.9811%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1485
DYNAMIC_UPDATE_SLICE,0.101,0.101,0.00209305%,99.9832%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:1486
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149208%,99.9847%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;4]:1542
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00182365%,99.9865%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;5]:1543
"Transpose (ND, X32) Transpose",0.102,0.102,0.00211378%,99.9886%,0,1,Delegate/Transpose (ND	 X32) Transpose:45
"Slice (ND, X32)",0.055,0.055,0.00113978%,99.9898%,0,1,Delegate/Slice (ND	 X32):46
"Slice (ND, X32)",0.031,0.031,0.000642422%,99.9904%,0,1,Delegate/Slice (ND	 X32):47
Multiply (ND),0.05,0.05,0.00103616%,99.9915%,0,1,Delegate/Multiply (ND):48
Multiply (ND),0.051,0.051,0.00105689%,99.9925%,0,1,Delegate/Multiply (ND):49
Subtract (ND),0.018,0.018,0.000373019%,99.9929%,0,1,Delegate/Subtract (ND):50
Multiply (ND),0.037,0.037,0.000766762%,99.9937%,0,1,Delegate/Multiply (ND):52
Add (ND),0.022,0.022,0.000455912%,99.9941%,0,1,Delegate/Add (ND):53
"Copy (NC, X32)",0.08,0.08,0.00165786%,99.9958%,0,1,Delegate/Copy (NC	 X32):54
"Transpose (ND, X32) Transpose",0.052,0.052,0.00107761%,99.9968%,0,1,Delegate/Transpose (ND	 X32) Transpose:55
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140918%,99.9983%,0,1,[Unknown]:1586
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174076%,100%,0,1,[Unknown]:1587

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
EMBEDDING_LOOKUP,105.609,105.609,2.18857%,2.18857%,0,1,[arith.constant223]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",55.703,59.9659,33.5526%,35.7412%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.952,25.952,0.537811%,36.279%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.607,25.819,14.4465%,50.7255%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.585,25.5308,14.2852%,65.0107%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.471,16.542,9.25575%,74.2665%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.404,10.6569,5.96282%,80.2293%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
"Batch Matrix Multiply (NC, F32) GEMM",10.192,10.3003,5.76333%,85.9926%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Batch Matrix Multiply (NC, F32) GEMM",10.283,10.2144,5.71523%,91.7078%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
GATHER_ND,2.012,2.012,0.0416953%,91.7495%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17

Number of nodes executed: 191
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,3765.85,78.0407%,78.0407%,0,136
"Batch Matrix Multiply (NC, F32) GEMM",2,553.897,11.4786%,89.5193%,0,54
"Transpose (ND, X32) Transpose",14,111.967,2.32032%,91.8396%,0,218
EMBEDDING_LOOKUP,1,105.609,2.18857%,94.0282%,0,1
Multiply (ND),33,91.985,1.90623%,95.9344%,0,522
Add (ND),11,69.306,1.43625%,97.3707%,0,191
"Softmax (NC, F32)",1,50.077,1.03776%,98.4084%,0,27
"Slice (ND, X32)",16,25.745,0.533521%,98.9419%,0,193
Sigmoid (NC),1,15.434,0.319843%,99.2618%,0,27
"Copy (NC, X32)",5,13.126,0.272014%,99.5338%,0,55
Static Reshape (NC),15,8.235,0.170656%,99.7044%,0,302
Sum (ND) Reduce,3,4.942,0.102414%,99.8069%,0,55
DYNAMIC_UPDATE_SLICE,56,4.411,0.0914104%,99.8983%,0,56
Subtract (ND),5,2.206,0.0457156%,99.944%,0,55
GATHER_ND,1,2.012,0.0416953%,99.9857%,0,1
SELECT_V2,1,0.235,0.00486997%,99.9905%,0,1
CAST,2,0.226,0.00468346%,99.9952%,0,2
Cosine (NC),1,0.053,0.00109833%,99.9963%,0,1
Sine (NC),1,0.047,0.000973994%,99.9973%,0,1
Reciprocal Square Root (NC),3,0.036,0.000746038%,99.9981%,0,55
LESS,1,0.033,0.000683869%,99.9987%,0,1
REDUCE_ALL,1,0.025,0.000518082%,99.9993%,0,1
ADD,1,0.007,0.000145063%,99.9994%,0,1
RESHAPE,4,0.005,0.000103616%,99.9995%,0,4
LESS_EQUAL,1,0.005,0.000103616%,99.9996%,0,1
GREATER_EQUAL,1,0.005,0.000103616%,99.9997%,0,1
SLICE,1,0.004,8.28932e-05%,99.9998%,0,1
PACK,1,0.004,8.28932e-05%,99.9999%,0,1
SELECT,1,0.003,6.21699e-05%,100%,0,1
LOGICAL_AND,1,0.003,6.21699e-05%,100%,0,1

Subgraph (index: 1, name: prefill_128) Timings (microseconds): count=1 curr=4825489
Memory (bytes): count=0
191 nodes observed


