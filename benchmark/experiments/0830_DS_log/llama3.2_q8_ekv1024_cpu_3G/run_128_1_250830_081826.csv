Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

Number of nodes executed: 0
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called

Timings (microseconds): count=0
Memory (bytes): count=0
0 nodes observed


Operator-wise Profiling Info for Regular Benchmark Runs:
Primary graph (name: decode) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.007,0.377844,0.00913531%,0.00913531%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;]:0
EMBEDDING_LOOKUP,1.195,2.4775,0.0598997%,0.069035%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
CAST,0.006,0.005625,0.000135998%,0.069171%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;]:3
LESS,0.002,0.00434375,0.000105021%,0.069276%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:8
ADD,0.585,0.193656,0.00468212%,0.0739581%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:9
SELECT,0.002,0.00465625,0.000112576%,0.0740707%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:10
RESHAPE,0.001,0.0006875,1.6622e-05%,0.0740873%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:11
CAST,0.003,0.00071875,1.73776e-05%,0.0741047%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:12
GREATER_EQUAL,0.002,0.00328125,7.93323e-05%,0.0741841%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:13
LESS_EQUAL,0.155,0.0224375,0.000542482%,0.0747265%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;11]:14
LOGICAL_AND,0.001,0.002875,6.95102e-05%,0.074796%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:15
REDUCE_ALL,0.004,0.156969,0.00379511%,0.0785912%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:16
GATHER_ND,0.004,1.86931,0.0451953%,0.123786%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;14]:17
RESHAPE,0,0.0015,3.62662e-05%,0.123823%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;15]:18
SELECT_V2,0.005,0.0069375,0.000167731%,0.12399%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;16]:19
RESHAPE,0,0.00090625,2.19108e-05%,0.124012%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:54
PACK,0.003,0.00496875,0.000120132%,0.124132%,0,1,[tfl.pack]:55
Static Reshape (NC),0.027,0.154,0.00372333%,0.127856%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0,0.0826875,0.00199918%,0.129855%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.012,0.0255,0.000616526%,0.130471%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0,0.119031,0.00287788%,0.133349%,0,1,Delegate/Cosine (NC):3
Sine (NC),0,0.00159375,3.85329e-05%,0.133388%,0,1,Delegate/Sine (NC):4
Multiply (ND),0.012,0.0195625,0.000472972%,0.133861%,0,1,Delegate/Multiply (ND):5
Sum (ND) Reduce,0.001,0.00125,3.02218e-05%,0.133891%,0,1,Delegate/Sum (ND) Reduce:6
Multiply (ND),0,0.00025,6.04437e-06%,0.133897%,0,1,Delegate/Multiply (ND):7
Add (ND),0,0.0690937,0.00167051%,0.135568%,0,1,Delegate/Add (ND):8
Reciprocal Square Root (NC),0,0.00015625,3.77773e-06%,0.135571%,0,1,Delegate/Reciprocal Square Root (NC):9
Multiply (ND),0.012,0.019625,0.000474483%,0.136046%,0,1,Delegate/Multiply (ND):10
Multiply (ND),0.007,0.344562,0.00833065%,0.144377%,0,1,Delegate/Multiply (ND):11
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.102,16.2209,0.392181%,0.536557%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
Static Reshape (NC),0.018,0.0635162,0.0445342%,0.581091%,0,29,Delegate/Static Reshape (NC):13
"Slice (ND, X32)",0.013,0.0294375,0.000711724%,0.581803%,0,1,Delegate/Slice (ND	 X32):14
"Slice (ND, X32)",0.011,0.0226875,0.000548527%,0.582352%,0,1,Delegate/Slice (ND	 X32):15
"Slice (ND, X32)",0.02,0.0193437,0.000467683%,0.582819%,0,1,Delegate/Slice (ND	 X32):16
Static Reshape (NC),0.013,0.0181562,0.000438972%,0.583258%,0,1,Delegate/Static Reshape (NC):17
"Slice (ND, X32)",0.012,0.0169688,0.000410262%,0.583668%,0,1,Delegate/Slice (ND	 X32):18
"Slice (ND, X32)",0.012,0.0177187,0.000428395%,0.584097%,0,1,Delegate/Slice (ND	 X32):19
Multiply (ND),0.011,0.0298922,0.0209589%,0.605056%,0,29,Delegate/Multiply (ND):20
Multiply (ND),0.011,0.0203438,0.000491861%,0.605548%,0,1,Delegate/Multiply (ND):21
Subtract (ND),0.011,0.0176562,0.000426884%,0.605974%,0,1,Delegate/Subtract (ND):22
Multiply (ND),0.011,0.0268675,0.018838%,0.624812%,0,29,Delegate/Multiply (ND):23
Multiply (ND),0.011,0.0573793,0.0402313%,0.665044%,0,29,Delegate/Multiply (ND):24
Add (ND),0.012,0.0170938,0.000413284%,0.665457%,0,1,Delegate/Add (ND):25
"Copy (NC, X32)",0.022,0.083875,0.00202789%,0.667485%,0,1,Delegate/Copy (NC	 X32):26
Static Reshape (NC),0.008,0.0182187,0.000440483%,0.667925%,0,1,Delegate/Static Reshape (NC):27
Static Reshape (NC),0,0.000375,9.06655e-06%,0.667935%,0,1,Delegate/Static Reshape (NC):28
"Slice (ND, X32)",0.012,0.0174375,0.000421595%,0.668356%,0,1,Delegate/Slice (ND	 X32):29
"Slice (ND, X32)",0.011,0.01675,0.000404973%,0.668761%,0,1,Delegate/Slice (ND	 X32):30
Multiply (ND),0.011,0.0900625,0.00217748%,0.670939%,0,1,Delegate/Multiply (ND):31
Multiply (ND),0.012,0.0407866,0.0285974%,0.699536%,0,29,Delegate/Multiply (ND):32
Subtract (ND),0.01,0.0191875,0.000463905%,0.7%,0,1,Delegate/Subtract (ND):33
Multiply (ND),0.011,0.0157349,0.0110325%,0.711032%,0,29,Delegate/Multiply (ND):34
Multiply (ND),0.011,0.0164688,0.000398173%,0.711431%,0,1,Delegate/Multiply (ND):35
Add (ND),0.011,0.0161563,0.000390617%,0.711821%,0,1,Delegate/Add (ND):36
"Copy (NC, X32)",0.022,0.0955625,0.00231046%,0.714132%,0,1,Delegate/Copy (NC	 X32):37
Static Reshape (NC),0,0.0004375,1.05776e-05%,0.714142%,0,1,Delegate/Static Reshape (NC):38
DYNAMIC_UPDATE_SLICE,0.003,0.286313,0.00692231%,0.721065%,0,1,[StatefulPartitionedCall:0]:56
DYNAMIC_UPDATE_SLICE,0.001,0.159406,0.00385404%,0.724919%,0,1,[StatefulPartitionedCall:28]:57
Multiply (ND),0.016,0.214045,0.144902%,0.86982%,0,28,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.001,0.00917522,0.00621134%,0.876032%,0,28,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",0.97,7.59905,5.14432%,6.02035%,0,28,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0.001,0.0770625,0.052169%,6.07252%,0,28,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,0.00721094,0.00488158%,6.0774%,0,28,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",1.473,1.58103,1.07031%,7.14771%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,0.0140078,0.00948286%,7.1572%,0,28,Delegate/Static Reshape (NC):6
Add (ND),0.032,0.0533092,0.0360887%,7.19329%,0,28,Delegate/Add (ND):7
"Softmax (NC, F32)",0.031,0.0469587,0.0317896%,7.22508%,0,28,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.538,21.1901,14.3451%,21.5702%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0.0215502,0.0145888%,21.5847%,0,28,Delegate/Static Reshape (NC):10
Static Reshape (NC),0,0.0238337,0.0161347%,21.6009%,0,28,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",1.438,2.7777,1.88042%,23.4813%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Transpose (ND, X32) Transpose",0.002,0.0485737,0.0328829%,23.5142%,0,28,Delegate/Transpose (ND	 X32) Transpose:14
Static Reshape (NC),0,0.0135837,0.00919575%,23.5234%,0,28,Delegate/Static Reshape (NC):15
"Fully Connected (NC, QD8, F32, QC8W) GEMM",0.667,9.51042,6.43826%,29.9616%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.019,0.0448817,0.0303835%,29.992%,0,28,Delegate/Add (ND):17
Multiply (ND),0.013,0.0318225,0.0215429%,30.0136%,0,28,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.002,0.0135312,0.00916024%,30.0227%,0,28,Delegate/Sum (ND) Reduce:19
Add (ND),0,0.00255357,0.00172869%,30.0245%,0,28,Delegate/Add (ND):21
Reciprocal Square Root (NC),0,0.00217299,0.00147105%,30.0259%,0,28,Delegate/Reciprocal Square Root (NC):22
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.686,25.1738,17.0419%,47.0678%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
Sigmoid (NC),0.021,0.0587924,0.0398007%,47.1076%,0,28,Delegate/Sigmoid (NC):26
Multiply (ND),0.01,0.0466696,0.0315939%,47.1392%,0,28,Delegate/Multiply (ND):27
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.709,24.6541,16.6901%,63.8293%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
Multiply (ND),0.012,0.0757868,0.0513054%,63.8806%,0,28,Delegate/Multiply (ND):29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.675,24.3288,16.4699%,80.3505%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
Add (ND),0.113,0.200167,0.135507%,80.486%,0,28,Delegate/Add (ND):31
Sum (ND) Reduce,0.001,0.00517299,0.00350196%,80.4895%,0,28,Delegate/Sum (ND) Reduce:33
Add (ND),0,0.0124397,0.00842132%,80.4979%,0,28,Delegate/Add (ND):35
Reciprocal Square Root (NC),0,0.00650558,0.00440408%,80.5023%,0,28,Delegate/Reciprocal Square Root (NC):36
Multiply (ND),0.014,0.0564621,0.0382231%,80.5405%,0,28,Delegate/Multiply (ND):37
Multiply (ND),0.007,0.074692,0.0505642%,80.5911%,0,28,Delegate/Multiply (ND):38
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.084,27.4524,18.5844%,99.1755%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
Static Reshape (NC),0.015,0.0733623,0.0478903%,99.2234%,0,27,Delegate/Static Reshape (NC):40
"Slice (ND, X32)",0.013,0.085912,0.0560827%,99.2795%,0,27,Delegate/Slice (ND	 X32):41
"Slice (ND, X32)",0.011,0.0400081,0.026117%,99.3056%,0,27,Delegate/Slice (ND	 X32):42
"Slice (ND, X32)",0.021,0.0223171,0.0145684%,99.3202%,0,27,Delegate/Slice (ND	 X32):43
Static Reshape (NC),0.012,0.0293264,0.019144%,99.3393%,0,27,Delegate/Static Reshape (NC):44
"Slice (ND, X32)",0.011,0.0189086,0.0123434%,99.3516%,0,27,Delegate/Slice (ND	 X32):45
"Slice (ND, X32)",0.011,0.0196944,0.0128564%,99.3645%,0,27,Delegate/Slice (ND	 X32):46
Multiply (ND),0.01,0.0367153,0.0239674%,99.3885%,0,27,Delegate/Multiply (ND):47
Multiply (ND),0.011,0.0413819,0.0270138%,99.4155%,0,27,Delegate/Multiply (ND):48
Subtract (ND),0.012,0.0166644,0.0108784%,99.4264%,0,27,Delegate/Subtract (ND):49
Multiply (ND),0.011,0.01911,0.0124748%,99.4388%,0,27,Delegate/Multiply (ND):50
Multiply (ND),0.011,0.051559,0.0336573%,99.4725%,0,27,Delegate/Multiply (ND):51
Add (ND),0.01,0.0161586,0.0105482%,99.483%,0,27,Delegate/Add (ND):52
"Copy (NC, X32)",0.022,0.037522,0.0244941%,99.5075%,0,27,Delegate/Copy (NC	 X32):53
Static Reshape (NC),0.011,0.152145,0.0993188%,99.6069%,0,27,Delegate/Static Reshape (NC):54
Static Reshape (NC),0,0.00260069,0.00169771%,99.6086%,0,27,Delegate/Static Reshape (NC):55
"Slice (ND, X32)",0.011,0.0161597,0.0105489%,99.6191%,0,27,Delegate/Slice (ND	 X32):56
"Slice (ND, X32)",0.01,0.0152384,0.00994752%,99.6291%,0,27,Delegate/Slice (ND	 X32):57
Multiply (ND),0.01,0.0151493,0.00988934%,99.6389%,0,27,Delegate/Multiply (ND):58
Multiply (ND),0.01,0.0175532,0.0114586%,99.6504%,0,27,Delegate/Multiply (ND):59
Subtract (ND),0.01,0.0153391,0.0100133%,99.6604%,0,27,Delegate/Subtract (ND):60
Multiply (ND),0.01,0.0146921,0.0095909%,99.67%,0,27,Delegate/Multiply (ND):61
Multiply (ND),0.011,0.014816,0.00967175%,99.6797%,0,27,Delegate/Multiply (ND):62
Add (ND),0.011,0.0149375,0.00975108%,99.6894%,0,27,Delegate/Add (ND):63
"Copy (NC, X32)",0.022,0.0294884,0.0192498%,99.7087%,0,27,Delegate/Copy (NC	 X32):64
Static Reshape (NC),0,0.000165509,0.000108043%,99.7088%,0,27,Delegate/Static Reshape (NC):65
DYNAMIC_UPDATE_SLICE,0.005,0.274,0.00662463%,99.7154%,0,1,[StatefulPartitionedCall:1]:110
DYNAMIC_UPDATE_SLICE,0.002,0.113562,0.00274565%,99.7182%,0,1,[StatefulPartitionedCall:29]:111
DYNAMIC_UPDATE_SLICE,0.005,0.325625,0.00787279%,99.726%,0,1,[StatefulPartitionedCall:12]:164
DYNAMIC_UPDATE_SLICE,0.002,0.141594,0.00342338%,99.7295%,0,1,[StatefulPartitionedCall:40]:165
DYNAMIC_UPDATE_SLICE,0.005,0.419625,0.0101455%,99.7396%,0,1,[StatefulPartitionedCall:21]:218
DYNAMIC_UPDATE_SLICE,0.001,0.139406,0.00337049%,99.743%,0,1,[StatefulPartitionedCall:49]:219
DYNAMIC_UPDATE_SLICE,0.005,0.2135,0.00516189%,99.7481%,0,1,[StatefulPartitionedCall:22]:272
DYNAMIC_UPDATE_SLICE,0.002,0.110344,0.00266783%,99.7508%,0,1,[StatefulPartitionedCall:50]:273
DYNAMIC_UPDATE_SLICE,0.005,0.349438,0.00844852%,99.7592%,0,1,[StatefulPartitionedCall:23]:326
DYNAMIC_UPDATE_SLICE,0.002,0.168281,0.00406862%,99.7633%,0,1,[StatefulPartitionedCall:51]:327
DYNAMIC_UPDATE_SLICE,0.005,0.226125,0.00546713%,99.7688%,0,1,[StatefulPartitionedCall:24]:380
DYNAMIC_UPDATE_SLICE,0.001,0.159594,0.00385857%,99.7726%,0,1,[StatefulPartitionedCall:52]:381
DYNAMIC_UPDATE_SLICE,0.005,0.204625,0.00494732%,99.7776%,0,1,[StatefulPartitionedCall:25]:434
DYNAMIC_UPDATE_SLICE,0.002,0.175906,0.00425297%,99.7818%,0,1,[StatefulPartitionedCall:53]:435
DYNAMIC_UPDATE_SLICE,0.005,0.322219,0.00779044%,99.7896%,0,1,[StatefulPartitionedCall:26]:488
DYNAMIC_UPDATE_SLICE,0.001,0.169937,0.00410866%,99.7937%,0,1,[StatefulPartitionedCall:54]:489
DYNAMIC_UPDATE_SLICE,0.005,0.417781,0.0101009%,99.8038%,0,1,[StatefulPartitionedCall:27]:542
DYNAMIC_UPDATE_SLICE,0.001,0.111594,0.00269806%,99.8065%,0,1,[StatefulPartitionedCall:55]:543
DYNAMIC_UPDATE_SLICE,0.005,0.240719,0.00581997%,99.8124%,0,1,[StatefulPartitionedCall:2]:596
DYNAMIC_UPDATE_SLICE,0.001,0.1375,0.0033244%,99.8157%,0,1,[StatefulPartitionedCall:30]:597
DYNAMIC_UPDATE_SLICE,0.005,0.215344,0.00520647%,99.8209%,0,1,[StatefulPartitionedCall:3]:650
DYNAMIC_UPDATE_SLICE,0.001,0.112375,0.00271694%,99.8236%,0,1,[StatefulPartitionedCall:31]:651
DYNAMIC_UPDATE_SLICE,0.005,0.315375,0.00762497%,99.8312%,0,1,[StatefulPartitionedCall:4]:704
DYNAMIC_UPDATE_SLICE,0.002,0.155844,0.00376791%,99.835%,0,1,[StatefulPartitionedCall:32]:705
DYNAMIC_UPDATE_SLICE,0.004,0.325688,0.0078743%,99.8429%,0,1,[StatefulPartitionedCall:5]:758
DYNAMIC_UPDATE_SLICE,0.001,0.135813,0.0032836%,99.8462%,0,1,[StatefulPartitionedCall:33]:759
DYNAMIC_UPDATE_SLICE,0.005,0.176781,0.00427412%,99.8504%,0,1,[StatefulPartitionedCall:6]:812
DYNAMIC_UPDATE_SLICE,0.001,0.119188,0.00288165%,99.8533%,0,1,[StatefulPartitionedCall:34]:813
DYNAMIC_UPDATE_SLICE,0.005,0.383531,0.00927282%,99.8626%,0,1,[StatefulPartitionedCall:7]:866
DYNAMIC_UPDATE_SLICE,0.001,0.141469,0.00342036%,99.866%,0,1,[StatefulPartitionedCall:35]:867
DYNAMIC_UPDATE_SLICE,0.004,0.266281,0.00643801%,99.8724%,0,1,[StatefulPartitionedCall:8]:920
DYNAMIC_UPDATE_SLICE,0.002,0.136344,0.00329645%,99.8757%,0,1,[StatefulPartitionedCall:36]:921
DYNAMIC_UPDATE_SLICE,0.005,0.258625,0.0062529%,99.882%,0,1,[StatefulPartitionedCall:9]:974
DYNAMIC_UPDATE_SLICE,0.001,0.139781,0.00337956%,99.8854%,0,1,[StatefulPartitionedCall:37]:975
DYNAMIC_UPDATE_SLICE,0.004,0.360563,0.00871749%,99.8941%,0,1,[StatefulPartitionedCall:10]:1028
DYNAMIC_UPDATE_SLICE,0.001,0.165,0.00398928%,99.8981%,0,1,[StatefulPartitionedCall:38]:1029
DYNAMIC_UPDATE_SLICE,0.006,0.352719,0.00852785%,99.9066%,0,1,[StatefulPartitionedCall:11]:1082
DYNAMIC_UPDATE_SLICE,0.001,0.11075,0.00267766%,99.9093%,0,1,[StatefulPartitionedCall:39]:1083
DYNAMIC_UPDATE_SLICE,0.005,0.310219,0.00750031%,99.9168%,0,1,[StatefulPartitionedCall:13]:1136
DYNAMIC_UPDATE_SLICE,0.001,0.111469,0.00269503%,99.9195%,0,1,[StatefulPartitionedCall:41]:1137
DYNAMIC_UPDATE_SLICE,0.005,0.492375,0.0119044%,99.9314%,0,1,[StatefulPartitionedCall:14]:1190
DYNAMIC_UPDATE_SLICE,0.001,0.116406,0.00281441%,99.9342%,0,1,[StatefulPartitionedCall:42]:1191
DYNAMIC_UPDATE_SLICE,0.005,0.215,0.00519816%,99.9394%,0,1,[StatefulPartitionedCall:15]:1244
DYNAMIC_UPDATE_SLICE,0.001,0.15075,0.00364475%,99.943%,0,1,[StatefulPartitionedCall:43]:1245
DYNAMIC_UPDATE_SLICE,0.004,0.426406,0.0103094%,99.9533%,0,1,[StatefulPartitionedCall:16]:1298
DYNAMIC_UPDATE_SLICE,0.001,0.160031,0.00386915%,99.9572%,0,1,[StatefulPartitionedCall:44]:1299
DYNAMIC_UPDATE_SLICE,0.005,0.234344,0.00566584%,99.9629%,0,1,[StatefulPartitionedCall:17]:1352
DYNAMIC_UPDATE_SLICE,0.001,0.128031,0.00309547%,99.966%,0,1,[StatefulPartitionedCall:45]:1353
DYNAMIC_UPDATE_SLICE,0.004,0.349219,0.00844323%,99.9744%,0,1,[StatefulPartitionedCall:18]:1406
DYNAMIC_UPDATE_SLICE,0.001,0.167125,0.00404066%,99.9785%,0,1,[StatefulPartitionedCall:46]:1407
DYNAMIC_UPDATE_SLICE,0.005,0.253656,0.00613277%,99.9846%,0,1,[StatefulPartitionedCall:19]:1460
DYNAMIC_UPDATE_SLICE,0.001,0.173219,0.00418799%,99.9888%,0,1,[StatefulPartitionedCall:47]:1461
DYNAMIC_UPDATE_SLICE,0.004,0.301812,0.00729706%,99.9961%,0,1,[StatefulPartitionedCall:20]:1514
DYNAMIC_UPDATE_SLICE,0.002,0.161844,0.00391297%,100%,0,1,[StatefulPartitionedCall:48]:1515

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.084,27.4524,18.5844%,18.5844%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.686,25.1738,17.0419%,35.6263%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.709,24.6541,16.6901%,52.3164%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.675,24.3288,16.4699%,68.7863%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
"Transpose (ND, X32) Transpose",1.538,21.1901,14.3451%,83.1313%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.102,16.2209,0.392181%,83.5235%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
"Fully Connected (NC, QD8, F32, QC8W) GEMM",0.667,9.51042,6.43826%,89.9618%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
"Transpose (ND, X32) Transpose",0.97,7.59905,5.14432%,95.1061%,0,28,Delegate/Transpose (ND	 X32) Transpose:2
"Batch Matrix Multiply (NC, F32) GEMM",1.438,2.7777,1.88042%,96.9865%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
EMBEDDING_LOOKUP,1.195,2.4775,0.0598997%,97.0464%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1

Number of nodes executed: 172
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,3127.56,75.6182%,75.6182%,0,141
"Transpose (ND, X32) Transpose",4,807.713,19.5289%,95.147%,0,112
"Batch Matrix Multiply (NC, F32) GEMM",2,122.043,2.95075%,98.0978%,0,56
Multiply (ND),27,25.156,0.608221%,98.706%,0,537
Static Reshape (NC),18,13.465,0.325556%,99.0315%,0,338
DYNAMIC_UPDATE_SLICE,56,12.464,0.301354%,99.3329%,0,56
Add (ND),10,9.712,0.234816%,99.5677%,0,197
"Slice (ND, X32)",14,6.025,0.145672%,99.7134%,0,196
EMBEDDING_LOOKUP,1,2.477,0.0598888%,99.7733%,0,1
"Copy (NC, X32)",4,1.987,0.0480416%,99.8213%,0,56
GATHER_ND,1,1.869,0.0451886%,99.8665%,0,1
Sigmoid (NC),1,1.646,0.0397969%,99.9063%,0,28
"Softmax (NC, F32)",1,1.314,0.0317699%,99.9381%,0,28
Subtract (ND),4,0.899,0.021736%,99.9598%,0,56
Sum (ND) Reduce,3,0.523,0.0126451%,99.9725%,0,57
RESHAPE,4,0.378,0.00913927%,99.9816%,0,4
Reciprocal Square Root (NC),3,0.242,0.00585107%,99.9874%,0,57
ADD,1,0.193,0.00466635%,99.9921%,0,1
REDUCE_ALL,1,0.156,0.00377176%,99.9959%,0,1
Cosine (NC),1,0.119,0.00287718%,99.9988%,0,1
LESS_EQUAL,1,0.022,0.000531915%,99.9993%,0,1
SELECT_V2,1,0.006,0.000145068%,99.9994%,0,1
CAST,2,0.005,0.00012089%,99.9996%,0,2
SELECT,1,0.004,9.67119e-05%,99.9997%,0,1
PACK,1,0.004,9.67119e-05%,99.9998%,0,1
LESS,1,0.004,9.67119e-05%,99.9999%,0,1
GREATER_EQUAL,1,0.003,7.25339e-05%,99.9999%,0,1
LOGICAL_AND,1,0.002,4.83559e-05%,100%,0,1
Sine (NC),1,0.001,2.4178e-05%,100%,0,1

Timings (microseconds): count=32 first=1300261 curr=4324775 min=1300261 max=4391147 avg=4.13608e+06 std=555928
Memory (bytes): count=0
172 nodes observed

Subgraph (index: 1, name: prefill_128) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.002,0.002,4.1354e-05%,4.1354e-05%,0,1,[arith.constant222]:0
EMBEDDING_LOOKUP,96.198,96.198,1.98908%,1.98913%,0,1,[arith.constant223]:1
CAST,0.229,0.229,0.00473503%,1.99386%,0,1,[arith.constant225]:3
LESS,0.042,0.042,0.000868433%,1.99473%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;1]:8
ADD,0.008,0.008,0.000165416%,1.99489%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;2]:9
SELECT,0.003,0.003,6.20309e-05%,1.99496%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;3]:10
RESHAPE,0.001,0.001,2.0677e-05%,1.99498%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;4]:11
CAST,0.001,0.001,2.0677e-05%,1.995%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:12
GREATER_EQUAL,0.005,0.005,0.000103385%,1.9951%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:13
LESS_EQUAL,0.005,0.005,0.000103385%,1.9952%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:14
LOGICAL_AND,0.003,0.003,6.20309e-05%,1.99527%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:15
REDUCE_ALL,0.029,0.029,0.000599632%,1.99587%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:16
GATHER_ND,2.29,2.29,0.0473503%,2.04322%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17
RESHAPE,0.002,0.002,4.1354e-05%,2.04326%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:19
SLICE,0.004,0.004,8.27079e-05%,2.04334%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;18]:57
RESHAPE,0.001,0.001,2.0677e-05%,2.04336%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:58
PACK,0.004,0.004,8.27079e-05%,2.04344%,0,1,[tfl.pack]:59
Static Reshape (NC),0.433,0.433,0.00895313%,2.0524%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0.001,0.001,2.0677e-05%,2.05242%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.026,0.026,0.000537602%,2.05296%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.042,0.042,0.000868433%,2.05382%,0,1,Delegate/Cosine (NC):3
Sine (NC),0.022,0.022,0.000454894%,2.05428%,0,1,Delegate/Sine (NC):4
Static Reshape (NC),0.069,0.069,0.00142671%,2.05571%,0,1,Delegate/Static Reshape (NC):5
Multiply (ND),0.329,0.329,0.00680273%,2.06251%,0,1,Delegate/Multiply (ND):6
Sum (ND) Reduce,0.093,0.093,0.00192296%,2.06443%,0,1,Delegate/Sum (ND) Reduce:7
Multiply (ND),0.066,0.066,0.00136468%,2.0658%,0,1,Delegate/Multiply (ND):8
Add (ND),0.037,0.037,0.000765048%,2.06656%,0,1,Delegate/Add (ND):9
Static Reshape (NC),0,0.000321429,0.000186093%,2.06675%,0,28,Delegate/Static Reshape (NC):10
Reciprocal Square Root (NC),0.001,0.001,2.0677e-05%,2.06677%,0,1,Delegate/Reciprocal Square Root (NC):11
Multiply (ND),0.224,0.224,0.00463164%,2.0714%,0,1,Delegate/Multiply (ND):12
Multiply (ND),0.096,0.096,0.00198499%,2.07338%,0,1,Delegate/Multiply (ND):13
"Fully Connected (NC, QD8, F32, QC8W) GEMM",23.15,23.15,0.478672%,2.55206%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
Static Reshape (NC),0.312,0.0111786,0.0064719%,2.55853%,0,28,Delegate/Static Reshape (NC):15
"Slice (ND, X32)",0.333,0.333,0.00688543%,2.56541%,0,1,Delegate/Slice (ND	 X32):16
"Slice (ND, X32)",0.169,0.169,0.00349441%,2.56891%,0,1,Delegate/Slice (ND	 X32):17
"Slice (ND, X32)",0.132,0.132,0.00272936%,2.57164%,0,1,Delegate/Slice (ND	 X32):18
Static Reshape (NC),0,0,0%,2.57164%,0,1,Delegate/Static Reshape (NC):19
"Transpose (ND, X32) Transpose",0.44,0.44,0.00909787%,2.58074%,0,1,Delegate/Transpose (ND	 X32) Transpose:20
"Slice (ND, X32)",0.185,0.185,0.00382524%,2.58456%,0,1,Delegate/Slice (ND	 X32):21
"Slice (ND, X32)",0.152,0.152,0.0031429%,2.5877%,0,1,Delegate/Slice (ND	 X32):22
Multiply (ND),0.214,0.214,0.00442487%,2.59213%,0,1,Delegate/Multiply (ND):23
Multiply (ND),0.141,0.127643,0.0738995%,2.66603%,0,28,Delegate/Multiply (ND):24
Subtract (ND),0.076,0.076,0.00157145%,2.6676%,0,1,Delegate/Subtract (ND):25
Multiply (ND),0.06,0.06,0.00124062%,2.66884%,0,1,Delegate/Multiply (ND):26
Multiply (ND),0.113,0.113,0.0023365%,2.67118%,0,1,Delegate/Multiply (ND):27
Add (ND),0.078,0.078,0.0016128%,2.67279%,0,1,Delegate/Add (ND):28
"Copy (NC, X32)",0.429,0.429,0.00887042%,2.68166%,0,1,Delegate/Copy (NC	 X32):29
"Transpose (ND, X32) Transpose",0.313,0.313,0.0064719%,2.68813%,0,1,Delegate/Transpose (ND	 X32) Transpose:30
"Transpose (ND, X32) Transpose",0.129,0.129,0.00266733%,2.6908%,0,1,Delegate/Transpose (ND	 X32) Transpose:31
"Slice (ND, X32)",0.046,0.046,0.000951141%,2.69175%,0,1,Delegate/Slice (ND	 X32):32
"Slice (ND, X32)",0.036,0.036,0.000744371%,2.69249%,0,1,Delegate/Slice (ND	 X32):33
Multiply (ND),0.051,0.051,0.00105453%,2.69355%,0,1,Delegate/Multiply (ND):34
Multiply (ND),0.026,0.0234286,0.0135641%,2.70711%,0,28,Delegate/Multiply (ND):35
Subtract (ND),0.017,0.017,0.000351509%,2.70746%,0,1,Delegate/Subtract (ND):36
Multiply (ND),0.034,0.034,0.000703017%,2.70817%,0,1,Delegate/Multiply (ND):37
Multiply (ND),0.026,0.026,0.000537602%,2.70871%,0,1,Delegate/Multiply (ND):38
Add (ND),0.017,0.017,0.000351509%,2.70906%,0,1,Delegate/Add (ND):39
"Copy (NC, X32)",0.085,0.085,0.00175754%,2.71081%,0,1,Delegate/Copy (NC	 X32):40
"Transpose (ND, X32) Transpose",0.054,0.054,0.00111656%,2.71193%,0,1,Delegate/Transpose (ND	 X32) Transpose:41
SELECT_V2,0.248,0.248,0.00512789%,2.71706%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:20
DYNAMIC_UPDATE_SLICE,0.09,0.09,0.00186093%,2.71892%,0,1,[StatefulPartitionedCall:0]:60
DYNAMIC_UPDATE_SLICE,0.094,0.094,0.00194364%,2.72086%,0,1,[StatefulPartitionedCall:28]:61
Multiply (ND),0.248,0.213444,0.119161%,2.84002%,0,27,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.261,0.25363,0.141596%,2.98162%,0,27,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",1.018,1.06919,0.596903%,3.57852%,0,27,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000148148,8.27079e-05%,3.57861%,0,27,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,0,0%,3.57861%,0,27,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",10.512,10.4346,5.82543%,9.40404%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,0.000185185,0.000103385%,9.40414%,0,27,Delegate/Static Reshape (NC):6
Add (ND),2.186,2.17641,1.21504%,10.6192%,0,27,Delegate/Add (ND):7
"Softmax (NC, F32)",2.109,2.10252,1.17379%,11.793%,0,27,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.777,1.80544,1.00794%,12.8009%,0,27,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0,0%,12.8009%,0,27,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",10.233,10.2967,5.74841%,18.5493%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Static Reshape (NC),0,7.40741e-05,4.1354e-05%,18.5494%,0,27,Delegate/Static Reshape (NC):13
"Transpose (ND, X32) Transpose",0.236,0.244963,0.136758%,18.6861%,0,27,Delegate/Transpose (ND	 X32) Transpose:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.865,10.5296,5.87844%,24.5646%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.292,0.287556,0.160536%,24.7251%,0,27,Delegate/Add (ND):17
Multiply (ND),0.129,0.152259,0.0850031%,24.8101%,0,27,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.086,0.0988519,0.0551869%,24.8653%,0,27,Delegate/Sum (ND) Reduce:19
Multiply (ND),0.025,0.0257037,0.0143498%,24.8796%,0,27,Delegate/Multiply (ND):20
Add (ND),0.018,0.0166296,0.00928396%,24.8889%,0,27,Delegate/Add (ND):21
Static Reshape (NC),0,0,0%,24.8889%,0,27,Delegate/Static Reshape (NC):22
Reciprocal Square Root (NC),0.001,0.00122222,0.00068234%,24.8896%,0,27,Delegate/Reciprocal Square Root (NC):23
Multiply (ND),0.177,0.159704,0.0891591%,24.9788%,0,27,Delegate/Multiply (ND):25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.667,25.5212,14.2479%,39.2267%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
Sigmoid (NC),0.648,0.607519,0.339165%,39.5659%,0,27,Delegate/Sigmoid (NC):27
Multiply (ND),0.938,0.952148,0.531564%,40.0974%,0,27,Delegate/Multiply (ND):28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.299,25.488,14.2294%,54.3269%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
Multiply (ND),0.966,0.934185,0.521535%,54.8484%,0,27,Delegate/Multiply (ND):30
"Fully Connected (NC, QD8, F32, QC8W) GEMM",54.893,59.9824,33.4869%,88.3353%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
Add (ND),0.275,0.281407,0.157104%,88.4924%,0,27,Delegate/Add (ND):32
Multiply (ND),0.112,0.127074,0.0709427%,88.5634%,0,27,Delegate/Multiply (ND):33
Sum (ND) Reduce,0.119,0.0915556,0.0511135%,88.6145%,0,27,Delegate/Sum (ND) Reduce:34
Add (ND),0.018,0.0144444,0.00806402%,88.6225%,0,27,Delegate/Add (ND):36
Static Reshape (NC),0,0,0%,88.6225%,0,27,Delegate/Static Reshape (NC):37
Reciprocal Square Root (NC),0,0.000296296,0.000165416%,88.6227%,0,27,Delegate/Reciprocal Square Root (NC):38
Multiply (ND),0.159,0.197074,0.110022%,88.7327%,0,27,Delegate/Multiply (ND):39
Multiply (ND),0.085,0.126222,0.0704672%,88.8032%,0,27,Delegate/Multiply (ND):40
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.448,16.44,9.17812%,97.9813%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
Static Reshape (NC),0.292,0.292444,0.163265%,98.1446%,0,27,Delegate/Static Reshape (NC):42
"Slice (ND, X32)",0.275,0.283852,0.158468%,98.303%,0,27,Delegate/Slice (ND	 X32):43
"Slice (ND, X32)",0.194,0.159111,0.0888283%,98.3919%,0,27,Delegate/Slice (ND	 X32):44
"Slice (ND, X32)",0.119,0.123423,0.0663524%,98.4582%,0,26,Delegate/Slice (ND	 X32):45
Static Reshape (NC),0,3.84615e-05,2.0677e-05%,98.4582%,0,26,Delegate/Static Reshape (NC):46
"Transpose (ND, X32) Transpose",0.441,0.461462,0.248082%,98.7063%,0,26,Delegate/Transpose (ND	 X32) Transpose:47
"Slice (ND, X32)",0.211,0.200769,0.107934%,98.8143%,0,26,Delegate/Slice (ND	 X32):48
"Slice (ND, X32)",0.199,0.172192,0.0925708%,98.9068%,0,26,Delegate/Slice (ND	 X32):49
Multiply (ND),0.173,0.179423,0.0964581%,99.0033%,0,26,Delegate/Multiply (ND):50
Multiply (ND),0.129,0.119852,0.0669107%,99.0702%,0,27,Delegate/Multiply (ND):51
Subtract (ND),0.069,0.0560385,0.0301264%,99.1003%,0,26,Delegate/Subtract (ND):52
Multiply (ND),0.072,0.062,0.0333313%,99.1337%,0,26,Delegate/Multiply (ND):53
Multiply (ND),0.116,0.126846,0.0681927%,99.2019%,0,26,Delegate/Multiply (ND):54
Add (ND),0.059,0.0663846,0.0356885%,99.2375%,0,26,Delegate/Add (ND):55
"Copy (NC, X32)",0.441,0.432192,0.232347%,99.4699%,0,26,Delegate/Copy (NC	 X32):56
"Transpose (ND, X32) Transpose",0.255,0.244308,0.13134%,99.6012%,0,26,Delegate/Transpose (ND	 X32) Transpose:57
"Transpose (ND, X32) Transpose",0.165,0.145308,0.0781176%,99.6793%,0,26,Delegate/Transpose (ND	 X32) Transpose:58
"Slice (ND, X32)",0.053,0.0600385,0.0322768%,99.7116%,0,26,Delegate/Slice (ND	 X32):59
"Slice (ND, X32)",0.029,0.0334231,0.0179683%,99.7296%,0,26,Delegate/Slice (ND	 X32):60
Multiply (ND),0.056,0.0383462,0.0206149%,99.7502%,0,26,Delegate/Multiply (ND):61
Multiply (ND),0.04,0.0397308,0.0213593%,99.7716%,0,26,Delegate/Multiply (ND):62
Subtract (ND),0.02,0.0225769,0.0121374%,99.7837%,0,26,Delegate/Subtract (ND):63
Multiply (ND),0.037,0.0281154,0.0151149%,99.7988%,0,26,Delegate/Multiply (ND):64
Multiply (ND),0.035,0.0296923,0.0159626%,99.8148%,0,26,Delegate/Multiply (ND):65
Add (ND),0.026,0.0217308,0.0116825%,99.8265%,0,26,Delegate/Add (ND):66
"Copy (NC, X32)",0.102,0.0841538,0.0452412%,99.8717%,0,26,Delegate/Copy (NC	 X32):67
"Transpose (ND, X32) Transpose",0.128,0.0569231,0.0306019%,99.9023%,0,26,Delegate/Transpose (ND	 X32) Transpose:68
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144739%,99.9037%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:117
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169551%,99.9054%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:118
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146807%,99.9069%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:174
DYNAMIC_UPDATE_SLICE,0.081,0.081,0.00167484%,99.9086%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:175
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.91%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:231
DYNAMIC_UPDATE_SLICE,0.081,0.081,0.00167484%,99.9117%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:232
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.9131%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:288
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017989%,99.9149%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:289
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142671%,99.9163%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:345
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173687%,99.918%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:346
DYNAMIC_UPDATE_SLICE,0.066,0.066,0.00136468%,99.9194%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:402
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00173687%,99.9211%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6;1]:403
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00148874%,99.9226%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:459
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175754%,99.9244%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:460
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146807%,99.9259%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;4]:516
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017989%,99.9277%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;5]:517
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144739%,99.9291%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:573
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177822%,99.9309%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;1]:574
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.9323%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:630
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175754%,99.934%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:631
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00148874%,99.9355%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;4]:687
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017989%,99.9373%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;5]:688
DYNAMIC_UPDATE_SLICE,0.075,0.075,0.00155077%,99.9389%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:744
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00181957%,99.9407%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;6]:745
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.9421%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;3]:801
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169551%,99.9438%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;7]:802
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142671%,99.9452%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;9]:858
DYNAMIC_UPDATE_SLICE,0.083,0.083,0.00171619%,99.9469%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;10]:859
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00150942%,99.9484%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;12]:915
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169551%,99.9501%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;]:916
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.9516%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;13]:972
DYNAMIC_UPDATE_SLICE,0.088,0.088,0.00181957%,99.9534%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:973
DYNAMIC_UPDATE_SLICE,0.066,0.066,0.00136468%,99.9547%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;14]:1029
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175754%,99.9565%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;15]:1030
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.9579%,0,1,[StatefulPartitionedCall:11]:1086
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00177822%,99.9597%,0,1,[StatefulPartitionedCall:39]:1087
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144739%,99.9611%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:1143
DYNAMIC_UPDATE_SLICE,0.09,0.09,0.00186093%,99.963%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1144
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146807%,99.9645%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:1200
DYNAMIC_UPDATE_SLICE,0.081,0.081,0.00167484%,99.9661%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1201
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00146807%,99.9676%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:1257
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00175754%,99.9694%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:1258
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00144739%,99.9708%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:1314
DYNAMIC_UPDATE_SLICE,0.081,0.081,0.00167484%,99.9725%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1315
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142671%,99.9739%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:1371
DYNAMIC_UPDATE_SLICE,0.083,0.083,0.00171619%,99.9756%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1372
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142671%,99.977%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1428
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184025%,99.9789%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25;1]:1429
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00142671%,99.9803%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1485
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017989%,99.9821%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:1486
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140603%,99.9835%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;4]:1542
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.0017989%,99.9853%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;5]:1543
"Transpose (ND, X32) Transpose",0.129,0.129,0.00266733%,99.988%,0,1,Delegate/Transpose (ND	 X32) Transpose:45
"Slice (ND, X32)",0.063,0.063,0.00130265%,99.9893%,0,1,Delegate/Slice (ND	 X32):46
"Slice (ND, X32)",0.031,0.031,0.000640986%,99.9899%,0,1,Delegate/Slice (ND	 X32):47
Multiply (ND),0.041,0.041,0.000847756%,99.9908%,0,1,Delegate/Multiply (ND):48
Multiply (ND),0.068,0.068,0.00140603%,99.9922%,0,1,Delegate/Multiply (ND):49
Subtract (ND),0.023,0.023,0.000475571%,99.9927%,0,1,Delegate/Subtract (ND):50
Multiply (ND),0.043,0.043,0.00088911%,99.9935%,0,1,Delegate/Multiply (ND):52
Add (ND),0.023,0.023,0.000475571%,99.994%,0,1,Delegate/Add (ND):53
"Copy (NC, X32)",0.08,0.08,0.00165416%,99.9957%,0,1,Delegate/Copy (NC	 X32):54
"Transpose (ND, X32) Transpose",0.055,0.055,0.00113723%,99.9968%,0,1,Delegate/Transpose (ND	 X32) Transpose:55
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00148874%,99.9983%,0,1,[Unknown]:1586
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169551%,100%,0,1,[Unknown]:1587

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
EMBEDDING_LOOKUP,96.198,96.198,1.98908%,1.98908%,0,1,[arith.constant223]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",54.893,59.9824,33.4869%,35.476%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.667,25.5212,14.2479%,49.7239%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.299,25.488,14.2294%,63.9534%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",23.15,23.15,0.478672%,64.432%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.448,16.44,9.17812%,73.6102%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.865,10.5296,5.87844%,79.4886%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
"Batch Matrix Multiply (NC, F32) GEMM",10.512,10.4346,5.82543%,85.314%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
"Batch Matrix Multiply (NC, F32) GEMM",10.233,10.2967,5.74841%,91.0624%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
GATHER_ND,2.29,2.29,0.0473503%,91.1098%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17

Number of nodes executed: 191
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,3748.11,77.4995%,77.4995%,0,136
"Batch Matrix Multiply (NC, F32) GEMM",2,559.745,11.5738%,89.0733%,0,54
"Transpose (ND, X32) Transpose",14,115.805,2.3945%,91.4678%,0,218
Multiply (ND),33,99.936,2.06637%,93.5342%,0,522
EMBEDDING_LOOKUP,1,96.198,1.98908%,95.5233%,0,1
Add (ND),11,77.41,1.60061%,97.1239%,0,191
"Softmax (NC, F32)",1,56.768,1.17379%,98.2977%,0,27
"Slice (ND, X32)",16,28.443,0.588115%,98.8858%,0,193
Sigmoid (NC),1,16.403,0.339165%,99.225%,0,27
"Copy (NC, X32)",5,14.019,0.289871%,99.5149%,0,55
Static Reshape (NC),15,8.733,0.180572%,99.6954%,0,302
Sum (ND) Reduce,3,5.234,0.108223%,99.8036%,0,55
DYNAMIC_UPDATE_SLICE,56,4.353,0.0900069%,99.8937%,0,56
GATHER_ND,1,2.29,0.0473503%,99.941%,0,1
Subtract (ND),5,2.16,0.0446623%,99.9857%,0,55
SELECT_V2,1,0.248,0.00512789%,99.9908%,0,1
CAST,2,0.23,0.00475571%,99.9955%,0,2
Reciprocal Square Root (NC),3,0.042,0.000868433%,99.9964%,0,55
LESS,1,0.042,0.000868433%,99.9973%,0,1
Cosine (NC),1,0.042,0.000868433%,99.9982%,0,1
REDUCE_ALL,1,0.029,0.000599632%,99.9988%,0,1
Sine (NC),1,0.022,0.000454894%,99.9992%,0,1
ADD,1,0.008,0.000165416%,99.9994%,0,1
RESHAPE,4,0.006,0.000124062%,99.9995%,0,4
LESS_EQUAL,1,0.005,0.000103385%,99.9996%,0,1
GREATER_EQUAL,1,0.005,0.000103385%,99.9997%,0,1
SLICE,1,0.004,8.27079e-05%,99.9998%,0,1
PACK,1,0.004,8.27079e-05%,99.9999%,0,1
SELECT,1,0.003,6.20309e-05%,99.9999%,0,1
LOGICAL_AND,1,0.003,6.20309e-05%,100%,0,1

Subgraph (index: 1, name: prefill_128) Timings (microseconds): count=1 curr=4836296
Memory (bytes): count=0
191 nodes observed


