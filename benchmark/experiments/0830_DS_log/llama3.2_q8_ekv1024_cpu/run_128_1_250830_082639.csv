Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name

Number of nodes executed: 0
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called

Timings (microseconds): count=0
Memory (bytes): count=0
0 nodes observed


Operator-wise Profiling Info for Regular Benchmark Runs:
Primary graph (name: decode) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.007,0.00240625,0.000623781%,0.000623781%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;]:0
EMBEDDING_LOOKUP,0.009,1.52225,0.394619%,0.395242%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
CAST,0.002,0.00159375,0.000413154%,0.395656%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;]:3
LESS,0.002,0.00209375,0.000542771%,0.396198%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:8
ADD,0.002,0.00253125,0.000656185%,0.396854%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:9
SELECT,0.001,0.00128125,0.000332143%,0.397187%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:10
RESHAPE,0,0.0003125,8.10106e-05%,0.397268%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:11
CAST,0.002,0.0004375,0.000113415%,0.397381%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:12
GREATER_EQUAL,0.001,0.0010625,0.000275436%,0.397657%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:13
LESS_EQUAL,0.001,0.00140625,0.000364547%,0.398021%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;11]:14
LOGICAL_AND,0.001,0.00115625,0.000299739%,0.398321%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:15
REDUCE_ALL,0.004,0.0039375,0.00102073%,0.399342%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:16
GATHER_ND,0.003,0.0095625,0.00247892%,0.40182%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;14]:17
RESHAPE,0,0.0001875,4.86063e-05%,0.401869%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;15]:18
SELECT_V2,0.004,0.00259375,0.000672388%,0.402541%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;16]:19
RESHAPE,0.001,0.00028125,7.29095e-05%,0.402614%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:54
PACK,0.003,0.00196875,0.000510366%,0.403125%,0,1,[tfl.pack]:55
Static Reshape (NC),0.084,0.231969,0.0601341%,0.463259%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0,0.0001875,4.86063e-05%,0.463307%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.033,0.154219,0.0399787%,0.503286%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.001,0.0005625,0.000145819%,0.503432%,0,1,Delegate/Cosine (NC):3
Sine (NC),0.001,0.00040625,0.000105314%,0.503537%,0,1,Delegate/Sine (NC):4
Multiply (ND),0.025,0.1695,0.0439401%,0.547477%,0,1,Delegate/Multiply (ND):5
Sum (ND) Reduce,0.001,0.0015,0.000388851%,0.547866%,0,1,Delegate/Sum (ND) Reduce:6
Multiply (ND),0.001,0.000875,0.00022683%,0.548093%,0,1,Delegate/Multiply (ND):7
Add (ND),0,3.125e-05,8.10106e-06%,0.548101%,0,1,Delegate/Add (ND):8
Reciprocal Square Root (NC),0,0.00021875,5.67074e-05%,0.548158%,0,1,Delegate/Reciprocal Square Root (NC):9
Multiply (ND),0.017,0.2015,0.0522356%,0.600393%,0,1,Delegate/Multiply (ND):10
Multiply (ND),0.008,0.151281,0.0392172%,0.639611%,0,1,Delegate/Multiply (ND):11
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.136,1.13069,0.293112%,0.932723%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
Static Reshape (NC),0.017,0.0040097,0.030144%,0.962867%,0,29,Delegate/Static Reshape (NC):13
"Slice (ND, X32)",0.017,0.11425,0.0296175%,0.992485%,0,1,Delegate/Slice (ND	 X32):14
"Slice (ND, X32)",0.015,0.112406,0.0291395%,1.02162%,0,1,Delegate/Slice (ND	 X32):15
"Slice (ND, X32)",0.027,0.0818125,0.0212086%,1.04283%,0,1,Delegate/Slice (ND	 X32):16
Static Reshape (NC),0.014,0.0745938,0.0193372%,1.06217%,0,1,Delegate/Static Reshape (NC):17
"Slice (ND, X32)",0.018,0.0596563,0.0154649%,1.07763%,0,1,Delegate/Slice (ND	 X32):18
"Slice (ND, X32)",0.016,0.0378438,0.00981038%,1.08745%,0,1,Delegate/Slice (ND	 X32):19
Multiply (ND),0.016,0.00137392,0.0103288%,1.09777%,0,29,Delegate/Multiply (ND):20
Multiply (ND),0.014,0.0315625,0.00818207%,1.10596%,0,1,Delegate/Multiply (ND):21
Subtract (ND),0.016,0.0346562,0.00898407%,1.11494%,0,1,Delegate/Subtract (ND):22
Multiply (ND),0.013,0.0141789,0.106594%,1.22153%,0,29,Delegate/Multiply (ND):23
Multiply (ND),0.014,0.01018,0.0765307%,1.29806%,0,29,Delegate/Multiply (ND):24
Add (ND),0.014,0.02325,0.00602719%,1.30409%,0,1,Delegate/Add (ND):25
"Copy (NC, X32)",0.029,0.064,0.016591%,1.32068%,0,1,Delegate/Copy (NC	 X32):26
Static Reshape (NC),0.022,0.0320625,0.00831168%,1.32899%,0,1,Delegate/Static Reshape (NC):27
Static Reshape (NC),0,0.00025,6.48084e-05%,1.32906%,0,1,Delegate/Static Reshape (NC):28
"Slice (ND, X32)",0.011,0.0282188,0.00731525%,1.33637%,0,1,Delegate/Slice (ND	 X32):29
"Slice (ND, X32)",0.011,0.0275,0.00712893%,1.3435%,0,1,Delegate/Slice (ND	 X32):30
Multiply (ND),0.013,0.0200313,0.00519278%,1.3487%,0,1,Delegate/Multiply (ND):31
Multiply (ND),0.012,0.0146616,0.110223%,1.45892%,0,29,Delegate/Multiply (ND):32
Subtract (ND),0.012,0.015875,0.00411534%,1.46303%,0,1,Delegate/Subtract (ND):33
Multiply (ND),0.011,0.000581897,0.00437457%,1.46741%,0,29,Delegate/Multiply (ND):34
Multiply (ND),0.011,0.02075,0.0053791%,1.47279%,0,1,Delegate/Multiply (ND):35
Add (ND),0.011,0.0193125,0.00500645%,1.47779%,0,1,Delegate/Add (ND):36
"Copy (NC, X32)",0.022,0.0385625,0.0099967%,1.48779%,0,1,Delegate/Copy (NC	 X32):37
Static Reshape (NC),0,0.00015625,4.05053e-05%,1.48783%,0,1,Delegate/Static Reshape (NC):38
DYNAMIC_UPDATE_SLICE,0.004,0.00425,0.00110174%,1.48893%,0,1,[StatefulPartitionedCall:0]:56
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000299739%,1.48923%,0,1,[StatefulPartitionedCall:28]:57
Multiply (ND),0.016,0.0125525,0.0911126%,1.58035%,0,28,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.001,0.00100223,0.00727475%,1.58762%,0,28,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",0.919,0.850821,6.17573%,7.76335%,0,28,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000257813,0.00187134%,7.76522%,0,28,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,8.92857e-06,6.48084e-05%,7.76528%,0,28,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",1.361,1.35085,9.80519%,17.5705%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,5.13393e-05,0.000372649%,17.5708%,0,28,Delegate/Static Reshape (NC):6
Add (ND),0.029,0.0222377,0.161414%,17.7323%,0,28,Delegate/Add (ND):7
"Softmax (NC, F32)",0.038,0.0209967,0.152405%,17.8847%,0,28,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.51,1.48725,10.7953%,28.68%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0.001,0.000231027,0.00167692%,28.6816%,0,28,Delegate/Static Reshape (NC):10
Static Reshape (NC),0,5.13393e-05,0.000372649%,28.682%,0,28,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",1.388,1.36271,9.89127%,38.5733%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Transpose (ND, X32) Transpose",0.002,0.00158594,0.0115116%,38.5848%,0,28,Delegate/Transpose (ND	 X32) Transpose:14
Static Reshape (NC),0,3.34821e-06,2.43032e-05%,38.5848%,0,28,Delegate/Static Reshape (NC):15
"Fully Connected (NC, QD8, F32, QC8W) GEMM",0.655,0.668718,4.85392%,43.4387%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.022,0.0155737,0.113042%,43.5518%,0,28,Delegate/Add (ND):17
Multiply (ND),0.014,0.0104297,0.0757044%,43.6275%,0,28,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.001,0.0014375,0.0104342%,43.6379%,0,28,Delegate/Sum (ND) Reduce:19
Add (ND),0,1.78571e-05,0.000129617%,43.638%,0,28,Delegate/Add (ND):21
Reciprocal Square Root (NC),0,2.23214e-06,1.62021e-05%,43.6381%,0,28,Delegate/Reciprocal Square Root (NC):22
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.687,1.69552,12.307%,55.9451%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
Sigmoid (NC),0.024,0.018606,0.135053%,56.0802%,0,28,Delegate/Sigmoid (NC):26
Multiply (ND),0.021,0.0105658,0.0766927%,56.1568%,0,28,Delegate/Multiply (ND):27
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.749,1.6919,12.2808%,68.4376%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
Multiply (ND),0.013,0.0154621,0.112232%,68.5498%,0,28,Delegate/Multiply (ND):29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.74,1.6839,12.2227%,80.7725%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
Add (ND),0.038,0.0179687,0.130427%,80.9029%,0,28,Delegate/Add (ND):31
Sum (ND) Reduce,0.001,0.00117299,0.00851421%,80.9115%,0,28,Delegate/Sum (ND) Reduce:33
Add (ND),0,8.92857e-06,6.48084e-05%,80.9115%,0,28,Delegate/Add (ND):35
Reciprocal Square Root (NC),0,5.58036e-06,4.05053e-05%,80.9116%,0,28,Delegate/Reciprocal Square Root (NC):36
Multiply (ND),0.013,0.013567,0.0984764%,81.01%,0,28,Delegate/Multiply (ND):37
Multiply (ND),0.007,0.00946205,0.0686807%,81.0787%,0,28,Delegate/Multiply (ND):38
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.092,2.29724,16.6746%,97.7533%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
Static Reshape (NC),0.017,0.0164549,0.115173%,97.8685%,0,27,Delegate/Static Reshape (NC):40
"Slice (ND, X32)",0.018,0.0131146,0.0917931%,97.9603%,0,27,Delegate/Slice (ND	 X32):41
"Slice (ND, X32)",0.013,0.0130162,0.0911045%,98.0514%,0,27,Delegate/Slice (ND	 X32):42
"Slice (ND, X32)",0.024,0.0121806,0.0852555%,98.1367%,0,27,Delegate/Slice (ND	 X32):43
Static Reshape (NC),0.016,0.0122731,0.0859036%,98.2226%,0,27,Delegate/Static Reshape (NC):44
"Slice (ND, X32)",0.012,0.0120394,0.0842672%,98.3068%,0,27,Delegate/Slice (ND	 X32):45
"Slice (ND, X32)",0.012,0.0113843,0.079682%,98.3865%,0,27,Delegate/Slice (ND	 X32):46
Multiply (ND),0.011,0.0118831,0.0831735%,98.4697%,0,27,Delegate/Multiply (ND):47
Multiply (ND),0.011,0.012059,0.0844049%,98.5541%,0,27,Delegate/Multiply (ND):48
Subtract (ND),0.011,0.0120324,0.0842186%,98.6383%,0,27,Delegate/Subtract (ND):49
Multiply (ND),0.011,0.0120914,0.0846317%,98.7229%,0,27,Delegate/Multiply (ND):50
Multiply (ND),0.011,0.0116701,0.0816829%,98.8046%,0,27,Delegate/Multiply (ND):51
Add (ND),0.011,0.0117859,0.082493%,98.8871%,0,27,Delegate/Add (ND):52
"Copy (NC, X32)",0.022,0.022735,0.159129%,99.0462%,0,27,Delegate/Copy (NC	 X32):53
Static Reshape (NC),0.011,0.0116632,0.0816343%,99.1279%,0,27,Delegate/Static Reshape (NC):54
Static Reshape (NC),0,2.31481e-05,0.000162021%,99.128%,0,27,Delegate/Static Reshape (NC):55
"Slice (ND, X32)",0.011,0.0118727,0.0831006%,99.2111%,0,27,Delegate/Slice (ND	 X32):56
"Slice (ND, X32)",0.01,0.0121319,0.0849153%,99.2961%,0,27,Delegate/Slice (ND	 X32):57
Multiply (ND),0.011,0.0120243,0.0841619%,99.3802%,0,27,Delegate/Multiply (ND):58
Multiply (ND),0.011,0.0117951,0.0825579%,99.4628%,0,27,Delegate/Multiply (ND):59
Subtract (ND),0.01,0.0118206,0.0827361%,99.5455%,0,27,Delegate/Subtract (ND):60
Multiply (ND),0.011,0.0122164,0.0855066%,99.631%,0,27,Delegate/Multiply (ND):61
Multiply (ND),0.011,0.0118056,0.0826308%,99.7136%,0,27,Delegate/Multiply (ND):62
Add (ND),0.011,0.0122824,0.0859684%,99.7996%,0,27,Delegate/Add (ND):63
"Copy (NC, X32)",0.022,0.0227812,0.159453%,99.9591%,0,27,Delegate/Copy (NC	 X32):64
Static Reshape (NC),0,2.08333e-05,0.000145819%,99.9592%,0,27,Delegate/Static Reshape (NC):65
DYNAMIC_UPDATE_SLICE,0.005,0.00471875,0.00122326%,99.9604%,0,1,[StatefulPartitionedCall:1]:110
DYNAMIC_UPDATE_SLICE,0.002,0.00153125,0.000396952%,99.9608%,0,1,[StatefulPartitionedCall:29]:111
DYNAMIC_UPDATE_SLICE,0.005,0.00484375,0.00125566%,99.9621%,0,1,[StatefulPartitionedCall:12]:164
DYNAMIC_UPDATE_SLICE,0.001,0.00115625,0.000299739%,99.9624%,0,1,[StatefulPartitionedCall:40]:165
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00119086%,99.9636%,0,1,[StatefulPartitionedCall:21]:218
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.00030784%,99.9639%,0,1,[StatefulPartitionedCall:49]:219
DYNAMIC_UPDATE_SLICE,0.004,0.00446875,0.00115845%,99.965%,0,1,[StatefulPartitionedCall:22]:272
DYNAMIC_UPDATE_SLICE,0.001,0.00128125,0.000332143%,99.9654%,0,1,[StatefulPartitionedCall:50]:273
DYNAMIC_UPDATE_SLICE,0.004,0.0046875,0.00121516%,99.9666%,0,1,[StatefulPartitionedCall:23]:326
DYNAMIC_UPDATE_SLICE,0.001,0.001125,0.000291638%,99.9669%,0,1,[StatefulPartitionedCall:51]:327
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00118275%,99.9681%,0,1,[StatefulPartitionedCall:24]:380
DYNAMIC_UPDATE_SLICE,0.001,0.00134375,0.000348345%,99.9684%,0,1,[StatefulPartitionedCall:52]:381
DYNAMIC_UPDATE_SLICE,0.005,0.00440625,0.00114225%,99.9696%,0,1,[StatefulPartitionedCall:25]:434
DYNAMIC_UPDATE_SLICE,0.001,0.00125,0.000324042%,99.9699%,0,1,[StatefulPartitionedCall:53]:435
DYNAMIC_UPDATE_SLICE,0.004,0.0044375,0.00115035%,99.971%,0,1,[StatefulPartitionedCall:26]:488
DYNAMIC_UPDATE_SLICE,0.002,0.00140625,0.000364547%,99.9714%,0,1,[StatefulPartitionedCall:54]:489
DYNAMIC_UPDATE_SLICE,0.005,0.00446875,0.00115845%,99.9726%,0,1,[StatefulPartitionedCall:27]:542
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000315941%,99.9729%,0,1,[StatefulPartitionedCall:55]:543
DYNAMIC_UPDATE_SLICE,0.004,0.004375,0.00113415%,99.974%,0,1,[StatefulPartitionedCall:2]:596
DYNAMIC_UPDATE_SLICE,0.001,0.0014375,0.000372649%,99.9744%,0,1,[StatefulPartitionedCall:30]:597
DYNAMIC_UPDATE_SLICE,0.005,0.00465625,0.00120706%,99.9756%,0,1,[StatefulPartitionedCall:3]:650
DYNAMIC_UPDATE_SLICE,0.001,0.00128125,0.000332143%,99.9759%,0,1,[StatefulPartitionedCall:31]:651
DYNAMIC_UPDATE_SLICE,0.004,0.0044375,0.00115035%,99.9771%,0,1,[StatefulPartitionedCall:4]:704
DYNAMIC_UPDATE_SLICE,0.002,0.0014375,0.000372649%,99.9774%,0,1,[StatefulPartitionedCall:32]:705
DYNAMIC_UPDATE_SLICE,0.005,0.004625,0.00119896%,99.9786%,0,1,[StatefulPartitionedCall:5]:758
DYNAMIC_UPDATE_SLICE,0.001,0.001125,0.000291638%,99.9789%,0,1,[StatefulPartitionedCall:33]:759
DYNAMIC_UPDATE_SLICE,0.005,0.0045,0.00116655%,99.9801%,0,1,[StatefulPartitionedCall:6]:812
DYNAMIC_UPDATE_SLICE,0.001,0.001375,0.000356446%,99.9804%,0,1,[StatefulPartitionedCall:34]:813
DYNAMIC_UPDATE_SLICE,0.005,0.00446875,0.00115845%,99.9816%,0,1,[StatefulPartitionedCall:7]:866
DYNAMIC_UPDATE_SLICE,0.001,0.001125,0.000291638%,99.9819%,0,1,[StatefulPartitionedCall:35]:867
DYNAMIC_UPDATE_SLICE,0.004,0.00465625,0.00120706%,99.9831%,0,1,[StatefulPartitionedCall:8]:920
DYNAMIC_UPDATE_SLICE,0.001,0.00146875,0.00038075%,99.9835%,0,1,[StatefulPartitionedCall:36]:921
DYNAMIC_UPDATE_SLICE,0.005,0.004375,0.00113415%,99.9846%,0,1,[StatefulPartitionedCall:9]:974
DYNAMIC_UPDATE_SLICE,0.001,0.00121875,0.000315941%,99.9849%,0,1,[StatefulPartitionedCall:37]:975
DYNAMIC_UPDATE_SLICE,0.006,0.00459375,0.00119086%,99.9861%,0,1,[StatefulPartitionedCall:10]:1028
DYNAMIC_UPDATE_SLICE,0.001,0.00128125,0.000332143%,99.9865%,0,1,[StatefulPartitionedCall:38]:1029
DYNAMIC_UPDATE_SLICE,0.005,0.00453125,0.00117465%,99.9876%,0,1,[StatefulPartitionedCall:11]:1082
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.00030784%,99.9879%,0,1,[StatefulPartitionedCall:39]:1083
DYNAMIC_UPDATE_SLICE,0.005,0.00459375,0.00119086%,99.9891%,0,1,[StatefulPartitionedCall:13]:1136
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000340244%,99.9895%,0,1,[StatefulPartitionedCall:41]:1137
DYNAMIC_UPDATE_SLICE,0.005,0.0045625,0.00118275%,99.9907%,0,1,[StatefulPartitionedCall:14]:1190
DYNAMIC_UPDATE_SLICE,0.001,0.0011875,0.00030784%,99.991%,0,1,[StatefulPartitionedCall:42]:1191
DYNAMIC_UPDATE_SLICE,0.005,0.0044375,0.00115035%,99.9921%,0,1,[StatefulPartitionedCall:15]:1244
DYNAMIC_UPDATE_SLICE,0.001,0.00128125,0.000332143%,99.9924%,0,1,[StatefulPartitionedCall:43]:1245
DYNAMIC_UPDATE_SLICE,0.005,0.00475,0.00123136%,99.9937%,0,1,[StatefulPartitionedCall:16]:1298
DYNAMIC_UPDATE_SLICE,0.001,0.0010625,0.000275436%,99.994%,0,1,[StatefulPartitionedCall:44]:1299
DYNAMIC_UPDATE_SLICE,0.005,0.0044375,0.00115035%,99.9951%,0,1,[StatefulPartitionedCall:17]:1352
DYNAMIC_UPDATE_SLICE,0.001,0.0013125,0.000340244%,99.9954%,0,1,[StatefulPartitionedCall:45]:1353
DYNAMIC_UPDATE_SLICE,0.005,0.00440625,0.00114225%,99.9966%,0,1,[StatefulPartitionedCall:18]:1406
DYNAMIC_UPDATE_SLICE,0.001,0.001375,0.000356446%,99.9969%,0,1,[StatefulPartitionedCall:46]:1407
DYNAMIC_UPDATE_SLICE,0.005,0.004625,0.00119896%,99.9981%,0,1,[StatefulPartitionedCall:19]:1460
DYNAMIC_UPDATE_SLICE,0.002,0.001375,0.000356446%,99.9985%,0,1,[StatefulPartitionedCall:47]:1461
DYNAMIC_UPDATE_SLICE,0.005,0.0046875,0.00121516%,99.9997%,0,1,[StatefulPartitionedCall:20]:1514
DYNAMIC_UPDATE_SLICE,0.001,0.00109375,0.000283537%,100%,0,1,[StatefulPartitionedCall:48]:1515

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.092,2.29724,16.6746%,16.6746%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:39
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.687,1.69552,12.307%,28.9817%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.749,1.6919,12.2808%,41.2624%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.74,1.6839,12.2227%,53.4851%,0,28,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:30
EMBEDDING_LOOKUP,0.009,1.52225,0.394619%,53.8797%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
"Transpose (ND, X32) Transpose",1.51,1.48725,10.7953%,64.675%,0,28,Delegate/Transpose (ND	 X32) Transpose:9
"Batch Matrix Multiply (NC, F32) GEMM",1.388,1.36271,9.89127%,74.5663%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Batch Matrix Multiply (NC, F32) GEMM",1.361,1.35085,9.80519%,84.3715%,0,28,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
"Fully Connected (NC, QD8, F32, QC8W) GEMM",1.136,1.13069,0.293112%,84.6646%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:12
"Transpose (ND, X32) Transpose",0.919,0.850821,6.17573%,90.8403%,0,28,Delegate/Transpose (ND	 X32) Transpose:2

Number of nodes executed: 172
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,226.172,58.6429%,58.6429%,0,141
"Batch Matrix Multiply (NC, F32) GEMM",2,75.978,19.6999%,78.3428%,0,56
"Transpose (ND, X32) Transpose",4,65.538,16.993%,95.3357%,0,112
Multiply (ND),27,6.52,1.69053%,97.0263%,0,537
"Slice (ND, X32)",14,2.77,0.718218%,97.7445%,0,196
Add (ND),10,2.252,0.583908%,98.3284%,0,197
Static Reshape (NC),18,1.557,0.403706%,98.7321%,0,338
EMBEDDING_LOOKUP,1,1.522,0.394631%,99.1267%,0,1
"Copy (NC, X32)",4,1.33,0.344848%,99.4716%,0,56
Subtract (ND),4,0.692,0.179425%,99.651%,0,56
"Softmax (NC, F32)",1,0.587,0.1522%,99.8032%,0,28
Sigmoid (NC),1,0.52,0.134828%,99.938%,0,28
DYNAMIC_UPDATE_SLICE,56,0.14,0.0362998%,99.9743%,0,56
Sum (ND) Reduce,3,0.073,0.0189278%,99.9933%,0,57
GATHER_ND,1,0.009,0.00233356%,99.9956%,0,1
REDUCE_ALL,1,0.003,0.000777853%,99.9964%,0,1
SELECT_V2,1,0.002,0.000518569%,99.9969%,0,1
RESHAPE,4,0.002,0.000518569%,99.9974%,0,4
LESS,1,0.002,0.000518569%,99.9979%,0,1
ADD,1,0.002,0.000518569%,99.9985%,0,1
SELECT,1,0.001,0.000259284%,99.9987%,0,1
PACK,1,0.001,0.000259284%,99.999%,0,1
LOGICAL_AND,1,0.001,0.000259284%,99.9992%,0,1
LESS_EQUAL,1,0.001,0.000259284%,99.9995%,0,1
GREATER_EQUAL,1,0.001,0.000259284%,99.9997%,0,1
CAST,2,0.001,0.000259284%,100%,0,2
Sine (NC),1,0,0%,100%,0,1
Reciprocal Square Root (NC),3,0,0%,100%,0,57
Cosine (NC),1,0,0%,100%,0,1

Timings (microseconds): count=32 first=771312 curr=369924 min=367225 max=771312 avg=385752 std=69679
Memory (bytes): count=0
172 nodes observed

Subgraph (index: 1, name: prefill_128) profile:
============================== Run Order ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
RESHAPE,0.002,0.002,4.14593e-05%,4.14593e-05%,0,1,[arith.constant222]:0
EMBEDDING_LOOKUP,103.03,103.03,2.13578%,2.13582%,0,1,[arith.constant223]:1
CAST,0.231,0.231,0.00478855%,2.14061%,0,1,[arith.constant225]:3
LESS,0.04,0.04,0.000829186%,2.14144%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;1]:8
ADD,0.007,0.007,0.000145108%,2.14158%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;2]:9
SELECT,0.003,0.003,6.2189e-05%,2.14164%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;3]:10
RESHAPE,0.001,0.001,2.07297e-05%,2.14166%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;4]:11
CAST,0.002,0.002,4.14593e-05%,2.14171%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:12
GREATER_EQUAL,0.005,0.005,0.000103648%,2.14181%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:13
LESS_EQUAL,0.005,0.005,0.000103648%,2.14191%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:14
LOGICAL_AND,0.003,0.003,6.2189e-05%,2.14197%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:15
REDUCE_ALL,0.027,0.027,0.000559701%,2.14253%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:16
GATHER_ND,2.184,2.184,0.0452736%,2.18781%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17
RESHAPE,0.002,0.002,4.14593e-05%,2.18785%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:19
SLICE,0.004,0.004,8.29186e-05%,2.18793%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;18]:57
RESHAPE,0,0,0%,2.18793%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;19]:58
PACK,0.003,0.003,6.2189e-05%,2.18799%,0,1,[tfl.pack]:59
Static Reshape (NC),0.296,0.296,0.00613598%,2.19413%,0,1,Delegate/Static Reshape (NC):0
Static Reshape (NC),0.001,0.001,2.07297e-05%,2.19415%,0,1,Delegate/Static Reshape (NC):1
Multiply (ND),0.028,0.028,0.00058043%,2.19473%,0,1,Delegate/Multiply (ND):2
Cosine (NC),0.044,0.044,0.000912105%,2.19564%,0,1,Delegate/Cosine (NC):3
Sine (NC),0.034,0.034,0.000704808%,2.19635%,0,1,Delegate/Sine (NC):4
Static Reshape (NC),0.066,0.066,0.00136816%,2.19772%,0,1,Delegate/Static Reshape (NC):5
Multiply (ND),0.323,0.323,0.00669568%,2.20441%,0,1,Delegate/Multiply (ND):6
Sum (ND) Reduce,0.11,0.11,0.00228026%,2.20669%,0,1,Delegate/Sum (ND) Reduce:7
Multiply (ND),0.026,0.026,0.000538971%,2.20723%,0,1,Delegate/Multiply (ND):8
Add (ND),0.018,0.018,0.000373134%,2.20761%,0,1,Delegate/Add (ND):9
Static Reshape (NC),0,0.000428571,0.000248756%,2.20785%,0,28,Delegate/Static Reshape (NC):10
Reciprocal Square Root (NC),0,0,0%,2.20785%,0,1,Delegate/Reciprocal Square Root (NC):11
Multiply (ND),0.227,0.227,0.00470563%,2.21256%,0,1,Delegate/Multiply (ND):12
Multiply (ND),0.135,0.135,0.0027985%,2.21536%,0,1,Delegate/Multiply (ND):13
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.6,25.6,0.530679%,2.74604%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
Static Reshape (NC),0.255,0.00914286,0.00530679%,2.75134%,0,28,Delegate/Static Reshape (NC):15
"Slice (ND, X32)",0.314,0.314,0.00650911%,2.75785%,0,1,Delegate/Slice (ND	 X32):16
"Slice (ND, X32)",0.148,0.148,0.00306799%,2.76092%,0,1,Delegate/Slice (ND	 X32):17
"Slice (ND, X32)",0.096,0.096,0.00199005%,2.76291%,0,1,Delegate/Slice (ND	 X32):18
Static Reshape (NC),0,0,0%,2.76291%,0,1,Delegate/Static Reshape (NC):19
"Transpose (ND, X32) Transpose",0.431,0.431,0.00893448%,2.77185%,0,1,Delegate/Transpose (ND	 X32) Transpose:20
"Slice (ND, X32)",0.193,0.193,0.00400082%,2.77585%,0,1,Delegate/Slice (ND	 X32):21
"Slice (ND, X32)",0.2,0.2,0.00414593%,2.77999%,0,1,Delegate/Slice (ND	 X32):22
Multiply (ND),0.158,0.158,0.00327529%,2.78327%,0,1,Delegate/Multiply (ND):23
Multiply (ND),0.1,0.115643,0.0671226%,2.85039%,0,28,Delegate/Multiply (ND):24
Subtract (ND),0.052,0.052,0.00107794%,2.85147%,0,1,Delegate/Subtract (ND):25
Multiply (ND),0.054,0.054,0.0011194%,2.85259%,0,1,Delegate/Multiply (ND):26
Multiply (ND),0.113,0.113,0.00234245%,2.85493%,0,1,Delegate/Multiply (ND):27
Add (ND),0.064,0.064,0.0013267%,2.85626%,0,1,Delegate/Add (ND):28
"Copy (NC, X32)",0.399,0.399,0.00827113%,2.86453%,0,1,Delegate/Copy (NC	 X32):29
"Transpose (ND, X32) Transpose",0.311,0.311,0.00644692%,2.87097%,0,1,Delegate/Transpose (ND	 X32) Transpose:30
"Transpose (ND, X32) Transpose",0.116,0.116,0.00240464%,2.87338%,0,1,Delegate/Transpose (ND	 X32) Transpose:31
"Slice (ND, X32)",0.06,0.06,0.00124378%,2.87462%,0,1,Delegate/Slice (ND	 X32):32
"Slice (ND, X32)",0.034,0.034,0.000704808%,2.87533%,0,1,Delegate/Slice (ND	 X32):33
Multiply (ND),0.047,0.047,0.000974294%,2.8763%,0,1,Delegate/Multiply (ND):34
Multiply (ND),0.041,0.0224643,0.013039%,2.88934%,0,28,Delegate/Multiply (ND):35
Subtract (ND),0.019,0.019,0.000393864%,2.88974%,0,1,Delegate/Subtract (ND):36
Multiply (ND),0.029,0.029,0.00060116%,2.89034%,0,1,Delegate/Multiply (ND):37
Multiply (ND),0.032,0.032,0.000663349%,2.891%,0,1,Delegate/Multiply (ND):38
Add (ND),0.017,0.017,0.000352404%,2.89135%,0,1,Delegate/Add (ND):39
"Copy (NC, X32)",0.114,0.114,0.00236318%,2.89372%,0,1,Delegate/Copy (NC	 X32):40
"Transpose (ND, X32) Transpose",0.048,0.048,0.000995024%,2.89471%,0,1,Delegate/Transpose (ND	 X32) Transpose:41
SELECT_V2,0.243,0.243,0.00503731%,2.89975%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:20
DYNAMIC_UPDATE_SLICE,0.096,0.096,0.00199005%,2.90174%,0,1,[StatefulPartitionedCall:0]:60
DYNAMIC_UPDATE_SLICE,0.096,0.096,0.00199005%,2.90373%,0,1,[StatefulPartitionedCall:28]:61
Multiply (ND),0.232,0.211556,0.118408%,3.02214%,0,27,Delegate/Multiply (ND):0
"Transpose (ND, X32) Transpose",0.272,0.266741,0.149295%,3.17143%,0,27,Delegate/Transpose (ND	 X32) Transpose:1
"Transpose (ND, X32) Transpose",1.141,1.11685,0.625103%,3.79653%,0,27,Delegate/Transpose (ND	 X32) Transpose:2
Static Reshape (NC),0,0.000296296,0.000165837%,3.7967%,0,27,Delegate/Static Reshape (NC):3
Static Reshape (NC),0,7.40741e-05,4.14593e-05%,3.79674%,0,27,Delegate/Static Reshape (NC):4
"Batch Matrix Multiply (NC, F32) GEMM",10.339,10.365,5.80128%,9.59802%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Static Reshape (NC),0,3.7037e-05,2.07297e-05%,9.59804%,0,27,Delegate/Static Reshape (NC):6
Add (ND),1.96,1.93489,1.08296%,10.681%,0,27,Delegate/Add (ND):7
"Softmax (NC, F32)",1.923,1.87989,1.05218%,11.7332%,0,27,Delegate/Softmax (NC	 F32):8
"Transpose (ND, X32) Transpose",1.762,1.77741,0.994816%,12.728%,0,27,Delegate/Transpose (ND	 X32) Transpose:9
Static Reshape (NC),0,0,0%,12.728%,0,27,Delegate/Static Reshape (NC):11
"Batch Matrix Multiply (NC, F32) GEMM",13.829,10.4737,5.86214%,18.5901%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Static Reshape (NC),0,3.7037e-05,2.07297e-05%,18.5902%,0,27,Delegate/Static Reshape (NC):13
"Transpose (ND, X32) Transpose",0.265,0.245407,0.137355%,18.7275%,0,27,Delegate/Transpose (ND	 X32) Transpose:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.567,10.616,5.9418%,24.6693%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
Add (ND),0.271,0.281852,0.157753%,24.8271%,0,27,Delegate/Add (ND):17
Multiply (ND),0.117,0.129963,0.0727404%,24.8998%,0,27,Delegate/Multiply (ND):18
Sum (ND) Reduce,0.102,0.0996296,0.0557628%,24.9556%,0,27,Delegate/Sum (ND) Reduce:19
Multiply (ND),0.025,0.0215556,0.0120647%,24.9676%,0,27,Delegate/Multiply (ND):20
Add (ND),0.02,0.0142222,0.00796019%,24.9756%,0,27,Delegate/Add (ND):21
Static Reshape (NC),0,0,0%,24.9756%,0,27,Delegate/Static Reshape (NC):22
Reciprocal Square Root (NC),0,0.000481481,0.000269486%,24.9759%,0,27,Delegate/Reciprocal Square Root (NC):23
Multiply (ND),0.243,0.16037,0.0897594%,25.0656%,0,27,Delegate/Multiply (ND):25
"Fully Connected (NC, QD8, F32, QC8W) GEMM",26.031,25.804,14.4425%,39.5081%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
Sigmoid (NC),0.559,0.581407,0.325414%,39.8336%,0,27,Delegate/Sigmoid (NC):27
Multiply (ND),0.839,0.844519,0.472678%,40.3062%,0,27,Delegate/Multiply (ND):28
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.854,25.5488,14.2997%,54.6059%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
Multiply (ND),0.841,0.859111,0.480845%,55.0867%,0,27,Delegate/Multiply (ND):30
"Fully Connected (NC, QD8, F32, QC8W) GEMM",60.018,59.4334,33.2649%,88.3517%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
Add (ND),0.306,0.284556,0.159266%,88.5109%,0,27,Delegate/Add (ND):32
Multiply (ND),0.123,0.125519,0.0702528%,88.5812%,0,27,Delegate/Multiply (ND):33
Sum (ND) Reduce,0.096,0.0885185,0.0495439%,88.6307%,0,27,Delegate/Sum (ND) Reduce:34
Add (ND),0.017,0.0157778,0.00883083%,88.6396%,0,27,Delegate/Add (ND):36
Static Reshape (NC),0,0,0%,88.6396%,0,27,Delegate/Static Reshape (NC):37
Reciprocal Square Root (NC),0.001,0.000703704,0.000393864%,88.64%,0,27,Delegate/Reciprocal Square Root (NC):38
Multiply (ND),0.196,0.188593,0.105555%,88.7455%,0,27,Delegate/Multiply (ND):39
Multiply (ND),0.077,0.0853333,0.0477611%,88.7933%,0,27,Delegate/Multiply (ND):40
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.939,16.5485,9.26222%,98.0555%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
Static Reshape (NC),0.306,0.276148,0.15456%,98.2101%,0,27,Delegate/Static Reshape (NC):42
"Slice (ND, X32)",0.273,0.282407,0.158064%,98.3681%,0,27,Delegate/Slice (ND	 X32):43
"Slice (ND, X32)",0.168,0.148037,0.0828564%,98.451%,0,27,Delegate/Slice (ND	 X32):44
"Slice (ND, X32)",0.108,0.108,0.0582089%,98.5092%,0,26,Delegate/Slice (ND	 X32):45
Static Reshape (NC),0,0,0%,98.5092%,0,26,Delegate/Static Reshape (NC):46
"Transpose (ND, X32) Transpose",0.365,0.386192,0.208147%,98.7173%,0,26,Delegate/Transpose (ND	 X32) Transpose:47
"Slice (ND, X32)",0.186,0.189577,0.102176%,98.8195%,0,26,Delegate/Slice (ND	 X32):48
"Slice (ND, X32)",0.189,0.167462,0.0902569%,98.9098%,0,26,Delegate/Slice (ND	 X32):49
Multiply (ND),0.163,0.167308,0.090174%,98.9999%,0,26,Delegate/Multiply (ND):50
Multiply (ND),0.111,0.112444,0.0629352%,99.0629%,0,27,Delegate/Multiply (ND):51
Subtract (ND),0.054,0.0576538,0.0310738%,99.0939%,0,26,Delegate/Subtract (ND):52
Multiply (ND),0.055,0.0653846,0.0352404%,99.1292%,0,26,Delegate/Multiply (ND):53
Multiply (ND),0.137,0.132654,0.0714966%,99.2007%,0,26,Delegate/Multiply (ND):54
Add (ND),0.058,0.0633846,0.0341625%,99.2348%,0,26,Delegate/Add (ND):55
"Copy (NC, X32)",0.42,0.423462,0.228234%,99.4631%,0,26,Delegate/Copy (NC	 X32):56
"Transpose (ND, X32) Transpose",0.253,0.248346,0.133851%,99.5969%,0,26,Delegate/Transpose (ND	 X32) Transpose:57
"Transpose (ND, X32) Transpose",0.147,0.141154,0.0760778%,99.673%,0,26,Delegate/Transpose (ND	 X32) Transpose:58
"Slice (ND, X32)",0.07,0.0606923,0.0327114%,99.7057%,0,26,Delegate/Slice (ND	 X32):59
"Slice (ND, X32)",0.032,0.0335385,0.0180763%,99.7238%,0,26,Delegate/Slice (ND	 X32):60
Multiply (ND),0.048,0.0439615,0.023694%,99.7475%,0,26,Delegate/Multiply (ND):61
Multiply (ND),0.035,0.0371154,0.0200041%,99.7675%,0,26,Delegate/Multiply (ND):62
Subtract (ND),0.018,0.0236154,0.012728%,99.7802%,0,26,Delegate/Subtract (ND):63
Multiply (ND),0.021,0.0260769,0.0140547%,99.7943%,0,26,Delegate/Multiply (ND):64
Multiply (ND),0.034,0.0321538,0.01733%,99.8116%,0,26,Delegate/Multiply (ND):65
Add (ND),0.026,0.0227308,0.0122512%,99.8239%,0,26,Delegate/Add (ND):66
"Copy (NC, X32)",0.094,0.0897308,0.0483623%,99.8722%,0,26,Delegate/Copy (NC	 X32):67
"Transpose (ND, X32) Transpose",0.135,0.0549615,0.0296227%,99.9018%,0,26,Delegate/Transpose (ND	 X32) Transpose:68
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138889%,99.9032%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:117
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169983%,99.9049%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:118
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00143035%,99.9064%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:174
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00178275%,99.9081%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:175
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147181%,99.9096%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:231
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9114%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:232
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138889%,99.9128%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:288
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169983%,99.9145%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:289
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145108%,99.916%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:345
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9178%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:346
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00143035%,99.9192%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:402
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00178275%,99.921%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6;1]:403
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00151327%,99.9225%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:459
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174129%,99.9242%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:460
DYNAMIC_UPDATE_SLICE,0.07,0.07,0.00145108%,99.9257%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;4]:516
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169983%,99.9274%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;5]:517
DYNAMIC_UPDATE_SLICE,0.075,0.075,0.00155472%,99.9289%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:573
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174129%,99.9307%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;1]:574
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147181%,99.9322%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:630
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.934%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:631
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149254%,99.9354%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;4]:687
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184494%,99.9373%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;5]:688
DYNAMIC_UPDATE_SLICE,0.077,0.077,0.00159618%,99.9389%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;1]:744
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00176202%,99.9407%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;6]:745
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147181%,99.9421%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;3]:801
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9439%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;7]:802
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138889%,99.9453%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;9]:858
DYNAMIC_UPDATE_SLICE,0.083,0.083,0.00172056%,99.947%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;10]:859
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140962%,99.9484%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;12]:915
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169983%,99.9501%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;]:916
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00143035%,99.9516%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;13]:972
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9534%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;2]:973
DYNAMIC_UPDATE_SLICE,0.071,0.071,0.00147181%,99.9548%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;14]:1029
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174129%,99.9566%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;15]:1030
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138889%,99.958%,0,1,[StatefulPartitionedCall:11]:1086
DYNAMIC_UPDATE_SLICE,0.084,0.084,0.00174129%,99.9597%,0,1,[StatefulPartitionedCall:39]:1087
DYNAMIC_UPDATE_SLICE,0.073,0.073,0.00151327%,99.9612%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;]:1143
DYNAMIC_UPDATE_SLICE,0.086,0.086,0.00178275%,99.963%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1144
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00143035%,99.9644%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;]:1200
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9662%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1201
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00143035%,99.9677%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;3]:1257
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9695%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;4]:1258
DYNAMIC_UPDATE_SLICE,0.095,0.095,0.00196932%,99.9715%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;6]:1314
DYNAMIC_UPDATE_SLICE,0.093,0.093,0.00192786%,99.9734%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1315
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149254%,99.9749%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff;1]:1371
DYNAMIC_UPDATE_SLICE,0.085,0.085,0.00176202%,99.9766%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1372
DYNAMIC_UPDATE_SLICE,0.069,0.069,0.00143035%,99.9781%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1428
DYNAMIC_UPDATE_SLICE,0.082,0.082,0.00169983%,99.9798%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25;1]:1429
DYNAMIC_UPDATE_SLICE,0.072,0.072,0.00149254%,99.9813%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1485
DYNAMIC_UPDATE_SLICE,0.089,0.089,0.00184494%,99.9831%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;2]:1486
DYNAMIC_UPDATE_SLICE,0.067,0.067,0.00138889%,99.9845%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;4]:1542
DYNAMIC_UPDATE_SLICE,0.087,0.087,0.00180348%,99.9863%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;5]:1543
"Transpose (ND, X32) Transpose",0.107,0.107,0.00221807%,99.9885%,0,1,Delegate/Transpose (ND	 X32) Transpose:45
"Slice (ND, X32)",0.061,0.061,0.00126451%,99.9898%,0,1,Delegate/Slice (ND	 X32):46
"Slice (ND, X32)",0.039,0.039,0.000808457%,99.9906%,0,1,Delegate/Slice (ND	 X32):47
Multiply (ND),0.051,0.051,0.00105721%,99.9916%,0,1,Delegate/Multiply (ND):48
Multiply (ND),0.044,0.044,0.000912105%,99.9926%,0,1,Delegate/Multiply (ND):49
Subtract (ND),0.018,0.018,0.000373134%,99.9929%,0,1,Delegate/Subtract (ND):50
Multiply (ND),0.033,0.033,0.000684079%,99.9936%,0,1,Delegate/Multiply (ND):52
Add (ND),0.017,0.017,0.000352404%,99.994%,0,1,Delegate/Add (ND):53
"Copy (NC, X32)",0.087,0.087,0.00180348%,99.9958%,0,1,Delegate/Copy (NC	 X32):54
"Transpose (ND, X32) Transpose",0.057,0.057,0.00118159%,99.9969%,0,1,Delegate/Transpose (ND	 X32) Transpose:55
DYNAMIC_UPDATE_SLICE,0.068,0.068,0.00140962%,99.9984%,0,1,[Unknown]:1586
DYNAMIC_UPDATE_SLICE,0.079,0.079,0.00163764%,100%,0,1,[Unknown]:1587

============================== Top by Computation Time ==============================
node type,first,avg_ms,%,cdf%,mem KB,times called,name
EMBEDDING_LOOKUP,103.03,103.03,2.13578%,2.13578%,0,1,[arith.constant223]:1
"Fully Connected (NC, QD8, F32, QC8W) GEMM",60.018,59.4334,33.2649%,35.4007%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:31
"Fully Connected (NC, QD8, F32, QC8W) GEMM",26.031,25.804,14.4425%,49.8432%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:26
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.6,25.6,0.530679%,50.3739%,0,1,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:14
"Fully Connected (NC, QD8, F32, QC8W) GEMM",25.854,25.5488,14.2997%,64.6736%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:29
"Fully Connected (NC, QD8, F32, QC8W) GEMM",16.939,16.5485,9.26222%,73.9358%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:41
"Fully Connected (NC, QD8, F32, QC8W) GEMM",10.567,10.616,5.9418%,79.8776%,0,27,Delegate/Fully Connected (NC	 QD8	 F32	 QC8W) GEMM:16
"Batch Matrix Multiply (NC, F32) GEMM",13.829,10.4737,5.86214%,85.7397%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
"Batch Matrix Multiply (NC, F32) GEMM",10.339,10.365,5.80128%,91.541%,0,27,Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
GATHER_ND,2.184,2.184,0.0452736%,91.5863%,0,1,[ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:17

Number of nodes executed: 191
============================== Summary by node type ==============================
node type,count,avg_ms,avg %,cdf %,mem KB,times called
"Fully Connected (NC, QD8, F32, QC8W) GEMM",6,3750.27,77.7418%,77.7418%,0,136
"Batch Matrix Multiply (NC, F32) GEMM",2,562.644,11.6634%,89.4052%,0,54
"Transpose (ND, X32) Transpose",14,114.64,2.37645%,91.7817%,0,218
EMBEDDING_LOOKUP,1,103.03,2.13578%,93.9175%,0,1
Multiply (ND),33,92.24,1.9121%,95.8296%,0,522
Add (ND),11,70.7,1.46559%,97.2952%,0,191
"Softmax (NC, F32)",1,50.757,1.05218%,98.3473%,0,27
"Slice (ND, X32)",16,27.308,0.566086%,98.9134%,0,193
Sigmoid (NC),1,15.698,0.325414%,99.2388%,0,27
"Copy (NC, X32)",5,13.943,0.289034%,99.5279%,0,55
Static Reshape (NC),15,8.099,0.16789%,99.6958%,0,302
Sum (ND) Reduce,3,5.19,0.107587%,99.8034%,0,55
DYNAMIC_UPDATE_SLICE,56,4.413,0.09148%,99.8948%,0,56
Subtract (ND),5,2.202,0.0456467%,99.9405%,0,55
GATHER_ND,1,2.184,0.0452736%,99.9857%,0,1
SELECT_V2,1,0.243,0.00503731%,99.9908%,0,1
CAST,2,0.233,0.00483001%,99.9956%,0,2
Cosine (NC),1,0.044,0.000912105%,99.9965%,0,1
LESS,1,0.04,0.000829186%,99.9974%,0,1
Sine (NC),1,0.034,0.000704808%,99.9981%,0,1
Reciprocal Square Root (NC),3,0.032,0.000663349%,99.9987%,0,55
REDUCE_ALL,1,0.027,0.000559701%,99.9993%,0,1
ADD,1,0.007,0.000145108%,99.9994%,0,1
RESHAPE,4,0.005,0.000103648%,99.9995%,0,4
LESS_EQUAL,1,0.005,0.000103648%,99.9996%,0,1
GREATER_EQUAL,1,0.005,0.000103648%,99.9997%,0,1
SLICE,1,0.004,8.29186e-05%,99.9998%,0,1
SELECT,1,0.003,6.2189e-05%,99.9999%,0,1
PACK,1,0.003,6.2189e-05%,100%,0,1
LOGICAL_AND,1,0.003,6.2189e-05%,100%,0,1

Subgraph (index: 1, name: prefill_128) Timings (microseconds): count=1 curr=4824006
Memory (bytes): count=0
191 nodes observed


