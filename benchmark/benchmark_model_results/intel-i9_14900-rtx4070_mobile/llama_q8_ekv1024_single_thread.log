INFO: STARTING!
INFO: Log parameter values verbosely: [0]
INFO: Num threads: [1]
INFO: Report the peak memory footprint: [1]
INFO: Graph: [/home/geonha/workspace/ws_DS_NPU/llama-3.2-3b-it-q8/llama_q8_ekv1024.tflite]
INFO: Signature to run: []
INFO: Enable op profiling: [1]
INFO: Op profiling output mode.: [csv]
INFO: Op profiling output file.: [./ops_results/llama_q8_ekv1024_single_thread.csv]
INFO: #threads used for CPU inference: [1]
INFO: Use xnnpack: [1]
INFO: Loaded model /home/geonha/workspace/ws_DS_NPU/llama-3.2-3b-it-q8/llama_q8_ekv1024.tflite
INFO: XNNPACK delegate created.
INFO: Explicitly applied XNNPACK delegate, and the model graph will be partially executed by the delegate w/ 198 delegate kernels.
INFO: The input model file size (MB): 3286.63
INFO: Initialized session in 207.81ms.
INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
INFO: count=1 curr=1610377

INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
INFO: count=50 first=351017 curr=354848 min=348947 max=364170 avg=352772 std=3026

INFO: Inference timings in us: Init: 207810, First inference: 1610377, Warmup (avg): 1.61038e+06, Inference (avg): 352772
INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
INFO: Memory footprint delta from the start of the tool (MB): init=172 overall=3918.25
INFO: Overall peak memory footprint (MB) via periodic monitoring: 3927
INFO: Memory status at the end of exeution:
INFO: - VmRSS              : 3927 MB
INFO: + RssAnnon           : 785 MB
INFO: + RssFile + RssShmem : 3142 MB
