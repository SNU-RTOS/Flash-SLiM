INFO: STARTING!
INFO: Log parameter values verbosely: [0]
INFO: Num threads: [4]
INFO: Report the peak memory footprint: [1]
INFO: Graph: [models/mobileone_s0.tflite]
INFO: Signature to run: []
INFO: Enable op profiling: [1]
INFO: Op profiling output mode.: [csv]
INFO: Op profiling output file.: [./benchmark/benchmark_model_results/mobileone_s0_4threads_xnnpack.csv]
INFO: #threads used for CPU inference: [4]
INFO: Use gpu: [0]
INFO: Use xnnpack: [1]
INFO: Loaded model models/mobileone_s0.tflite
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
INFO: XNNPACK delegate created.
INFO: Explicitly applied XNNPACK delegate, and the model graph will be completely executed by the delegate.
INFO: The input model file size (MB): 8.35326
INFO: Initialized session in 32.314ms.
INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
INFO: count=353 first=6072 curr=1343 min=1250 max=6072 avg=1396.93 std=343 p5=1258 median=1339 p95=1648

INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
INFO: count=536 first=1427 curr=2307 min=1259 max=4016 avg=1817.43 std=453 p5=1306 median=1752 p95=2515

INFO: Inference timings in us: Init: 32314, First inference: 6072, Warmup (avg): 1396.93, Inference (avg): 1817.43
INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
INFO: Memory footprint delta from the start of the tool (MB): init=26 overall=27.5
INFO: Overall peak memory footprint (MB) via periodic monitoring: 32.5
INFO: Memory status at the end of exeution:
INFO: - VmRSS              : 32 MB
INFO: + RssAnnon           : 16 MB
INFO: + RssFile + RssShmem : 16 MB
