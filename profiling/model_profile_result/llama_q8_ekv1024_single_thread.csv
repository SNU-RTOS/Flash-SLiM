Profiling Info for Benchmark Initialization:
Primary graph (name: decode) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 1.095, 1.004, 17.0473%, 17.0473%, 256, 2, AllocateTensors/0
ModifyGraphWithDelegate, 8.676, 4.8855, 82.9527%, 100%, 256, 2, ModifyGraphWithDelegate/0

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 8.676, 4.8855, 82.9527%, 82.9527%, 256, 2, ModifyGraphWithDelegate/0
AllocateTensors, 1.095, 1.004, 17.0473%, 100%, 256, 2, AllocateTensors/0

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 9.771, 82.9527%, 82.9527%, 256, 2
AllocateTensors, 1, 2.008, 17.0473%, 100%, 256, 2

Timings (microseconds): count=1 curr=11779
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 1, name: prefill_128) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 1.069, 0.9985, 17.4365%, 17.4365%, 0, 2, AllocateTensors/1
ModifyGraphWithDelegate, 8.32, 4.728, 82.5635%, 100%, 0, 2, ModifyGraphWithDelegate/1

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 8.32, 4.728, 82.5635%, 82.5635%, 0, 2, ModifyGraphWithDelegate/1
AllocateTensors, 1.069, 0.9985, 17.4365%, 100%, 0, 2, AllocateTensors/1

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 9.456, 82.5635%, 82.5635%, 0, 2
AllocateTensors, 1, 1.997, 17.4365%, 100%, 0, 2

Subgraph (index: 1, name: prefill_128) Timings (microseconds): count=1 curr=11453
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 2, name: prefill_256) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 1.46, 1.323, 21.2428%, 21.2428%, 0, 2, AllocateTensors/2
ModifyGraphWithDelegate, 8.398, 4.905, 78.7572%, 100%, 0, 2, ModifyGraphWithDelegate/2

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 8.398, 4.905, 78.7572%, 78.7572%, 0, 2, ModifyGraphWithDelegate/2
AllocateTensors, 1.46, 1.323, 21.2428%, 100%, 0, 2, AllocateTensors/2

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 9.81, 78.7572%, 78.7572%, 0, 2
AllocateTensors, 1, 2.646, 21.2428%, 100%, 0, 2

Subgraph (index: 2, name: prefill_256) Timings (microseconds): count=1 curr=12456
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 3, name: prefill_512) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 1.214, 1.1875, 22.0254%, 22.0254%, 0, 2, AllocateTensors/3
ModifyGraphWithDelegate, 7.084, 4.204, 77.9746%, 100%, 0, 2, ModifyGraphWithDelegate/3

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 7.084, 4.204, 77.9746%, 77.9746%, 0, 2, ModifyGraphWithDelegate/3
AllocateTensors, 1.214, 1.1875, 22.0254%, 100%, 0, 2, AllocateTensors/3

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 8.408, 77.9746%, 77.9746%, 0, 2
AllocateTensors, 1, 2.375, 22.0254%, 100%, 0, 2

Subgraph (index: 3, name: prefill_512) Timings (microseconds): count=1 curr=10783
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 4, name: prefill_64) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 0.941, 0.905, 17.9706%, 17.9706%, 0, 2, AllocateTensors/4
ModifyGraphWithDelegate, 7.189, 4.131, 82.0294%, 100%, 0, 2, ModifyGraphWithDelegate/4

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 7.189, 4.131, 82.0294%, 82.0294%, 0, 2, ModifyGraphWithDelegate/4
AllocateTensors, 0.941, 0.905, 17.9706%, 100%, 0, 2, AllocateTensors/4

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 8.262, 82.0294%, 82.0294%, 0, 2
AllocateTensors, 1, 1.81, 17.9706%, 100%, 0, 2

Subgraph (index: 4, name: prefill_64) Timings (microseconds): count=1 curr=10072
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 5, name: prefill_8) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 0.907, 0.867, 17.7373%, 17.7373%, 0, 2, AllocateTensors/5
ModifyGraphWithDelegate, 7.021, 4.021, 82.2627%, 100%, 0, 2, ModifyGraphWithDelegate/5

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 7.021, 4.021, 82.2627%, 82.2627%, 0, 2, ModifyGraphWithDelegate/5
AllocateTensors, 0.907, 0.867, 17.7373%, 100%, 0, 2, AllocateTensors/5

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 8.042, 82.2627%, 82.2627%, 0, 2
AllocateTensors, 1, 1.734, 17.7373%, 100%, 0, 2

Subgraph (index: 5, name: prefill_8) Timings (microseconds): count=1 curr=9776
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 6, name: odml.scaled_dot_product_attention.impl) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.066, 0.043, 78.8991%, 78.8991%, 0, 2, ModifyGraphWithDelegate/6
AllocateTensors, 0.01, 0.00766667, 21.1009%, 100%, 0, 3, AllocateTensors/6

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.066, 0.043, 78.8991%, 78.8991%, 0, 2, ModifyGraphWithDelegate/6
AllocateTensors, 0.01, 0.00766667, 21.1009%, 100%, 0, 3, AllocateTensors/6

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.086, 78.8991%, 78.8991%, 0, 2
AllocateTensors, 1, 0.023, 21.1009%, 100%, 0, 3

Subgraph (index: 6, name: odml.scaled_dot_product_attention.impl) Timings (microseconds): count=1 curr=109
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 7, name: odml.scaled_dot_product_attention.impl_0) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 70.6897%, 70.6897%, 0, 2, ModifyGraphWithDelegate/7
AllocateTensors, 0.01, 0.00566667, 29.3103%, 100%, 0, 3, AllocateTensors/7

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 70.6897%, 70.6897%, 0, 2, ModifyGraphWithDelegate/7
AllocateTensors, 0.01, 0.00566667, 29.3103%, 100%, 0, 3, AllocateTensors/7

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 70.6897%, 70.6897%, 0, 2
AllocateTensors, 1, 0.017, 29.3103%, 100%, 0, 3

Subgraph (index: 7, name: odml.scaled_dot_product_attention.impl_0) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 8, name: odml.scaled_dot_product_attention.impl_1) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 75%, 75%, 0, 2, ModifyGraphWithDelegate/8
AllocateTensors, 0.008, 0.00433333, 25%, 100%, 0, 3, AllocateTensors/8

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 75%, 75%, 0, 2, ModifyGraphWithDelegate/8
AllocateTensors, 0.008, 0.00433333, 25%, 100%, 0, 3, AllocateTensors/8

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 75%, 75%, 0, 2
AllocateTensors, 1, 0.013, 25%, 100%, 0, 3

Subgraph (index: 8, name: odml.scaled_dot_product_attention.impl_1) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 9, name: odml.scaled_dot_product_attention.impl_2) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.021, 72.4138%, 72.4138%, 0, 2, ModifyGraphWithDelegate/9
AllocateTensors, 0.01, 0.00533333, 27.5862%, 100%, 0, 3, AllocateTensors/9

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.021, 72.4138%, 72.4138%, 0, 2, ModifyGraphWithDelegate/9
AllocateTensors, 0.01, 0.00533333, 27.5862%, 100%, 0, 3, AllocateTensors/9

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.042, 72.4138%, 72.4138%, 0, 2
AllocateTensors, 1, 0.016, 27.5862%, 100%, 0, 3

Subgraph (index: 9, name: odml.scaled_dot_product_attention.impl_2) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 10, name: odml.scaled_dot_product_attention.impl_3) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/10
AllocateTensors, 0.01, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/10

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/10
AllocateTensors, 0.01, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/10

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 70.9091%, 70.9091%, 0, 2
AllocateTensors, 1, 0.016, 29.0909%, 100%, 0, 3

Subgraph (index: 10, name: odml.scaled_dot_product_attention.impl_3) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 11, name: odml.scaled_dot_product_attention.impl_4) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/11
AllocateTensors, 0.009, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/11

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/11
AllocateTensors, 0.009, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/11

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 70.3704%, 70.3704%, 0, 2
AllocateTensors, 1, 0.016, 29.6296%, 100%, 0, 3

Subgraph (index: 11, name: odml.scaled_dot_product_attention.impl_4) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 12, name: odml.scaled_dot_product_attention.impl_5) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/12
AllocateTensors, 0.009, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/12

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/12
AllocateTensors, 0.009, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/12

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 69.8113%, 69.8113%, 0, 2
AllocateTensors, 1, 0.016, 30.1887%, 100%, 0, 3

Subgraph (index: 12, name: odml.scaled_dot_product_attention.impl_5) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 13, name: odml.scaled_dot_product_attention.impl_6) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.02, 74.0741%, 74.0741%, 0, 2, ModifyGraphWithDelegate/13
AllocateTensors, 0.008, 0.00466667, 25.9259%, 100%, 0, 3, AllocateTensors/13

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.02, 74.0741%, 74.0741%, 0, 2, ModifyGraphWithDelegate/13
AllocateTensors, 0.008, 0.00466667, 25.9259%, 100%, 0, 3, AllocateTensors/13

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 74.0741%, 74.0741%, 0, 2
AllocateTensors, 1, 0.014, 25.9259%, 100%, 0, 3

Subgraph (index: 13, name: odml.scaled_dot_product_attention.impl_6) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 14, name: odml.scaled_dot_product_attention.impl_7) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.0265, 75.7143%, 75.7143%, 0, 2, ModifyGraphWithDelegate/14
AllocateTensors, 0.01, 0.00566667, 24.2857%, 100%, 0, 3, AllocateTensors/14

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.0265, 75.7143%, 75.7143%, 0, 2, ModifyGraphWithDelegate/14
AllocateTensors, 0.01, 0.00566667, 24.2857%, 100%, 0, 3, AllocateTensors/14

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.053, 75.7143%, 75.7143%, 0, 2
AllocateTensors, 1, 0.017, 24.2857%, 100%, 0, 3

Subgraph (index: 14, name: odml.scaled_dot_product_attention.impl_7) Timings (microseconds): count=1 curr=70
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 15, name: odml.scaled_dot_product_attention.impl_8) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.023, 0.0175, 68.6275%, 68.6274%, 0, 2, ModifyGraphWithDelegate/15
AllocateTensors, 0.01, 0.00533333, 31.3725%, 100%, 0, 3, AllocateTensors/15

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.023, 0.0175, 68.6275%, 68.6274%, 0, 2, ModifyGraphWithDelegate/15
AllocateTensors, 0.01, 0.00533333, 31.3725%, 100%, 0, 3, AllocateTensors/15

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.035, 68.6275%, 68.6275%, 0, 2
AllocateTensors, 1, 0.016, 31.3726%, 100%, 0, 3

Subgraph (index: 15, name: odml.scaled_dot_product_attention.impl_8) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 16, name: odml.scaled_dot_product_attention.impl_9) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.022, 75.8621%, 75.8621%, 0, 2, ModifyGraphWithDelegate/16
AllocateTensors, 0.008, 0.00466667, 24.1379%, 100%, 0, 3, AllocateTensors/16

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.022, 75.8621%, 75.8621%, 0, 2, ModifyGraphWithDelegate/16
AllocateTensors, 0.008, 0.00466667, 24.1379%, 100%, 0, 3, AllocateTensors/16

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.044, 75.8621%, 75.8621%, 0, 2
AllocateTensors, 1, 0.014, 24.1379%, 100%, 0, 3

Subgraph (index: 16, name: odml.scaled_dot_product_attention.impl_9) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 17, name: odml.scaled_dot_product_attention.impl_10) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 9.27318%, 9.27318%, 0, 2, ModifyGraphWithDelegate/17
AllocateTensors, 0.356, 0.120667, 90.7268%, 100%, 0, 3, AllocateTensors/17

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
AllocateTensors, 0.356, 0.120667, 90.7268%, 90.7268%, 0, 3, AllocateTensors/17
ModifyGraphWithDelegate, 0.026, 0.0185, 9.27318%, 100%, 0, 2, ModifyGraphWithDelegate/17

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
AllocateTensors, 1, 0.362, 90.7268%, 90.7268%, 0, 3
ModifyGraphWithDelegate, 1, 0.037, 9.27318%, 100%, 0, 2

Subgraph (index: 17, name: odml.scaled_dot_product_attention.impl_10) Timings (microseconds): count=1 curr=399
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 18, name: odml.scaled_dot_product_attention.impl_11) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/18
AllocateTensors, 0.008, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/18

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/18
AllocateTensors, 0.008, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/18

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 18, name: odml.scaled_dot_product_attention.impl_11) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 19, name: odml.scaled_dot_product_attention.impl_12) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 42.0455%, 42.0455%, 0, 2, ModifyGraphWithDelegate/19
AllocateTensors, 0.046, 0.017, 57.9545%, 100%, 0, 3, AllocateTensors/19

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 42.0455%, 42.0455%, 0, 2, ModifyGraphWithDelegate/19
AllocateTensors, 0.046, 0.017, 57.9545%, 100%, 0, 3, AllocateTensors/19

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
AllocateTensors, 1, 0.051, 57.9545%, 57.9545%, 0, 3
ModifyGraphWithDelegate, 1, 0.037, 42.0455%, 100%, 0, 2

Subgraph (index: 19, name: odml.scaled_dot_product_attention.impl_12) Timings (microseconds): count=1 curr=88
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 20, name: odml.scaled_dot_product_attention.impl_13) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/20
AllocateTensors, 0.008, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/20

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/20
AllocateTensors, 0.008, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/20

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 20, name: odml.scaled_dot_product_attention.impl_13) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 21, name: odml.scaled_dot_product_attention.impl_14) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/21
AllocateTensors, 0.008, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/21

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/21
AllocateTensors, 0.008, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/21

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 21, name: odml.scaled_dot_product_attention.impl_14) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 22, name: odml.scaled_dot_product_attention.impl_15) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/22
AllocateTensors, 0.009, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/22

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/22
AllocateTensors, 0.009, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/22

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 73.0769%, 73.0769%, 0, 2
AllocateTensors, 1, 0.014, 26.9231%, 100%, 0, 3

Subgraph (index: 22, name: odml.scaled_dot_product_attention.impl_15) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 23, name: odml.scaled_dot_product_attention.impl_16) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0205, 70.6897%, 70.6897%, 0, 2, ModifyGraphWithDelegate/23
AllocateTensors, 0.012, 0.00566667, 29.3103%, 100%, 0, 3, AllocateTensors/23

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0205, 70.6897%, 70.6897%, 0, 2, ModifyGraphWithDelegate/23
AllocateTensors, 0.012, 0.00566667, 29.3103%, 100%, 0, 3, AllocateTensors/23

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 70.6897%, 70.6897%, 0, 2
AllocateTensors, 1, 0.017, 29.3103%, 100%, 0, 3

Subgraph (index: 23, name: odml.scaled_dot_product_attention.impl_16) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 24, name: odml.scaled_dot_product_attention.impl_17) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/24
AllocateTensors, 0.011, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/24

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/24
AllocateTensors, 0.011, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/24

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 67.9245%, 67.9245%, 0, 2
AllocateTensors, 1, 0.017, 32.0755%, 100%, 0, 3

Subgraph (index: 24, name: odml.scaled_dot_product_attention.impl_17) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 25, name: odml.scaled_dot_product_attention.impl_18) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 68.5185%, 68.5185%, 0, 2, ModifyGraphWithDelegate/25
AllocateTensors, 0.012, 0.00566667, 31.4815%, 100%, 0, 3, AllocateTensors/25

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 68.5185%, 68.5185%, 0, 2, ModifyGraphWithDelegate/25
AllocateTensors, 0.012, 0.00566667, 31.4815%, 100%, 0, 3, AllocateTensors/25

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 68.5185%, 68.5185%, 0, 2
AllocateTensors, 1, 0.017, 31.4815%, 100%, 0, 3

Subgraph (index: 25, name: odml.scaled_dot_product_attention.impl_18) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 26, name: odml.scaled_dot_product_attention.impl_19) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.024, 0.017, 56.6667%, 56.6667%, 0, 2, ModifyGraphWithDelegate/26
AllocateTensors, 0.02, 0.00866667, 43.3333%, 100%, 0, 3, AllocateTensors/26

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.024, 0.017, 56.6667%, 56.6667%, 0, 2, ModifyGraphWithDelegate/26
AllocateTensors, 0.02, 0.00866667, 43.3333%, 100%, 0, 3, AllocateTensors/26

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.034, 56.6667%, 56.6667%, 0, 2
AllocateTensors, 1, 0.026, 43.3333%, 100%, 0, 3

Subgraph (index: 26, name: odml.scaled_dot_product_attention.impl_19) Timings (microseconds): count=1 curr=60
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 27, name: odml.scaled_dot_product_attention.impl_20) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.024, 0.0175, 68.6275%, 68.6274%, 0, 2, ModifyGraphWithDelegate/27
AllocateTensors, 0.01, 0.00533333, 31.3725%, 100%, 0, 3, AllocateTensors/27

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.024, 0.0175, 68.6275%, 68.6274%, 0, 2, ModifyGraphWithDelegate/27
AllocateTensors, 0.01, 0.00533333, 31.3725%, 100%, 0, 3, AllocateTensors/27

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.035, 68.6275%, 68.6275%, 0, 2
AllocateTensors, 1, 0.016, 31.3726%, 100%, 0, 3

Subgraph (index: 27, name: odml.scaled_dot_product_attention.impl_20) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 28, name: odml.scaled_dot_product_attention.impl_21) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/28
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/28

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/28
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/28

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 28, name: odml.scaled_dot_product_attention.impl_21) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 29, name: odml.scaled_dot_product_attention.impl_22) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 65.4545%, 65.4545%, 0, 2, ModifyGraphWithDelegate/29
AllocateTensors, 0.013, 0.00633333, 34.5455%, 100%, 0, 3, AllocateTensors/29

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 65.4545%, 65.4545%, 0, 2, ModifyGraphWithDelegate/29
AllocateTensors, 0.013, 0.00633333, 34.5455%, 100%, 0, 3, AllocateTensors/29

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 65.4545%, 65.4545%, 0, 2
AllocateTensors, 1, 0.019, 34.5455%, 100%, 0, 3

Subgraph (index: 29, name: odml.scaled_dot_product_attention.impl_22) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 30, name: odml.scaled_dot_product_attention.impl_23) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/30
AllocateTensors, 0.008, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/30

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/30
AllocateTensors, 0.008, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/30

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 30, name: odml.scaled_dot_product_attention.impl_23) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 31, name: odml.scaled_dot_product_attention.impl_24) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.018, 73.4694%, 73.4694%, 0, 2, ModifyGraphWithDelegate/31
AllocateTensors, 0.008, 0.00433333, 26.5306%, 100%, 0, 3, AllocateTensors/31

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.018, 73.4694%, 73.4694%, 0, 2, ModifyGraphWithDelegate/31
AllocateTensors, 0.008, 0.00433333, 26.5306%, 100%, 0, 3, AllocateTensors/31

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 73.4694%, 73.4694%, 0, 2
AllocateTensors, 1, 0.013, 26.5306%, 100%, 0, 3

Subgraph (index: 31, name: odml.scaled_dot_product_attention.impl_24) Timings (microseconds): count=1 curr=49
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 32, name: odml.scaled_dot_product_attention.impl_25) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.02, 71.4286%, 71.4286%, 0, 2, ModifyGraphWithDelegate/32
AllocateTensors, 0.009, 0.00533333, 28.5714%, 100%, 0, 3, AllocateTensors/32

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.02, 71.4286%, 71.4286%, 0, 2, ModifyGraphWithDelegate/32
AllocateTensors, 0.009, 0.00533333, 28.5714%, 100%, 0, 3, AllocateTensors/32

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 71.4286%, 71.4286%, 0, 2
AllocateTensors, 1, 0.016, 28.5714%, 100%, 0, 3

Subgraph (index: 32, name: odml.scaled_dot_product_attention.impl_25) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 33, name: odml.scaled_dot_product_attention.impl_26) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.018, 73.4694%, 73.4694%, 0, 2, ModifyGraphWithDelegate/33
AllocateTensors, 0.008, 0.00433333, 26.5306%, 100%, 0, 3, AllocateTensors/33

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.018, 73.4694%, 73.4694%, 0, 2, ModifyGraphWithDelegate/33
AllocateTensors, 0.008, 0.00433333, 26.5306%, 100%, 0, 3, AllocateTensors/33

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 73.4694%, 73.4694%, 0, 2
AllocateTensors, 1, 0.013, 26.5306%, 100%, 0, 3

Subgraph (index: 33, name: odml.scaled_dot_product_attention.impl_26) Timings (microseconds): count=1 curr=49
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 34, name: odml.scaled_dot_product_attention.impl_27) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.022, 72.1311%, 72.1311%, 0, 2, ModifyGraphWithDelegate/34
AllocateTensors, 0.009, 0.00566667, 27.8689%, 100%, 0, 3, AllocateTensors/34

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.022, 72.1311%, 72.1311%, 0, 2, ModifyGraphWithDelegate/34
AllocateTensors, 0.009, 0.00566667, 27.8689%, 100%, 0, 3, AllocateTensors/34

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.044, 72.1311%, 72.1311%, 0, 2
AllocateTensors, 1, 0.017, 27.8689%, 100%, 0, 3

Subgraph (index: 34, name: odml.scaled_dot_product_attention.impl_27) Timings (microseconds): count=1 curr=61
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 35, name: odml.scaled_dot_product_attention.impl_28) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 61.194%, 61.194%, 0, 2, ModifyGraphWithDelegate/35
AllocateTensors, 0.02, 0.00866667, 38.806%, 100%, 0, 3, AllocateTensors/35

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 61.194%, 61.194%, 0, 2, ModifyGraphWithDelegate/35
AllocateTensors, 0.02, 0.00866667, 38.806%, 100%, 0, 3, AllocateTensors/35

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 61.194%, 61.194%, 0, 2
AllocateTensors, 1, 0.026, 38.806%, 100%, 0, 3

Subgraph (index: 35, name: odml.scaled_dot_product_attention.impl_28) Timings (microseconds): count=1 curr=67
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 36, name: odml.scaled_dot_product_attention.impl_29) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/36
AllocateTensors, 0.01, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/36

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/36
AllocateTensors, 0.01, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/36

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 69.6429%, 69.6429%, 0, 2
AllocateTensors, 1, 0.017, 30.3571%, 100%, 0, 3

Subgraph (index: 36, name: odml.scaled_dot_product_attention.impl_29) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 37, name: odml.scaled_dot_product_attention.impl_30) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 71.6981%, 71.6981%, 0, 2, ModifyGraphWithDelegate/37
AllocateTensors, 0.009, 0.005, 28.3019%, 100%, 0, 3, AllocateTensors/37

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 71.6981%, 71.6981%, 0, 2, ModifyGraphWithDelegate/37
AllocateTensors, 0.009, 0.005, 28.3019%, 100%, 0, 3, AllocateTensors/37

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 71.6981%, 71.6981%, 0, 2
AllocateTensors, 1, 0.015, 28.3019%, 100%, 0, 3

Subgraph (index: 37, name: odml.scaled_dot_product_attention.impl_30) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 38, name: odml.scaled_dot_product_attention.impl_31) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 64.9123%, 64.9123%, 0, 2, ModifyGraphWithDelegate/38
AllocateTensors, 0.014, 0.00666667, 35.0877%, 100%, 0, 3, AllocateTensors/38

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 64.9123%, 64.9123%, 0, 2, ModifyGraphWithDelegate/38
AllocateTensors, 0.014, 0.00666667, 35.0877%, 100%, 0, 3, AllocateTensors/38

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 64.9123%, 64.9123%, 0, 2
AllocateTensors, 1, 0.02, 35.0877%, 100%, 0, 3

Subgraph (index: 38, name: odml.scaled_dot_product_attention.impl_31) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 39, name: odml.scaled_dot_product_attention.impl_32) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0205, 73.2143%, 73.2143%, 0, 2, ModifyGraphWithDelegate/39
AllocateTensors, 0.01, 0.005, 26.7857%, 100%, 0, 3, AllocateTensors/39

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0205, 73.2143%, 73.2143%, 0, 2, ModifyGraphWithDelegate/39
AllocateTensors, 0.01, 0.005, 26.7857%, 100%, 0, 3, AllocateTensors/39

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 73.2143%, 73.2143%, 0, 2
AllocateTensors, 1, 0.015, 26.7857%, 100%, 0, 3

Subgraph (index: 39, name: odml.scaled_dot_product_attention.impl_32) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 40, name: odml.scaled_dot_product_attention.impl_33) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 72.2222%, 72.2222%, 0, 2, ModifyGraphWithDelegate/40
AllocateTensors, 0.01, 0.005, 27.7778%, 100%, 0, 3, AllocateTensors/40

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 72.2222%, 72.2222%, 0, 2, ModifyGraphWithDelegate/40
AllocateTensors, 0.01, 0.005, 27.7778%, 100%, 0, 3, AllocateTensors/40

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 72.2222%, 72.2222%, 0, 2
AllocateTensors, 1, 0.015, 27.7778%, 100%, 0, 3

Subgraph (index: 40, name: odml.scaled_dot_product_attention.impl_33) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 41, name: odml.scaled_dot_product_attention.impl_34) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/41
AllocateTensors, 0.009, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/41

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/41
AllocateTensors, 0.009, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/41

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 41, name: odml.scaled_dot_product_attention.impl_34) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 42, name: odml.scaled_dot_product_attention.impl_35) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/42
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/42

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/42
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/42

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 42, name: odml.scaled_dot_product_attention.impl_35) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 43, name: odml.scaled_dot_product_attention.impl_36) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/43
AllocateTensors, 0.012, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/43

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/43
AllocateTensors, 0.012, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/43

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 69.0909%, 69.0909%, 0, 2
AllocateTensors, 1, 0.017, 30.9091%, 100%, 0, 3

Subgraph (index: 43, name: odml.scaled_dot_product_attention.impl_36) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 44, name: odml.scaled_dot_product_attention.impl_37) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/44
AllocateTensors, 0.009, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/44

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/44
AllocateTensors, 0.009, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/44

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 73.0769%, 73.0769%, 0, 2
AllocateTensors, 1, 0.014, 26.9231%, 100%, 0, 3

Subgraph (index: 44, name: odml.scaled_dot_product_attention.impl_37) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 45, name: odml.scaled_dot_product_attention.impl_38) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 70.5882%, 70.5882%, 0, 2, ModifyGraphWithDelegate/45
AllocateTensors, 0.009, 0.005, 29.4118%, 100%, 0, 3, AllocateTensors/45

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 70.5882%, 70.5882%, 0, 2, ModifyGraphWithDelegate/45
AllocateTensors, 0.009, 0.005, 29.4118%, 100%, 0, 3, AllocateTensors/45

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 70.5882%, 70.5882%, 0, 2
AllocateTensors, 1, 0.015, 29.4118%, 100%, 0, 3

Subgraph (index: 45, name: odml.scaled_dot_product_attention.impl_38) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 46, name: odml.scaled_dot_product_attention.impl_39) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.02, 71.4286%, 71.4286%, 0, 2, ModifyGraphWithDelegate/46
AllocateTensors, 0.01, 0.00533333, 28.5714%, 100%, 0, 3, AllocateTensors/46

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.02, 71.4286%, 71.4286%, 0, 2, ModifyGraphWithDelegate/46
AllocateTensors, 0.01, 0.00533333, 28.5714%, 100%, 0, 3, AllocateTensors/46

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 71.4286%, 71.4286%, 0, 2
AllocateTensors, 1, 0.016, 28.5714%, 100%, 0, 3

Subgraph (index: 46, name: odml.scaled_dot_product_attention.impl_39) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 47, name: odml.scaled_dot_product_attention.impl_40) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 52.6316%, 52.6316%, 0, 2, ModifyGraphWithDelegate/47
AllocateTensors, 0.031, 0.012, 47.3684%, 100%, 0, 3, AllocateTensors/47

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 52.6316%, 52.6316%, 0, 2, ModifyGraphWithDelegate/47
AllocateTensors, 0.031, 0.012, 47.3684%, 100%, 0, 3, AllocateTensors/47

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 52.6316%, 52.6316%, 0, 2
AllocateTensors, 1, 0.036, 47.3684%, 100%, 0, 3

Subgraph (index: 47, name: odml.scaled_dot_product_attention.impl_40) Timings (microseconds): count=1 curr=76
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 48, name: odml.scaled_dot_product_attention.impl_41) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.042, 0.026, 77.6119%, 77.6119%, 0, 2, ModifyGraphWithDelegate/48
AllocateTensors, 0.009, 0.005, 22.3881%, 100%, 0, 3, AllocateTensors/48

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.042, 0.026, 77.6119%, 77.6119%, 0, 2, ModifyGraphWithDelegate/48
AllocateTensors, 0.009, 0.005, 22.3881%, 100%, 0, 3, AllocateTensors/48

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.052, 77.6119%, 77.6119%, 0, 2
AllocateTensors, 1, 0.015, 22.3881%, 100%, 0, 3

Subgraph (index: 48, name: odml.scaled_dot_product_attention.impl_41) Timings (microseconds): count=1 curr=67
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 49, name: odml.scaled_dot_product_attention.impl_42) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/49
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/49

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/49
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/49

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 49, name: odml.scaled_dot_product_attention.impl_42) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 50, name: odml.scaled_dot_product_attention.impl_43) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 64.4068%, 64.4068%, 0, 2, ModifyGraphWithDelegate/50
AllocateTensors, 0.015, 0.007, 35.5932%, 100%, 0, 3, AllocateTensors/50

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 64.4068%, 64.4068%, 0, 2, ModifyGraphWithDelegate/50
AllocateTensors, 0.015, 0.007, 35.5932%, 100%, 0, 3, AllocateTensors/50

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 64.4068%, 64.4068%, 0, 2
AllocateTensors, 1, 0.021, 35.5932%, 100%, 0, 3

Subgraph (index: 50, name: odml.scaled_dot_product_attention.impl_43) Timings (microseconds): count=1 curr=59
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 51, name: odml.scaled_dot_product_attention.impl_44) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.035, 0.023, 73.0159%, 73.0159%, 0, 2, ModifyGraphWithDelegate/51
AllocateTensors, 0.011, 0.00566667, 26.9841%, 100%, 0, 3, AllocateTensors/51

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.035, 0.023, 73.0159%, 73.0159%, 0, 2, ModifyGraphWithDelegate/51
AllocateTensors, 0.011, 0.00566667, 26.9841%, 100%, 0, 3, AllocateTensors/51

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.046, 73.0159%, 73.0159%, 0, 2
AllocateTensors, 1, 0.017, 26.9841%, 100%, 0, 3

Subgraph (index: 51, name: odml.scaled_dot_product_attention.impl_44) Timings (microseconds): count=1 curr=63
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 52, name: odml.scaled_dot_product_attention.impl_45) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.023, 76.6667%, 76.6667%, 0, 2, ModifyGraphWithDelegate/52
AllocateTensors, 0.009, 0.00466667, 23.3333%, 100%, 0, 3, AllocateTensors/52

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.023, 76.6667%, 76.6667%, 0, 2, ModifyGraphWithDelegate/52
AllocateTensors, 0.009, 0.00466667, 23.3333%, 100%, 0, 3, AllocateTensors/52

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.046, 76.6667%, 76.6667%, 0, 2
AllocateTensors, 1, 0.014, 23.3333%, 100%, 0, 3

Subgraph (index: 52, name: odml.scaled_dot_product_attention.impl_45) Timings (microseconds): count=1 curr=60
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 53, name: odml.scaled_dot_product_attention.impl_46) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.0215, 70.4918%, 70.4918%, 0, 2, ModifyGraphWithDelegate/53
AllocateTensors, 0.012, 0.006, 29.5082%, 100%, 0, 3, AllocateTensors/53

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.0215, 70.4918%, 70.4918%, 0, 2, ModifyGraphWithDelegate/53
AllocateTensors, 0.012, 0.006, 29.5082%, 100%, 0, 3, AllocateTensors/53

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.043, 70.4918%, 70.4918%, 0, 2
AllocateTensors, 1, 0.018, 29.5082%, 100%, 0, 3

Subgraph (index: 53, name: odml.scaled_dot_product_attention.impl_46) Timings (microseconds): count=1 curr=61
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 54, name: odml.scaled_dot_product_attention.impl_47) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.021, 75%, 75%, 0, 2, ModifyGraphWithDelegate/54
AllocateTensors, 0.009, 0.00466667, 25%, 100%, 0, 3, AllocateTensors/54

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.021, 75%, 75%, 0, 2, ModifyGraphWithDelegate/54
AllocateTensors, 0.009, 0.00466667, 25%, 100%, 0, 3, AllocateTensors/54

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.042, 75%, 75%, 0, 2
AllocateTensors, 1, 0.014, 25%, 100%, 0, 3

Subgraph (index: 54, name: odml.scaled_dot_product_attention.impl_47) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 55, name: odml.scaled_dot_product_attention.impl_48) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.044, 0.0275, 78.5714%, 78.5714%, 0, 2, ModifyGraphWithDelegate/55
AllocateTensors, 0.009, 0.005, 21.4286%, 100%, 0, 3, AllocateTensors/55

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.044, 0.0275, 78.5714%, 78.5714%, 0, 2, ModifyGraphWithDelegate/55
AllocateTensors, 0.009, 0.005, 21.4286%, 100%, 0, 3, AllocateTensors/55

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.055, 78.5714%, 78.5714%, 0, 2
AllocateTensors, 1, 0.015, 21.4286%, 100%, 0, 3

Subgraph (index: 55, name: odml.scaled_dot_product_attention.impl_48) Timings (microseconds): count=1 curr=70
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 56, name: odml.scaled_dot_product_attention.impl_49) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/56
AllocateTensors, 0.008, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/56

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/56
AllocateTensors, 0.008, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/56

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 73.0769%, 73.0769%, 0, 2
AllocateTensors, 1, 0.014, 26.9231%, 100%, 0, 3

Subgraph (index: 56, name: odml.scaled_dot_product_attention.impl_49) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 57, name: odml.scaled_dot_product_attention.impl_50) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/57
AllocateTensors, 0.01, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/57

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/57
AllocateTensors, 0.01, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/57

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 57, name: odml.scaled_dot_product_attention.impl_50) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 58, name: odml.scaled_dot_product_attention.impl_51) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/58
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/58

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/58
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/58

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 58, name: odml.scaled_dot_product_attention.impl_51) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 59, name: odml.scaled_dot_product_attention.impl_52) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/59
AllocateTensors, 0.012, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/59

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/59
AllocateTensors, 0.012, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/59

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 67.2727%, 67.2727%, 0, 2
AllocateTensors, 1, 0.018, 32.7273%, 100%, 0, 3

Subgraph (index: 59, name: odml.scaled_dot_product_attention.impl_52) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 60, name: odml.scaled_dot_product_attention.impl_53) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/60
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/60

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/60
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/60

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 60, name: odml.scaled_dot_product_attention.impl_53) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 61, name: odml.scaled_dot_product_attention.impl_54) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/61
AllocateTensors, 0.01, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/61

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/61
AllocateTensors, 0.01, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/61

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 70.9091%, 70.9091%, 0, 2
AllocateTensors, 1, 0.016, 29.0909%, 100%, 0, 3

Subgraph (index: 61, name: odml.scaled_dot_product_attention.impl_54) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 62, name: odml.scaled_dot_product_attention.impl_55) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/62
AllocateTensors, 0.01, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/62

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/62
AllocateTensors, 0.01, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/62

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 70.3704%, 70.3704%, 0, 2
AllocateTensors, 1, 0.016, 29.6296%, 100%, 0, 3

Subgraph (index: 62, name: odml.scaled_dot_product_attention.impl_55) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 63, name: odml.scaled_dot_product_attention.impl_56) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 72.2222%, 72.2222%, 0, 2, ModifyGraphWithDelegate/63
AllocateTensors, 0.01, 0.005, 27.7778%, 100%, 0, 3, AllocateTensors/63

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 72.2222%, 72.2222%, 0, 2, ModifyGraphWithDelegate/63
AllocateTensors, 0.01, 0.005, 27.7778%, 100%, 0, 3, AllocateTensors/63

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 72.2222%, 72.2222%, 0, 2
AllocateTensors, 1, 0.015, 27.7778%, 100%, 0, 3

Subgraph (index: 63, name: odml.scaled_dot_product_attention.impl_56) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 64, name: odml.scaled_dot_product_attention.impl_57) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/64
AllocateTensors, 0.012, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/64

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/64
AllocateTensors, 0.012, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/64

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.019, 33.3333%, 100%, 0, 3

Subgraph (index: 64, name: odml.scaled_dot_product_attention.impl_57) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 65, name: odml.scaled_dot_product_attention.impl_58) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/65
AllocateTensors, 0.01, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/65

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/65
AllocateTensors, 0.01, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/65

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 69.6429%, 69.6429%, 0, 2
AllocateTensors, 1, 0.017, 30.3571%, 100%, 0, 3

Subgraph (index: 65, name: odml.scaled_dot_product_attention.impl_58) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 66, name: odml.scaled_dot_product_attention.impl_59) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/66
AllocateTensors, 0.011, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/66

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/66
AllocateTensors, 0.011, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/66

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 70.3704%, 70.3704%, 0, 2
AllocateTensors, 1, 0.016, 29.6296%, 100%, 0, 3

Subgraph (index: 66, name: odml.scaled_dot_product_attention.impl_59) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 67, name: odml.scaled_dot_product_attention.impl_60) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/67
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/67

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/67
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/67

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 69.8113%, 69.8113%, 0, 2
AllocateTensors, 1, 0.016, 30.1887%, 100%, 0, 3

Subgraph (index: 67, name: odml.scaled_dot_product_attention.impl_60) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 68, name: odml.scaled_dot_product_attention.impl_61) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.0215, 69.3548%, 69.3548%, 0, 2, ModifyGraphWithDelegate/68
AllocateTensors, 0.013, 0.00633333, 30.6452%, 100%, 0, 3, AllocateTensors/68

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.0215, 69.3548%, 69.3548%, 0, 2, ModifyGraphWithDelegate/68
AllocateTensors, 0.013, 0.00633333, 30.6452%, 100%, 0, 3, AllocateTensors/68

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.043, 69.3548%, 69.3548%, 0, 2
AllocateTensors, 1, 0.019, 30.6452%, 100%, 0, 3

Subgraph (index: 68, name: odml.scaled_dot_product_attention.impl_61) Timings (microseconds): count=1 curr=62
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 69, name: odml.scaled_dot_product_attention.impl_62) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/69
AllocateTensors, 0.012, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/69

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/69
AllocateTensors, 0.012, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/69

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 69.0909%, 69.0909%, 0, 2
AllocateTensors, 1, 0.017, 30.9091%, 100%, 0, 3

Subgraph (index: 69, name: odml.scaled_dot_product_attention.impl_62) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 70, name: odml.scaled_dot_product_attention.impl_63) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.021, 48.8372%, 48.8372%, 0, 2, ModifyGraphWithDelegate/70
AllocateTensors, 0.038, 0.0146667, 51.1628%, 100%, 0, 3, AllocateTensors/70

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.021, 48.8372%, 48.8372%, 0, 2, ModifyGraphWithDelegate/70
AllocateTensors, 0.038, 0.0146667, 51.1628%, 100%, 0, 3, AllocateTensors/70

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
AllocateTensors, 1, 0.044, 51.1628%, 51.1628%, 0, 3
ModifyGraphWithDelegate, 1, 0.042, 48.8372%, 100%, 0, 2

Subgraph (index: 70, name: odml.scaled_dot_product_attention.impl_63) Timings (microseconds): count=1 curr=86
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 71, name: odml.scaled_dot_product_attention.impl_64) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.021, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/71
AllocateTensors, 0.016, 0.007, 33.3333%, 100%, 0, 3, AllocateTensors/71

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.021, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/71
AllocateTensors, 0.016, 0.007, 33.3333%, 100%, 0, 3, AllocateTensors/71

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.042, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.021, 33.3333%, 100%, 0, 3

Subgraph (index: 71, name: odml.scaled_dot_product_attention.impl_64) Timings (microseconds): count=1 curr=63
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 72, name: odml.scaled_dot_product_attention.impl_65) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 63.7931%, 63.7931%, 0, 2, ModifyGraphWithDelegate/72
AllocateTensors, 0.015, 0.007, 36.2069%, 100%, 0, 3, AllocateTensors/72

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 63.7931%, 63.7931%, 0, 2, ModifyGraphWithDelegate/72
AllocateTensors, 0.015, 0.007, 36.2069%, 100%, 0, 3, AllocateTensors/72

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 63.7931%, 63.7931%, 0, 2
AllocateTensors, 1, 0.021, 36.2069%, 100%, 0, 3

Subgraph (index: 72, name: odml.scaled_dot_product_attention.impl_65) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 73, name: odml.scaled_dot_product_attention.impl_66) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/73
AllocateTensors, 0.011, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/73

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/73
AllocateTensors, 0.011, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/73

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 69.0909%, 69.0909%, 0, 2
AllocateTensors, 1, 0.017, 30.9091%, 100%, 0, 3

Subgraph (index: 73, name: odml.scaled_dot_product_attention.impl_66) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 74, name: odml.scaled_dot_product_attention.impl_67) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 68.4211%, 68.4211%, 0, 2, ModifyGraphWithDelegate/74
AllocateTensors, 0.012, 0.006, 31.5789%, 100%, 0, 3, AllocateTensors/74

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 68.4211%, 68.4211%, 0, 2, ModifyGraphWithDelegate/74
AllocateTensors, 0.012, 0.006, 31.5789%, 100%, 0, 3, AllocateTensors/74

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 68.4211%, 68.4211%, 0, 2
AllocateTensors, 1, 0.018, 31.5789%, 100%, 0, 3

Subgraph (index: 74, name: odml.scaled_dot_product_attention.impl_67) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 75, name: odml.scaled_dot_product_attention.impl_68) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/75
AllocateTensors, 0.011, 0.006, 33.3333%, 100%, 0, 3, AllocateTensors/75

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/75
AllocateTensors, 0.011, 0.006, 33.3333%, 100%, 0, 3, AllocateTensors/75

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.018, 33.3333%, 100%, 0, 3

Subgraph (index: 75, name: odml.scaled_dot_product_attention.impl_68) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 76, name: odml.scaled_dot_product_attention.impl_69) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.02, 68.9655%, 68.9655%, 0, 2, ModifyGraphWithDelegate/76
AllocateTensors, 0.012, 0.006, 31.0345%, 100%, 0, 3, AllocateTensors/76

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.02, 68.9655%, 68.9655%, 0, 2, ModifyGraphWithDelegate/76
AllocateTensors, 0.012, 0.006, 31.0345%, 100%, 0, 3, AllocateTensors/76

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 68.9655%, 68.9655%, 0, 2
AllocateTensors, 1, 0.018, 31.0345%, 100%, 0, 3

Subgraph (index: 76, name: odml.scaled_dot_product_attention.impl_69) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 77, name: odml.scaled_dot_product_attention.impl_70) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.02, 70.1754%, 70.1754%, 0, 2, ModifyGraphWithDelegate/77
AllocateTensors, 0.01, 0.00566667, 29.8246%, 100%, 0, 3, AllocateTensors/77

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.02, 70.1754%, 70.1754%, 0, 2, ModifyGraphWithDelegate/77
AllocateTensors, 0.01, 0.00566667, 29.8246%, 100%, 0, 3, AllocateTensors/77

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 70.1754%, 70.1754%, 0, 2
AllocateTensors, 1, 0.017, 29.8246%, 100%, 0, 3

Subgraph (index: 77, name: odml.scaled_dot_product_attention.impl_70) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 78, name: odml.scaled_dot_product_attention.impl_71) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 62.9032%, 62.9032%, 0, 2, ModifyGraphWithDelegate/78
AllocateTensors, 0.016, 0.00766667, 37.0968%, 100%, 0, 3, AllocateTensors/78

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 62.9032%, 62.9032%, 0, 2, ModifyGraphWithDelegate/78
AllocateTensors, 0.016, 0.00766667, 37.0968%, 100%, 0, 3, AllocateTensors/78

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 62.9032%, 62.9032%, 0, 2
AllocateTensors, 1, 0.023, 37.0968%, 100%, 0, 3

Subgraph (index: 78, name: odml.scaled_dot_product_attention.impl_71) Timings (microseconds): count=1 curr=62
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 79, name: odml.scaled_dot_product_attention.impl_72) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 69.4915%, 69.4915%, 0, 2, ModifyGraphWithDelegate/79
AllocateTensors, 0.013, 0.006, 30.5085%, 100%, 0, 3, AllocateTensors/79

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 69.4915%, 69.4915%, 0, 2, ModifyGraphWithDelegate/79
AllocateTensors, 0.013, 0.006, 30.5085%, 100%, 0, 3, AllocateTensors/79

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 69.4915%, 69.4915%, 0, 2
AllocateTensors, 1, 0.018, 30.5085%, 100%, 0, 3

Subgraph (index: 79, name: odml.scaled_dot_product_attention.impl_72) Timings (microseconds): count=1 curr=59
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 80, name: odml.scaled_dot_product_attention.impl_73) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 66.1017%, 66.1017%, 0, 2, ModifyGraphWithDelegate/80
AllocateTensors, 0.014, 0.00666667, 33.8983%, 100%, 0, 3, AllocateTensors/80

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 66.1017%, 66.1017%, 0, 2, ModifyGraphWithDelegate/80
AllocateTensors, 0.014, 0.00666667, 33.8983%, 100%, 0, 3, AllocateTensors/80

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 66.1017%, 66.1017%, 0, 2
AllocateTensors, 1, 0.02, 33.8983%, 100%, 0, 3

Subgraph (index: 80, name: odml.scaled_dot_product_attention.impl_73) Timings (microseconds): count=1 curr=59
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 81, name: odml.scaled_dot_product_attention.impl_74) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/81
AllocateTensors, 0.013, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/81

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/81
AllocateTensors, 0.013, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/81

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.019, 33.3333%, 100%, 0, 3

Subgraph (index: 81, name: odml.scaled_dot_product_attention.impl_74) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 82, name: odml.scaled_dot_product_attention.impl_75) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 68.4211%, 68.4211%, 0, 2, ModifyGraphWithDelegate/82
AllocateTensors, 0.012, 0.006, 31.5789%, 100%, 0, 3, AllocateTensors/82

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 68.4211%, 68.4211%, 0, 2, ModifyGraphWithDelegate/82
AllocateTensors, 0.012, 0.006, 31.5789%, 100%, 0, 3, AllocateTensors/82

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 68.4211%, 68.4211%, 0, 2
AllocateTensors, 1, 0.018, 31.5789%, 100%, 0, 3

Subgraph (index: 82, name: odml.scaled_dot_product_attention.impl_75) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 83, name: odml.scaled_dot_product_attention.impl_76) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.024, 76.1905%, 76.1905%, 0, 2, ModifyGraphWithDelegate/83
AllocateTensors, 0.009, 0.005, 23.8095%, 100%, 0, 3, AllocateTensors/83

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.024, 76.1905%, 76.1905%, 0, 2, ModifyGraphWithDelegate/83
AllocateTensors, 0.009, 0.005, 23.8095%, 100%, 0, 3, AllocateTensors/83

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.048, 76.1905%, 76.1905%, 0, 2
AllocateTensors, 1, 0.015, 23.8095%, 100%, 0, 3

Subgraph (index: 83, name: odml.scaled_dot_product_attention.impl_76) Timings (microseconds): count=1 curr=63
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 84, name: odml.scaled_dot_product_attention.impl_77) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.023, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/84
AllocateTensors, 0.014, 0.00766667, 33.3333%, 100%, 0, 3, AllocateTensors/84

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.023, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/84
AllocateTensors, 0.014, 0.00766667, 33.3333%, 100%, 0, 3, AllocateTensors/84

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.046, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.023, 33.3333%, 100%, 0, 3

Subgraph (index: 84, name: odml.scaled_dot_product_attention.impl_77) Timings (microseconds): count=1 curr=69
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 85, name: odml.scaled_dot_product_attention.impl_78) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.041, 0.0265, 75.7143%, 75.7143%, 0, 2, ModifyGraphWithDelegate/85
AllocateTensors, 0.01, 0.00566667, 24.2857%, 100%, 0, 3, AllocateTensors/85

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.041, 0.0265, 75.7143%, 75.7143%, 0, 2, ModifyGraphWithDelegate/85
AllocateTensors, 0.01, 0.00566667, 24.2857%, 100%, 0, 3, AllocateTensors/85

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.053, 75.7143%, 75.7143%, 0, 2
AllocateTensors, 1, 0.017, 24.2857%, 100%, 0, 3

Subgraph (index: 85, name: odml.scaled_dot_product_attention.impl_78) Timings (microseconds): count=1 curr=70
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 86, name: odml.scaled_dot_product_attention.impl_79) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.024, 64%, 64%, 0, 2, ModifyGraphWithDelegate/86
AllocateTensors, 0.021, 0.009, 36%, 100%, 0, 3, AllocateTensors/86

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.024, 64%, 64%, 0, 2, ModifyGraphWithDelegate/86
AllocateTensors, 0.021, 0.009, 36%, 100%, 0, 3, AllocateTensors/86

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.048, 64%, 64%, 0, 2
AllocateTensors, 1, 0.027, 36%, 100%, 0, 3

Subgraph (index: 86, name: odml.scaled_dot_product_attention.impl_79) Timings (microseconds): count=1 curr=75
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 87, name: odml.scaled_dot_product_attention.impl_80) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/87
AllocateTensors, 0.012, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/87

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/87
AllocateTensors, 0.012, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/87

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 67.8571%, 67.8571%, 0, 2
AllocateTensors, 1, 0.018, 32.1429%, 100%, 0, 3

Subgraph (index: 87, name: odml.scaled_dot_product_attention.impl_80) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 88, name: odml.scaled_dot_product_attention.impl_81) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 70.1754%, 70.1754%, 0, 2, ModifyGraphWithDelegate/88
AllocateTensors, 0.011, 0.00566667, 29.8246%, 100%, 0, 3, AllocateTensors/88

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 70.1754%, 70.1754%, 0, 2, ModifyGraphWithDelegate/88
AllocateTensors, 0.011, 0.00566667, 29.8246%, 100%, 0, 3, AllocateTensors/88

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 70.1754%, 70.1754%, 0, 2
AllocateTensors, 1, 0.017, 29.8246%, 100%, 0, 3

Subgraph (index: 88, name: odml.scaled_dot_product_attention.impl_81) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 89, name: odml.scaled_dot_product_attention.impl_82) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/89
AllocateTensors, 0.009, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/89

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/89
AllocateTensors, 0.009, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/89

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 89, name: odml.scaled_dot_product_attention.impl_82) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 90, name: odml.scaled_dot_product_attention.impl_83) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/90
AllocateTensors, 0.01, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/90

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 70.3704%, 70.3704%, 0, 2, ModifyGraphWithDelegate/90
AllocateTensors, 0.01, 0.00533333, 29.6296%, 100%, 0, 3, AllocateTensors/90

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 70.3704%, 70.3704%, 0, 2
AllocateTensors, 1, 0.016, 29.6296%, 100%, 0, 3

Subgraph (index: 90, name: odml.scaled_dot_product_attention.impl_83) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 91, name: odml.scaled_dot_product_attention.impl_84) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/91
AllocateTensors, 0.011, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/91

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/91
AllocateTensors, 0.011, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/91

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 70.9091%, 70.9091%, 0, 2
AllocateTensors, 1, 0.016, 29.0909%, 100%, 0, 3

Subgraph (index: 91, name: odml.scaled_dot_product_attention.impl_84) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 92, name: odml.scaled_dot_product_attention.impl_85) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/92
AllocateTensors, 0.013, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/92

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/92
AllocateTensors, 0.013, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/92

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.019, 33.3333%, 100%, 0, 3

Subgraph (index: 92, name: odml.scaled_dot_product_attention.impl_85) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 93, name: odml.scaled_dot_product_attention.impl_86) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/93
AllocateTensors, 0.011, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/93

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/93
AllocateTensors, 0.011, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/93

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 69.6429%, 69.6429%, 0, 2
AllocateTensors, 1, 0.017, 30.3571%, 100%, 0, 3

Subgraph (index: 93, name: odml.scaled_dot_product_attention.impl_86) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 94, name: odml.scaled_dot_product_attention.impl_87) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 68.5185%, 68.5185%, 0, 2, ModifyGraphWithDelegate/94
AllocateTensors, 0.01, 0.00566667, 31.4815%, 100%, 0, 3, AllocateTensors/94

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 68.5185%, 68.5185%, 0, 2, ModifyGraphWithDelegate/94
AllocateTensors, 0.01, 0.00566667, 31.4815%, 100%, 0, 3, AllocateTensors/94

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 68.5185%, 68.5185%, 0, 2
AllocateTensors, 1, 0.017, 31.4815%, 100%, 0, 3

Subgraph (index: 94, name: odml.scaled_dot_product_attention.impl_87) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 95, name: odml.scaled_dot_product_attention.impl_88) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/95
AllocateTensors, 0.012, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/95

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/95
AllocateTensors, 0.012, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/95

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 67.8571%, 67.8571%, 0, 2
AllocateTensors, 1, 0.018, 32.1429%, 100%, 0, 3

Subgraph (index: 95, name: odml.scaled_dot_product_attention.impl_88) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 96, name: odml.scaled_dot_product_attention.impl_89) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/96
AllocateTensors, 0.013, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/96

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/96
AllocateTensors, 0.013, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/96

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 67.2727%, 67.2727%, 0, 2
AllocateTensors, 1, 0.018, 32.7273%, 100%, 0, 3

Subgraph (index: 96, name: odml.scaled_dot_product_attention.impl_89) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 97, name: odml.scaled_dot_product_attention.impl_90) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 74.0741%, 74.0741%, 0, 2, ModifyGraphWithDelegate/97
AllocateTensors, 0.009, 0.00466667, 25.9259%, 100%, 0, 3, AllocateTensors/97

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 74.0741%, 74.0741%, 0, 2, ModifyGraphWithDelegate/97
AllocateTensors, 0.009, 0.00466667, 25.9259%, 100%, 0, 3, AllocateTensors/97

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 74.0741%, 74.0741%, 0, 2
AllocateTensors, 1, 0.014, 25.9259%, 100%, 0, 3

Subgraph (index: 97, name: odml.scaled_dot_product_attention.impl_90) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 98, name: odml.scaled_dot_product_attention.impl_91) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 52.6316%, 52.6316%, 0, 2, ModifyGraphWithDelegate/98
AllocateTensors, 0.03, 0.012, 47.3684%, 100%, 0, 3, AllocateTensors/98

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 52.6316%, 52.6316%, 0, 2, ModifyGraphWithDelegate/98
AllocateTensors, 0.03, 0.012, 47.3684%, 100%, 0, 3, AllocateTensors/98

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 52.6316%, 52.6316%, 0, 2
AllocateTensors, 1, 0.036, 47.3684%, 100%, 0, 3

Subgraph (index: 98, name: odml.scaled_dot_product_attention.impl_91) Timings (microseconds): count=1 curr=76
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 99, name: odml.scaled_dot_product_attention.impl_92) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/99
AllocateTensors, 0.011, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/99

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/99
AllocateTensors, 0.011, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/99

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 69.6429%, 69.6429%, 0, 2
AllocateTensors, 1, 0.017, 30.3571%, 100%, 0, 3

Subgraph (index: 99, name: odml.scaled_dot_product_attention.impl_92) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 100, name: odml.scaled_dot_product_attention.impl_93) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/100
AllocateTensors, 0.012, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/100

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/100
AllocateTensors, 0.012, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/100

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 69.6429%, 69.6429%, 0, 2
AllocateTensors, 1, 0.017, 30.3571%, 100%, 0, 3

Subgraph (index: 100, name: odml.scaled_dot_product_attention.impl_93) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 101, name: odml.scaled_dot_product_attention.impl_94) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/101
AllocateTensors, 0.013, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/101

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/101
AllocateTensors, 0.013, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/101

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 67.8571%, 67.8571%, 0, 2
AllocateTensors, 1, 0.018, 32.1429%, 100%, 0, 3

Subgraph (index: 101, name: odml.scaled_dot_product_attention.impl_94) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 102, name: odml.scaled_dot_product_attention.impl_95) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/102
AllocateTensors, 0.012, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/102

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 69.6429%, 69.6429%, 0, 2, ModifyGraphWithDelegate/102
AllocateTensors, 0.012, 0.00566667, 30.3571%, 100%, 0, 3, AllocateTensors/102

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 69.6429%, 69.6429%, 0, 2
AllocateTensors, 1, 0.017, 30.3571%, 100%, 0, 3

Subgraph (index: 102, name: odml.scaled_dot_product_attention.impl_95) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 103, name: odml.scaled_dot_product_attention.impl_96) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/103
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/103

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/103
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/103

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 69.8113%, 69.8113%, 0, 2
AllocateTensors, 1, 0.016, 30.1887%, 100%, 0, 3

Subgraph (index: 103, name: odml.scaled_dot_product_attention.impl_96) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 104, name: odml.scaled_dot_product_attention.impl_97) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/104
AllocateTensors, 0.012, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/104

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/104
AllocateTensors, 0.012, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/104

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 69.0909%, 69.0909%, 0, 2
AllocateTensors, 1, 0.017, 30.9091%, 100%, 0, 3

Subgraph (index: 104, name: odml.scaled_dot_product_attention.impl_97) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 105, name: odml.scaled_dot_product_attention.impl_98) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/105
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/105

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/105
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/105

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 69.8113%, 69.8113%, 0, 2
AllocateTensors, 1, 0.016, 30.1887%, 100%, 0, 3

Subgraph (index: 105, name: odml.scaled_dot_product_attention.impl_98) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 106, name: odml.scaled_dot_product_attention.impl_99) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.0215, 74.1379%, 74.1379%, 0, 2, ModifyGraphWithDelegate/106
AllocateTensors, 0.009, 0.005, 25.8621%, 100%, 0, 3, AllocateTensors/106

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.0215, 74.1379%, 74.1379%, 0, 2, ModifyGraphWithDelegate/106
AllocateTensors, 0.009, 0.005, 25.8621%, 100%, 0, 3, AllocateTensors/106

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.043, 74.1379%, 74.1379%, 0, 2
AllocateTensors, 1, 0.015, 25.8621%, 100%, 0, 3

Subgraph (index: 106, name: odml.scaled_dot_product_attention.impl_99) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 107, name: odml.scaled_dot_product_attention.impl_100) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/107
AllocateTensors, 0.008, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/107

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 73.0769%, 73.0769%, 0, 2, ModifyGraphWithDelegate/107
AllocateTensors, 0.008, 0.00466667, 26.9231%, 100%, 0, 3, AllocateTensors/107

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 73.0769%, 73.0769%, 0, 2
AllocateTensors, 1, 0.014, 26.9231%, 100%, 0, 3

Subgraph (index: 107, name: odml.scaled_dot_product_attention.impl_100) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 108, name: odml.scaled_dot_product_attention.impl_101) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/108
AllocateTensors, 0.012, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/108

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/108
AllocateTensors, 0.012, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/108

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 67.2727%, 67.2727%, 0, 2
AllocateTensors, 1, 0.018, 32.7273%, 100%, 0, 3

Subgraph (index: 108, name: odml.scaled_dot_product_attention.impl_101) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 109, name: odml.scaled_dot_product_attention.impl_102) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/109
AllocateTensors, 0.013, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/109

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/109
AllocateTensors, 0.013, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/109

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 67.2727%, 67.2727%, 0, 2
AllocateTensors, 1, 0.018, 32.7273%, 100%, 0, 3

Subgraph (index: 109, name: odml.scaled_dot_product_attention.impl_102) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 110, name: odml.scaled_dot_product_attention.impl_103) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/110
AllocateTensors, 0.011, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/110

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/110
AllocateTensors, 0.011, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/110

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 67.9245%, 67.9245%, 0, 2
AllocateTensors, 1, 0.017, 32.0755%, 100%, 0, 3

Subgraph (index: 110, name: odml.scaled_dot_product_attention.impl_103) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 111, name: odml.scaled_dot_product_attention.impl_104) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/111
AllocateTensors, 0.008, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/111

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/111
AllocateTensors, 0.008, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/111

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 111, name: odml.scaled_dot_product_attention.impl_104) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 112, name: odml.scaled_dot_product_attention.impl_105) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/112
AllocateTensors, 0.011, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/112

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/112
AllocateTensors, 0.011, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/112

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 67.9245%, 67.9245%, 0, 2
AllocateTensors, 1, 0.017, 32.0755%, 100%, 0, 3

Subgraph (index: 112, name: odml.scaled_dot_product_attention.impl_105) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 113, name: odml.scaled_dot_product_attention.impl_106) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.021, 72.4138%, 72.4138%, 0, 2, ModifyGraphWithDelegate/113
AllocateTensors, 0.011, 0.00533333, 27.5862%, 100%, 0, 3, AllocateTensors/113

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.032, 0.021, 72.4138%, 72.4138%, 0, 2, ModifyGraphWithDelegate/113
AllocateTensors, 0.011, 0.00533333, 27.5862%, 100%, 0, 3, AllocateTensors/113

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.042, 72.4138%, 72.4138%, 0, 2
AllocateTensors, 1, 0.016, 27.5862%, 100%, 0, 3

Subgraph (index: 113, name: odml.scaled_dot_product_attention.impl_106) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 114, name: odml.scaled_dot_product_attention.impl_107) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.02, 72.7273%, 72.7273%, 0, 2, ModifyGraphWithDelegate/114
AllocateTensors, 0.01, 0.005, 27.2727%, 100%, 0, 3, AllocateTensors/114

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.02, 72.7273%, 72.7273%, 0, 2, ModifyGraphWithDelegate/114
AllocateTensors, 0.01, 0.005, 27.2727%, 100%, 0, 3, AllocateTensors/114

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 72.7273%, 72.7273%, 0, 2
AllocateTensors, 1, 0.015, 27.2727%, 100%, 0, 3

Subgraph (index: 114, name: odml.scaled_dot_product_attention.impl_107) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 115, name: odml.scaled_dot_product_attention.impl_108) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.043, 0.0265, 79.1045%, 79.1045%, 0, 2, ModifyGraphWithDelegate/115
AllocateTensors, 0.009, 0.00466667, 20.8955%, 100%, 0, 3, AllocateTensors/115

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.043, 0.0265, 79.1045%, 79.1045%, 0, 2, ModifyGraphWithDelegate/115
AllocateTensors, 0.009, 0.00466667, 20.8955%, 100%, 0, 3, AllocateTensors/115

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.053, 79.1045%, 79.1045%, 0, 2
AllocateTensors, 1, 0.014, 20.8955%, 100%, 0, 3

Subgraph (index: 115, name: odml.scaled_dot_product_attention.impl_108) Timings (microseconds): count=1 curr=67
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 116, name: odml.scaled_dot_product_attention.impl_109) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 65.5738%, 65.5738%, 0, 2, ModifyGraphWithDelegate/116
AllocateTensors, 0.015, 0.007, 34.4262%, 100%, 0, 3, AllocateTensors/116

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.02, 65.5738%, 65.5738%, 0, 2, ModifyGraphWithDelegate/116
AllocateTensors, 0.015, 0.007, 34.4262%, 100%, 0, 3, AllocateTensors/116

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.04, 65.5738%, 65.5738%, 0, 2
AllocateTensors, 1, 0.021, 34.4262%, 100%, 0, 3

Subgraph (index: 116, name: odml.scaled_dot_product_attention.impl_109) Timings (microseconds): count=1 curr=61
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 117, name: odml.scaled_dot_product_attention.impl_110) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.069, 0.04, 83.3333%, 83.3333%, 0, 2, ModifyGraphWithDelegate/117
AllocateTensors, 0.01, 0.00533333, 16.6667%, 100%, 0, 3, AllocateTensors/117

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.069, 0.04, 83.3333%, 83.3333%, 0, 2, ModifyGraphWithDelegate/117
AllocateTensors, 0.01, 0.00533333, 16.6667%, 100%, 0, 3, AllocateTensors/117

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.08, 83.3333%, 83.3333%, 0, 2
AllocateTensors, 1, 0.016, 16.6667%, 100%, 0, 3

Subgraph (index: 117, name: odml.scaled_dot_product_attention.impl_110) Timings (microseconds): count=1 curr=96
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 118, name: odml.scaled_dot_product_attention.impl_111) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.033, 0.022, 74.5763%, 74.5763%, 0, 2, ModifyGraphWithDelegate/118
AllocateTensors, 0.009, 0.005, 25.4237%, 100%, 0, 3, AllocateTensors/118

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.033, 0.022, 74.5763%, 74.5763%, 0, 2, ModifyGraphWithDelegate/118
AllocateTensors, 0.009, 0.005, 25.4237%, 100%, 0, 3, AllocateTensors/118

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.044, 74.5763%, 74.5763%, 0, 2
AllocateTensors, 1, 0.015, 25.4237%, 100%, 0, 3

Subgraph (index: 118, name: odml.scaled_dot_product_attention.impl_111) Timings (microseconds): count=1 curr=59
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 119, name: odml.scaled_dot_product_attention.impl_112) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 71.9298%, 71.9298%, 0, 2, ModifyGraphWithDelegate/119
AllocateTensors, 0.01, 0.00533333, 28.0702%, 100%, 0, 3, AllocateTensors/119

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.0205, 71.9298%, 71.9298%, 0, 2, ModifyGraphWithDelegate/119
AllocateTensors, 0.01, 0.00533333, 28.0702%, 100%, 0, 3, AllocateTensors/119

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 71.9298%, 71.9298%, 0, 2
AllocateTensors, 1, 0.016, 28.0702%, 100%, 0, 3

Subgraph (index: 119, name: odml.scaled_dot_product_attention.impl_112) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 120, name: odml.scaled_dot_product_attention.impl_113) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.039, 0.0245, 74.2424%, 74.2424%, 0, 2, ModifyGraphWithDelegate/120
AllocateTensors, 0.011, 0.00566667, 25.7576%, 100%, 0, 3, AllocateTensors/120

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.039, 0.0245, 74.2424%, 74.2424%, 0, 2, ModifyGraphWithDelegate/120
AllocateTensors, 0.011, 0.00566667, 25.7576%, 100%, 0, 3, AllocateTensors/120

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.049, 74.2424%, 74.2424%, 0, 2
AllocateTensors, 1, 0.017, 25.7576%, 100%, 0, 3

Subgraph (index: 120, name: odml.scaled_dot_product_attention.impl_113) Timings (microseconds): count=1 curr=66
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 121, name: odml.scaled_dot_product_attention.impl_114) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.0205, 71.9298%, 71.9298%, 0, 2, ModifyGraphWithDelegate/121
AllocateTensors, 0.011, 0.00533333, 28.0702%, 100%, 0, 3, AllocateTensors/121

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.0205, 71.9298%, 71.9298%, 0, 2, ModifyGraphWithDelegate/121
AllocateTensors, 0.011, 0.00533333, 28.0702%, 100%, 0, 3, AllocateTensors/121

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 71.9298%, 71.9298%, 0, 2
AllocateTensors, 1, 0.016, 28.0702%, 100%, 0, 3

Subgraph (index: 121, name: odml.scaled_dot_product_attention.impl_114) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 122, name: odml.scaled_dot_product_attention.impl_115) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.055, 0.0325, 81.25%, 81.25%, 0, 2, ModifyGraphWithDelegate/122
AllocateTensors, 0.009, 0.005, 18.75%, 100%, 0, 3, AllocateTensors/122

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.055, 0.0325, 81.25%, 81.25%, 0, 2, ModifyGraphWithDelegate/122
AllocateTensors, 0.009, 0.005, 18.75%, 100%, 0, 3, AllocateTensors/122

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.065, 81.25%, 81.25%, 0, 2
AllocateTensors, 1, 0.015, 18.75%, 100%, 0, 3

Subgraph (index: 122, name: odml.scaled_dot_product_attention.impl_115) Timings (microseconds): count=1 curr=80
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 123, name: odml.scaled_dot_product_attention.impl_116) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.046, 0.028, 75.6757%, 75.6757%, 0, 2, ModifyGraphWithDelegate/123
AllocateTensors, 0.012, 0.006, 24.3243%, 100%, 0, 3, AllocateTensors/123

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.046, 0.028, 75.6757%, 75.6757%, 0, 2, ModifyGraphWithDelegate/123
AllocateTensors, 0.012, 0.006, 24.3243%, 100%, 0, 3, AllocateTensors/123

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.056, 75.6757%, 75.6757%, 0, 2
AllocateTensors, 1, 0.018, 24.3243%, 100%, 0, 3

Subgraph (index: 123, name: odml.scaled_dot_product_attention.impl_116) Timings (microseconds): count=1 curr=74
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 124, name: odml.scaled_dot_product_attention.impl_117) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.023, 74.1935%, 74.1936%, 0, 2, ModifyGraphWithDelegate/124
AllocateTensors, 0.011, 0.00533333, 25.8065%, 100%, 0, 3, AllocateTensors/124

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.023, 74.1935%, 74.1936%, 0, 2, ModifyGraphWithDelegate/124
AllocateTensors, 0.011, 0.00533333, 25.8065%, 100%, 0, 3, AllocateTensors/124

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.046, 74.1936%, 74.1936%, 0, 2
AllocateTensors, 1, 0.016, 25.8064%, 100%, 0, 3

Subgraph (index: 124, name: odml.scaled_dot_product_attention.impl_117) Timings (microseconds): count=1 curr=62
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 125, name: odml.scaled_dot_product_attention.impl_118) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 52.7778%, 52.7778%, 0, 2, ModifyGraphWithDelegate/125
AllocateTensors, 0.028, 0.0113333, 47.2222%, 100%, 0, 3, AllocateTensors/125

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 52.7778%, 52.7778%, 0, 2, ModifyGraphWithDelegate/125
AllocateTensors, 0.028, 0.0113333, 47.2222%, 100%, 0, 3, AllocateTensors/125

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 52.7778%, 52.7778%, 0, 2
AllocateTensors, 1, 0.034, 47.2222%, 100%, 0, 3

Subgraph (index: 125, name: odml.scaled_dot_product_attention.impl_118) Timings (microseconds): count=1 curr=72
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 126, name: odml.scaled_dot_product_attention.impl_119) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.044, 0.027, 76.0563%, 76.0563%, 0, 2, ModifyGraphWithDelegate/126
AllocateTensors, 0.012, 0.00566667, 23.9437%, 100%, 0, 3, AllocateTensors/126

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.044, 0.027, 76.0563%, 76.0563%, 0, 2, ModifyGraphWithDelegate/126
AllocateTensors, 0.012, 0.00566667, 23.9437%, 100%, 0, 3, AllocateTensors/126

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.054, 76.0563%, 76.0563%, 0, 2
AllocateTensors, 1, 0.017, 23.9437%, 100%, 0, 3

Subgraph (index: 126, name: odml.scaled_dot_product_attention.impl_119) Timings (microseconds): count=1 curr=71
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 127, name: odml.scaled_dot_product_attention.impl_120) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.0205, 73.2143%, 73.2143%, 0, 2, ModifyGraphWithDelegate/127
AllocateTensors, 0.01, 0.005, 26.7857%, 100%, 0, 3, AllocateTensors/127

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.0205, 73.2143%, 73.2143%, 0, 2, ModifyGraphWithDelegate/127
AllocateTensors, 0.01, 0.005, 26.7857%, 100%, 0, 3, AllocateTensors/127

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 73.2143%, 73.2143%, 0, 2
AllocateTensors, 1, 0.015, 26.7857%, 100%, 0, 3

Subgraph (index: 127, name: odml.scaled_dot_product_attention.impl_120) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 128, name: odml.scaled_dot_product_attention.impl_121) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/128
AllocateTensors, 0.009, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/128

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/128
AllocateTensors, 0.009, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/128

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 128, name: odml.scaled_dot_product_attention.impl_121) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 129, name: odml.scaled_dot_product_attention.impl_122) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.042, 0.026, 76.4706%, 76.4706%, 0, 2, ModifyGraphWithDelegate/129
AllocateTensors, 0.01, 0.00533333, 23.5294%, 100%, 0, 3, AllocateTensors/129

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.042, 0.026, 76.4706%, 76.4706%, 0, 2, ModifyGraphWithDelegate/129
AllocateTensors, 0.01, 0.00533333, 23.5294%, 100%, 0, 3, AllocateTensors/129

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.052, 76.4706%, 76.4706%, 0, 2
AllocateTensors, 1, 0.016, 23.5294%, 100%, 0, 3

Subgraph (index: 129, name: odml.scaled_dot_product_attention.impl_122) Timings (microseconds): count=1 curr=68
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 130, name: odml.scaled_dot_product_attention.impl_123) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.043, 0.0265, 77.9412%, 77.9412%, 0, 2, ModifyGraphWithDelegate/130
AllocateTensors, 0.01, 0.005, 22.0588%, 100%, 0, 3, AllocateTensors/130

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.043, 0.0265, 77.9412%, 77.9412%, 0, 2, ModifyGraphWithDelegate/130
AllocateTensors, 0.01, 0.005, 22.0588%, 100%, 0, 3, AllocateTensors/130

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.053, 77.9412%, 77.9412%, 0, 2
AllocateTensors, 1, 0.015, 22.0588%, 100%, 0, 3

Subgraph (index: 130, name: odml.scaled_dot_product_attention.impl_123) Timings (microseconds): count=1 curr=68
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 131, name: odml.scaled_dot_product_attention.impl_124) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.0205, 70.6897%, 70.6897%, 0, 2, ModifyGraphWithDelegate/131
AllocateTensors, 0.011, 0.00566667, 29.3103%, 100%, 0, 3, AllocateTensors/131

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.031, 0.0205, 70.6897%, 70.6897%, 0, 2, ModifyGraphWithDelegate/131
AllocateTensors, 0.011, 0.00566667, 29.3103%, 100%, 0, 3, AllocateTensors/131

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.041, 70.6897%, 70.6897%, 0, 2
AllocateTensors, 1, 0.017, 29.3103%, 100%, 0, 3

Subgraph (index: 131, name: odml.scaled_dot_product_attention.impl_124) Timings (microseconds): count=1 curr=58
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 132, name: odml.scaled_dot_product_attention.impl_125) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.0195, 73.5849%, 73.5849%, 0, 2, ModifyGraphWithDelegate/132
AllocateTensors, 0.008, 0.00466667, 26.4151%, 100%, 0, 3, AllocateTensors/132

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.029, 0.0195, 73.5849%, 73.5849%, 0, 2, ModifyGraphWithDelegate/132
AllocateTensors, 0.008, 0.00466667, 26.4151%, 100%, 0, 3, AllocateTensors/132

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 73.5849%, 73.5849%, 0, 2
AllocateTensors, 1, 0.014, 26.4151%, 100%, 0, 3

Subgraph (index: 132, name: odml.scaled_dot_product_attention.impl_125) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 133, name: odml.scaled_dot_product_attention.impl_126) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.057, 0.0335, 81.7073%, 81.7073%, 0, 2, ModifyGraphWithDelegate/133
AllocateTensors, 0.009, 0.005, 18.2927%, 100%, 0, 3, AllocateTensors/133

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.057, 0.0335, 81.7073%, 81.7073%, 0, 2, ModifyGraphWithDelegate/133
AllocateTensors, 0.009, 0.005, 18.2927%, 100%, 0, 3, AllocateTensors/133

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.067, 81.7073%, 81.7073%, 0, 2
AllocateTensors, 1, 0.015, 18.2927%, 100%, 0, 3

Subgraph (index: 133, name: odml.scaled_dot_product_attention.impl_126) Timings (microseconds): count=1 curr=82
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 134, name: odml.scaled_dot_product_attention.impl_127) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.038, 0.024, 77.4194%, 77.4194%, 0, 2, ModifyGraphWithDelegate/134
AllocateTensors, 0.008, 0.00466667, 22.5806%, 100%, 0, 3, AllocateTensors/134

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.038, 0.024, 77.4194%, 77.4194%, 0, 2, ModifyGraphWithDelegate/134
AllocateTensors, 0.008, 0.00466667, 22.5806%, 100%, 0, 3, AllocateTensors/134

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.048, 77.4193%, 77.4193%, 0, 2
AllocateTensors, 1, 0.014, 22.5806%, 100%, 0, 3

Subgraph (index: 134, name: odml.scaled_dot_product_attention.impl_127) Timings (microseconds): count=1 curr=62
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 135, name: odml.scaled_dot_product_attention.impl_128) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.037, 0.0235, 70.1493%, 70.1493%, 0, 2, ModifyGraphWithDelegate/135
AllocateTensors, 0.014, 0.00666667, 29.8507%, 100%, 0, 3, AllocateTensors/135

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.037, 0.0235, 70.1493%, 70.1493%, 0, 2, ModifyGraphWithDelegate/135
AllocateTensors, 0.014, 0.00666667, 29.8507%, 100%, 0, 3, AllocateTensors/135

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.047, 70.1493%, 70.1493%, 0, 2
AllocateTensors, 1, 0.02, 29.8507%, 100%, 0, 3

Subgraph (index: 135, name: odml.scaled_dot_product_attention.impl_128) Timings (microseconds): count=1 curr=67
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 136, name: odml.scaled_dot_product_attention.impl_129) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.044, 0.0275, 77.4648%, 77.4648%, 0, 2, ModifyGraphWithDelegate/136
AllocateTensors, 0.01, 0.00533333, 22.5352%, 100%, 0, 3, AllocateTensors/136

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.044, 0.0275, 77.4648%, 77.4648%, 0, 2, ModifyGraphWithDelegate/136
AllocateTensors, 0.01, 0.00533333, 22.5352%, 100%, 0, 3, AllocateTensors/136

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.055, 77.4648%, 77.4648%, 0, 2
AllocateTensors, 1, 0.016, 22.5352%, 100%, 0, 3

Subgraph (index: 136, name: odml.scaled_dot_product_attention.impl_129) Timings (microseconds): count=1 curr=71
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 137, name: odml.scaled_dot_product_attention.impl_130) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.046, 0.028, 77.7778%, 77.7778%, 0, 2, ModifyGraphWithDelegate/137
AllocateTensors, 0.011, 0.00533333, 22.2222%, 100%, 0, 3, AllocateTensors/137

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.046, 0.028, 77.7778%, 77.7778%, 0, 2, ModifyGraphWithDelegate/137
AllocateTensors, 0.011, 0.00533333, 22.2222%, 100%, 0, 3, AllocateTensors/137

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.056, 77.7778%, 77.7778%, 0, 2
AllocateTensors, 1, 0.016, 22.2222%, 100%, 0, 3

Subgraph (index: 137, name: odml.scaled_dot_product_attention.impl_130) Timings (microseconds): count=1 curr=72
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 138, name: odml.scaled_dot_product_attention.impl_131) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.048, 0.029, 78.3784%, 78.3784%, 0, 2, ModifyGraphWithDelegate/138
AllocateTensors, 0.01, 0.00533333, 21.6216%, 100%, 0, 3, AllocateTensors/138

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.048, 0.029, 78.3784%, 78.3784%, 0, 2, ModifyGraphWithDelegate/138
AllocateTensors, 0.01, 0.00533333, 21.6216%, 100%, 0, 3, AllocateTensors/138

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.058, 78.3784%, 78.3784%, 0, 2
AllocateTensors, 1, 0.016, 21.6216%, 100%, 0, 3

Subgraph (index: 138, name: odml.scaled_dot_product_attention.impl_131) Timings (microseconds): count=1 curr=74
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 139, name: odml.scaled_dot_product_attention.impl_132) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.037, 0.0235, 74.6032%, 74.6032%, 0, 2, ModifyGraphWithDelegate/139
AllocateTensors, 0.01, 0.00533333, 25.3968%, 100%, 0, 3, AllocateTensors/139

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.037, 0.0235, 74.6032%, 74.6032%, 0, 2, ModifyGraphWithDelegate/139
AllocateTensors, 0.01, 0.00533333, 25.3968%, 100%, 0, 3, AllocateTensors/139

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.047, 74.6032%, 74.6032%, 0, 2
AllocateTensors, 1, 0.016, 25.3968%, 100%, 0, 3

Subgraph (index: 139, name: odml.scaled_dot_product_attention.impl_132) Timings (microseconds): count=1 curr=63
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 140, name: odml.scaled_dot_product_attention.impl_133) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.024, 75%, 75%, 0, 2, ModifyGraphWithDelegate/140
AllocateTensors, 0.009, 0.00533333, 25%, 100%, 0, 3, AllocateTensors/140

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.036, 0.024, 75%, 75%, 0, 2, ModifyGraphWithDelegate/140
AllocateTensors, 0.009, 0.00533333, 25%, 100%, 0, 3, AllocateTensors/140

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.048, 75%, 75%, 0, 2
AllocateTensors, 1, 0.016, 25%, 100%, 0, 3

Subgraph (index: 140, name: odml.scaled_dot_product_attention.impl_133) Timings (microseconds): count=1 curr=64
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 141, name: odml.scaled_dot_product_attention.impl_134) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.046, 0.028, 76.7123%, 76.7123%, 0, 2, ModifyGraphWithDelegate/141
AllocateTensors, 0.011, 0.00566667, 23.2877%, 100%, 0, 3, AllocateTensors/141

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.046, 0.028, 76.7123%, 76.7123%, 0, 2, ModifyGraphWithDelegate/141
AllocateTensors, 0.011, 0.00566667, 23.2877%, 100%, 0, 3, AllocateTensors/141

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.056, 76.7123%, 76.7123%, 0, 2
AllocateTensors, 1, 0.017, 23.2877%, 100%, 0, 3

Subgraph (index: 141, name: odml.scaled_dot_product_attention.impl_134) Timings (microseconds): count=1 curr=73
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 142, name: odml.scaled_dot_product_attention.impl_135) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.033, 0.0215, 68.254%, 68.254%, 0, 2, ModifyGraphWithDelegate/142
AllocateTensors, 0.014, 0.00666667, 31.746%, 100%, 0, 3, AllocateTensors/142

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.033, 0.0215, 68.254%, 68.254%, 0, 2, ModifyGraphWithDelegate/142
AllocateTensors, 0.014, 0.00666667, 31.746%, 100%, 0, 3, AllocateTensors/142

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.043, 68.254%, 68.254%, 0, 2
AllocateTensors, 1, 0.02, 31.746%, 100%, 0, 3

Subgraph (index: 142, name: odml.scaled_dot_product_attention.impl_135) Timings (microseconds): count=1 curr=63
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 143, name: odml.scaled_dot_product_attention.impl_136) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.03, 76.9231%, 76.9231%, 0, 2, ModifyGraphWithDelegate/143
AllocateTensors, 0.012, 0.006, 23.0769%, 100%, 0, 3, AllocateTensors/143

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.03, 0.03, 76.9231%, 76.9231%, 0, 2, ModifyGraphWithDelegate/143
AllocateTensors, 0.012, 0.006, 23.0769%, 100%, 0, 3, AllocateTensors/143

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.06, 76.9231%, 76.9231%, 0, 2
AllocateTensors, 1, 0.018, 23.0769%, 100%, 0, 3

Subgraph (index: 143, name: odml.scaled_dot_product_attention.impl_136) Timings (microseconds): count=1 curr=78
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 144, name: odml.scaled_dot_product_attention.impl_137) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 68.4211%, 68.4211%, 0, 2, ModifyGraphWithDelegate/144
AllocateTensors, 0.012, 0.006, 31.5789%, 100%, 0, 3, AllocateTensors/144

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 68.4211%, 68.4211%, 0, 2, ModifyGraphWithDelegate/144
AllocateTensors, 0.012, 0.006, 31.5789%, 100%, 0, 3, AllocateTensors/144

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 68.4211%, 68.4211%, 0, 2
AllocateTensors, 1, 0.018, 31.5789%, 100%, 0, 3

Subgraph (index: 144, name: odml.scaled_dot_product_attention.impl_137) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 145, name: odml.scaled_dot_product_attention.impl_138) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.053, 0.0315, 75.9036%, 75.9036%, 0, 2, ModifyGraphWithDelegate/145
AllocateTensors, 0.013, 0.00666667, 24.0964%, 100%, 0, 3, AllocateTensors/145

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.053, 0.0315, 75.9036%, 75.9036%, 0, 2, ModifyGraphWithDelegate/145
AllocateTensors, 0.013, 0.00666667, 24.0964%, 100%, 0, 3, AllocateTensors/145

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.063, 75.9036%, 75.9036%, 0, 2
AllocateTensors, 1, 0.02, 24.0964%, 100%, 0, 3

Subgraph (index: 145, name: odml.scaled_dot_product_attention.impl_138) Timings (microseconds): count=1 curr=83
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 146, name: odml.scaled_dot_product_attention.impl_139) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/146
AllocateTensors, 0.012, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/146

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 67.8571%, 67.8571%, 0, 2, ModifyGraphWithDelegate/146
AllocateTensors, 0.012, 0.006, 32.1429%, 100%, 0, 3, AllocateTensors/146

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 67.8571%, 67.8571%, 0, 2
AllocateTensors, 1, 0.018, 32.1429%, 100%, 0, 3

Subgraph (index: 146, name: odml.scaled_dot_product_attention.impl_139) Timings (microseconds): count=1 curr=56
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 147, name: odml.scaled_dot_product_attention.impl_140) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/147
AllocateTensors, 0.013, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/147

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/147
AllocateTensors, 0.013, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/147

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.019, 33.3333%, 100%, 0, 3

Subgraph (index: 147, name: odml.scaled_dot_product_attention.impl_140) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 148, name: odml.scaled_dot_product_attention.impl_141) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 65%, 65%, 0, 2, ModifyGraphWithDelegate/148
AllocateTensors, 0.015, 0.007, 35%, 100%, 0, 3, AllocateTensors/148

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 65%, 65%, 0, 2, ModifyGraphWithDelegate/148
AllocateTensors, 0.015, 0.007, 35%, 100%, 0, 3, AllocateTensors/148

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 65%, 65%, 0, 2
AllocateTensors, 1, 0.021, 35%, 100%, 0, 3

Subgraph (index: 148, name: odml.scaled_dot_product_attention.impl_141) Timings (microseconds): count=1 curr=60
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 149, name: odml.scaled_dot_product_attention.impl_142) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.039, 0.025, 61.7284%, 61.7284%, 0, 2, ModifyGraphWithDelegate/149
AllocateTensors, 0.024, 0.0103333, 38.2716%, 100%, 0, 3, AllocateTensors/149

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.039, 0.025, 61.7284%, 61.7284%, 0, 2, ModifyGraphWithDelegate/149
AllocateTensors, 0.024, 0.0103333, 38.2716%, 100%, 0, 3, AllocateTensors/149

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.05, 61.7284%, 61.7284%, 0, 2
AllocateTensors, 1, 0.031, 38.2716%, 100%, 0, 3

Subgraph (index: 149, name: odml.scaled_dot_product_attention.impl_142) Timings (microseconds): count=1 curr=81
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 150, name: odml.scaled_dot_product_attention.impl_143) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.033, 0.022, 73.3333%, 73.3333%, 0, 2, ModifyGraphWithDelegate/150
AllocateTensors, 0.01, 0.00533333, 26.6667%, 100%, 0, 3, AllocateTensors/150

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.033, 0.022, 73.3333%, 73.3333%, 0, 2, ModifyGraphWithDelegate/150
AllocateTensors, 0.01, 0.00533333, 26.6667%, 100%, 0, 3, AllocateTensors/150

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.044, 73.3333%, 73.3333%, 0, 2
AllocateTensors, 1, 0.016, 26.6667%, 100%, 0, 3

Subgraph (index: 150, name: odml.scaled_dot_product_attention.impl_143) Timings (microseconds): count=1 curr=60
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 151, name: odml.scaled_dot_product_attention.impl_144) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/151
AllocateTensors, 0.01, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/151

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 70.9091%, 70.9091%, 0, 2, ModifyGraphWithDelegate/151
AllocateTensors, 0.01, 0.00533333, 29.0909%, 100%, 0, 3, AllocateTensors/151

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 70.9091%, 70.9091%, 0, 2
AllocateTensors, 1, 0.016, 29.0909%, 100%, 0, 3

Subgraph (index: 151, name: odml.scaled_dot_product_attention.impl_144) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 152, name: odml.scaled_dot_product_attention.impl_145) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 50.6849%, 50.6849%, 0, 2, ModifyGraphWithDelegate/152
AllocateTensors, 0.03, 0.012, 49.3151%, 100%, 0, 3, AllocateTensors/152

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 50.6849%, 50.6849%, 0, 2, ModifyGraphWithDelegate/152
AllocateTensors, 0.03, 0.012, 49.3151%, 100%, 0, 3, AllocateTensors/152

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 50.6849%, 50.6849%, 0, 2
AllocateTensors, 1, 0.036, 49.3151%, 100%, 0, 3

Subgraph (index: 152, name: odml.scaled_dot_product_attention.impl_145) Timings (microseconds): count=1 curr=73
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 153, name: odml.scaled_dot_product_attention.impl_146) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 68.5185%, 68.5185%, 0, 2, ModifyGraphWithDelegate/153
AllocateTensors, 0.012, 0.00566667, 31.4815%, 100%, 0, 3, AllocateTensors/153

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 68.5185%, 68.5185%, 0, 2, ModifyGraphWithDelegate/153
AllocateTensors, 0.012, 0.00566667, 31.4815%, 100%, 0, 3, AllocateTensors/153

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 68.5185%, 68.5185%, 0, 2
AllocateTensors, 1, 0.017, 31.4815%, 100%, 0, 3

Subgraph (index: 153, name: odml.scaled_dot_product_attention.impl_146) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 154, name: odml.scaled_dot_product_attention.impl_147) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.035, 0.023, 69.697%, 69.697%, 0, 2, ModifyGraphWithDelegate/154
AllocateTensors, 0.014, 0.00666667, 30.303%, 100%, 0, 3, AllocateTensors/154

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.035, 0.023, 69.697%, 69.697%, 0, 2, ModifyGraphWithDelegate/154
AllocateTensors, 0.014, 0.00666667, 30.303%, 100%, 0, 3, AllocateTensors/154

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.046, 69.697%, 69.697%, 0, 2
AllocateTensors, 1, 0.02, 30.303%, 100%, 0, 3

Subgraph (index: 154, name: odml.scaled_dot_product_attention.impl_147) Timings (microseconds): count=1 curr=66
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 155, name: odml.scaled_dot_product_attention.impl_148) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/155
AllocateTensors, 0.012, 0.006, 33.3333%, 100%, 0, 3, AllocateTensors/155

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/155
AllocateTensors, 0.012, 0.006, 33.3333%, 100%, 0, 3, AllocateTensors/155

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.018, 33.3333%, 100%, 0, 3

Subgraph (index: 155, name: odml.scaled_dot_product_attention.impl_148) Timings (microseconds): count=1 curr=54
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 156, name: odml.scaled_dot_product_attention.impl_149) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/156
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/156

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/156
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/156

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 69.8113%, 69.8113%, 0, 2
AllocateTensors, 1, 0.016, 30.1887%, 100%, 0, 3

Subgraph (index: 156, name: odml.scaled_dot_product_attention.impl_149) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 157, name: odml.scaled_dot_product_attention.impl_150) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 63.9344%, 63.9344%, 0, 2, ModifyGraphWithDelegate/157
AllocateTensors, 0.016, 0.00733333, 36.0656%, 100%, 0, 3, AllocateTensors/157

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.0195, 63.9344%, 63.9344%, 0, 2, ModifyGraphWithDelegate/157
AllocateTensors, 0.016, 0.00733333, 36.0656%, 100%, 0, 3, AllocateTensors/157

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.039, 63.9344%, 63.9344%, 0, 2
AllocateTensors, 1, 0.022, 36.0656%, 100%, 0, 3

Subgraph (index: 157, name: odml.scaled_dot_product_attention.impl_150) Timings (microseconds): count=1 curr=61
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 158, name: odml.scaled_dot_product_attention.impl_151) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/158
AllocateTensors, 0.013, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/158

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/158
AllocateTensors, 0.013, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/158

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 67.2727%, 67.2727%, 0, 2
AllocateTensors, 1, 0.018, 32.7273%, 100%, 0, 3

Subgraph (index: 158, name: odml.scaled_dot_product_attention.impl_151) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 159, name: odml.scaled_dot_product_attention.impl_152) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/159
AllocateTensors, 0.014, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/159

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.028, 0.019, 66.6667%, 66.6667%, 0, 2, ModifyGraphWithDelegate/159
AllocateTensors, 0.014, 0.00633333, 33.3333%, 100%, 0, 3, AllocateTensors/159

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 66.6667%, 66.6667%, 0, 2
AllocateTensors, 1, 0.019, 33.3333%, 100%, 0, 3

Subgraph (index: 159, name: odml.scaled_dot_product_attention.impl_152) Timings (microseconds): count=1 curr=57
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 160, name: odml.scaled_dot_product_attention.impl_153) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0175, 70%, 70%, 0, 2, ModifyGraphWithDelegate/160
AllocateTensors, 0.01, 0.005, 30%, 100%, 0, 3, AllocateTensors/160

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.025, 0.0175, 70%, 70%, 0, 2, ModifyGraphWithDelegate/160
AllocateTensors, 0.01, 0.005, 30%, 100%, 0, 3, AllocateTensors/160

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.035, 70%, 70%, 0, 2
AllocateTensors, 1, 0.015, 30%, 100%, 0, 3

Subgraph (index: 160, name: odml.scaled_dot_product_attention.impl_153) Timings (microseconds): count=1 curr=50
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 161, name: odml.scaled_dot_product_attention.impl_154) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/161
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/161

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 71.1538%, 71.1538%, 0, 2, ModifyGraphWithDelegate/161
AllocateTensors, 0.009, 0.005, 28.8462%, 100%, 0, 3, AllocateTensors/161

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 71.1538%, 71.1538%, 0, 2
AllocateTensors, 1, 0.015, 28.8462%, 100%, 0, 3

Subgraph (index: 161, name: odml.scaled_dot_product_attention.impl_154) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 162, name: odml.scaled_dot_product_attention.impl_155) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/162
AllocateTensors, 0.011, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/162

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 69.0909%, 69.0909%, 0, 2, ModifyGraphWithDelegate/162
AllocateTensors, 0.011, 0.00566667, 30.9091%, 100%, 0, 3, AllocateTensors/162

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 69.0909%, 69.0909%, 0, 2
AllocateTensors, 1, 0.017, 30.9091%, 100%, 0, 3

Subgraph (index: 162, name: odml.scaled_dot_product_attention.impl_155) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 163, name: odml.scaled_dot_product_attention.impl_156) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/163
AllocateTensors, 0.012, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/163

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.0185, 67.2727%, 67.2727%, 0, 2, ModifyGraphWithDelegate/163
AllocateTensors, 0.012, 0.006, 32.7273%, 100%, 0, 3, AllocateTensors/163

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 67.2727%, 67.2727%, 0, 2
AllocateTensors, 1, 0.018, 32.7273%, 100%, 0, 3

Subgraph (index: 163, name: odml.scaled_dot_product_attention.impl_156) Timings (microseconds): count=1 curr=55
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 164, name: odml.scaled_dot_product_attention.impl_157) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 69.2308%, 69.2308%, 0, 2, ModifyGraphWithDelegate/164
AllocateTensors, 0.011, 0.00533333, 30.7692%, 100%, 0, 3, AllocateTensors/164

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 69.2308%, 69.2308%, 0, 2, ModifyGraphWithDelegate/164
AllocateTensors, 0.011, 0.00533333, 30.7692%, 100%, 0, 3, AllocateTensors/164

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 69.2308%, 69.2308%, 0, 2
AllocateTensors, 1, 0.016, 30.7692%, 100%, 0, 3

Subgraph (index: 164, name: odml.scaled_dot_product_attention.impl_157) Timings (microseconds): count=1 curr=52
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 165, name: odml.scaled_dot_product_attention.impl_158) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/165
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/165

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 69.8113%, 69.8113%, 0, 2, ModifyGraphWithDelegate/165
AllocateTensors, 0.01, 0.00533333, 30.1887%, 100%, 0, 3, AllocateTensors/165

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 69.8113%, 69.8113%, 0, 2
AllocateTensors, 1, 0.016, 30.1887%, 100%, 0, 3

Subgraph (index: 165, name: odml.scaled_dot_product_attention.impl_158) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 166, name: odml.scaled_dot_product_attention.impl_159) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 71.6981%, 71.6981%, 0, 2, ModifyGraphWithDelegate/166
AllocateTensors, 0.009, 0.005, 28.3019%, 100%, 0, 3, AllocateTensors/166

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.019, 71.6981%, 71.6981%, 0, 2, ModifyGraphWithDelegate/166
AllocateTensors, 0.009, 0.005, 28.3019%, 100%, 0, 3, AllocateTensors/166

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.038, 71.6981%, 71.6981%, 0, 2
AllocateTensors, 1, 0.015, 28.3019%, 100%, 0, 3

Subgraph (index: 166, name: odml.scaled_dot_product_attention.impl_159) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 167, name: odml.scaled_dot_product_attention.impl_160) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/167
AllocateTensors, 0.01, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/167

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.027, 0.0185, 72.549%, 72.549%, 0, 2, ModifyGraphWithDelegate/167
AllocateTensors, 0.01, 0.00466667, 27.451%, 100%, 0, 3, AllocateTensors/167

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.037, 72.549%, 72.549%, 0, 2
AllocateTensors, 1, 0.014, 27.451%, 100%, 0, 3

Subgraph (index: 167, name: odml.scaled_dot_product_attention.impl_160) Timings (microseconds): count=1 curr=51
Memory (bytes): count=0
2 nodes observed

Subgraph (index: 168, name: odml.scaled_dot_product_attention.impl_161) profile:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/168
AllocateTensors, 0.012, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/168

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
ModifyGraphWithDelegate, 0.026, 0.018, 67.9245%, 67.9245%, 0, 2, ModifyGraphWithDelegate/168
AllocateTensors, 0.012, 0.00566667, 32.0755%, 100%, 0, 3, AllocateTensors/168

Number of nodes executed: 2
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
ModifyGraphWithDelegate, 1, 0.036, 67.9245%, 67.9245%, 0, 2
AllocateTensors, 1, 0.017, 32.0755%, 100%, 0, 3

Subgraph (index: 168, name: odml.scaled_dot_product_attention.impl_161) Timings (microseconds): count=1 curr=53
Memory (bytes): count=0
2 nodes observed


Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
FULLY_CONNECTED, 36.628, 37.333, 10.6121%, 10.6121%, 0, 1, [StatefulPartitionedCall:56]:1541
SUM, 0.002, 0.00174, 0.000494605%, 10.6126%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.normalization.RMSNorm_final_norm;1]:1535
FULLY_CONNECTED, 2.46, 2.35982, 0.670792%, 11.2834%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1532
FULLY_CONNECTED, 2.48, 2.29602, 0.652657%, 11.936%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1530
FULLY_CONNECTED, 2.348, 2.37204, 0.674266%, 12.6103%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1527
SUM, 0.002, 0.00172, 0.00048892%, 12.6108%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1521
FULLY_CONNECTED, 0.87, 0.87668, 0.249201%, 12.86%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1518
DYNAMIC_UPDATE_SLICE, 0.337, 0.34576, 0.0982842%, 12.9583%, 0, 1, [StatefulPartitionedCall:48]:1515
DYNAMIC_UPDATE_SLICE, 0.296, 0.30568, 0.0868913%, 13.0452%, 0, 1, [StatefulPartitionedCall:20]:1514
FULLY_CONNECTED, 1.533, 1.45926, 0.414803%, 13.46%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1487
SUM, 0.002, 0.00176, 0.00050029%, 13.4605%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_27/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1481
FULLY_CONNECTED, 2.305, 2.40074, 0.682424%, 14.1429%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1478
FULLY_CONNECTED, 2.224, 2.31112, 0.656949%, 14.7999%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1476
FULLY_CONNECTED, 2.325, 2.34378, 0.666233%, 15.4661%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1473
SUM, 0.002, 0.00174, 0.000494605%, 15.4666%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1467
FULLY_CONNECTED, 0.843, 0.87624, 0.249076%, 15.7157%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1464
DYNAMIC_UPDATE_SLICE, 0.399, 0.36546, 0.103884%, 15.8195%, 0, 1, [StatefulPartitionedCall:47]:1461
DYNAMIC_UPDATE_SLICE, 0.301, 0.308, 0.0875507%, 15.9071%, 0, 1, [StatefulPartitionedCall:19]:1460
FULLY_CONNECTED, 1.526, 1.4511, 0.412483%, 16.3196%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1433
SUM, 0.002, 0.00168, 0.000477549%, 16.3201%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1427
FULLY_CONNECTED, 2.489, 2.36496, 0.672253%, 16.9923%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1424
FULLY_CONNECTED, 2.276, 2.30598, 0.655488%, 17.6478%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1422
FULLY_CONNECTED, 2.347, 2.38432, 0.677756%, 18.3256%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1419
SUM, 0.002, 0.00158, 0.000449124%, 18.326%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1413
FULLY_CONNECTED, 0.822, 0.87626, 0.249082%, 18.5751%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1410
DYNAMIC_UPDATE_SLICE, 0.436, 0.3572, 0.101536%, 18.6766%, 0, 1, [StatefulPartitionedCall:46]:1407
DYNAMIC_UPDATE_SLICE, 0.31, 0.3069, 0.0872381%, 18.7639%, 0, 1, [StatefulPartitionedCall:18]:1406
FULLY_CONNECTED, 1.484, 1.45508, 0.413615%, 19.1775%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1379
SUM, 0.002, 0.0017, 0.000483235%, 19.178%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_25/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1373
FULLY_CONNECTED, 2.597, 2.38474, 0.677876%, 19.8558%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1370
FULLY_CONNECTED, 2.362, 2.32558, 0.661059%, 20.5169%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1368
FULLY_CONNECTED, 2.343, 2.37974, 0.676455%, 21.1933%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1365
SUM, 0.002, 0.00184, 0.00052303%, 21.1939%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1359
FULLY_CONNECTED, 1.016, 0.88692, 0.252112%, 21.446%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1356
DYNAMIC_UPDATE_SLICE, 0.377, 0.35812, 0.101798%, 21.5478%, 0, 1, [StatefulPartitionedCall:45]:1353
DYNAMIC_UPDATE_SLICE, 0.309, 0.3194, 0.0907913%, 21.6386%, 0, 1, [StatefulPartitionedCall:17]:1352
FULLY_CONNECTED, 1.393, 1.44388, 0.410431%, 22.049%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1325
SUM, 0.002, 0.00174, 0.000494605%, 22.0495%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_24/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1319
FULLY_CONNECTED, 2.249, 2.3601, 0.670872%, 22.7204%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1316
FULLY_CONNECTED, 2.348, 2.30574, 0.65542%, 23.3758%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1314
FULLY_CONNECTED, 2.334, 2.37112, 0.674004%, 24.0498%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1311
SUM, 0.001, 0.0017, 0.000483235%, 24.0503%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1305
FULLY_CONNECTED, 0.838, 0.89414, 0.254164%, 24.3044%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1302
DYNAMIC_UPDATE_SLICE, 0.334, 0.3587, 0.101963%, 24.4064%, 0, 1, [StatefulPartitionedCall:44]:1299
DYNAMIC_UPDATE_SLICE, 0.298, 0.30952, 0.0879828%, 24.4944%, 0, 1, [StatefulPartitionedCall:16]:1298
FULLY_CONNECTED, 1.495, 1.46092, 0.415275%, 24.9097%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1271
SUM, 0.001, 0.00176, 0.00050029%, 24.9102%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_23/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1265
FULLY_CONNECTED, 2.414, 2.40216, 0.682828%, 25.593%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1262
FULLY_CONNECTED, 2.376, 2.31608, 0.658359%, 26.2513%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1260
FULLY_CONNECTED, 2.233, 2.3848, 0.677893%, 26.9292%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1257
SUM, 0.002, 0.00204, 0.000579882%, 26.9298%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1251
FULLY_CONNECTED, 0.852, 0.8893, 0.252789%, 27.1826%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1248
DYNAMIC_UPDATE_SLICE, 0.33, 0.36102, 0.102622%, 27.2852%, 0, 1, [StatefulPartitionedCall:43]:1245
DYNAMIC_UPDATE_SLICE, 0.387, 0.31726, 0.0901829%, 27.3754%, 0, 1, [StatefulPartitionedCall:15]:1244
FULLY_CONNECTED, 1.482, 1.4771, 0.419874%, 27.7953%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1217
SUM, 0.001, 0.00164, 0.000466179%, 27.7958%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1211
FULLY_CONNECTED, 2.44, 2.40328, 0.683146%, 28.4789%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1208
FULLY_CONNECTED, 2.348, 2.318, 0.658905%, 29.1378%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1206
FULLY_CONNECTED, 2.254, 2.3784, 0.676074%, 29.8139%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1203
SUM, 0.002, 0.00188, 0.000534401%, 29.8144%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1197
FULLY_CONNECTED, 0.846, 0.88544, 0.251691%, 30.0661%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1194
DYNAMIC_UPDATE_SLICE, 0.335, 0.3673, 0.104407%, 30.1705%, 0, 1, [StatefulPartitionedCall:42]:1191
DYNAMIC_UPDATE_SLICE, 0.325, 0.3074, 0.0873802%, 30.2579%, 0, 1, [StatefulPartitionedCall:14]:1190
FULLY_CONNECTED, 1.504, 1.45524, 0.41366%, 30.6716%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1163
SUM, 0.001, 0.00184, 0.00052303%, 30.6721%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1157
FULLY_CONNECTED, 2.451, 2.37344, 0.674664%, 31.3467%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1154
FULLY_CONNECTED, 2.229, 2.33082, 0.662549%, 32.0093%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1152
FULLY_CONNECTED, 2.36, 2.39382, 0.680457%, 32.6897%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1149
SUM, 0.001, 0.0018, 0.00051166%, 32.6903%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1143
FULLY_CONNECTED, 0.858, 0.89486, 0.254369%, 32.9446%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1140
DYNAMIC_UPDATE_SLICE, 0.384, 0.35974, 0.102258%, 33.0469%, 0, 1, [StatefulPartitionedCall:41]:1137
DYNAMIC_UPDATE_SLICE, 0.305, 0.31632, 0.0899157%, 33.1368%, 0, 1, [StatefulPartitionedCall:13]:1136
FULLY_CONNECTED, 1.435, 1.47206, 0.418441%, 33.5552%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1109
SUM, 0.001, 0.0017, 0.000483235%, 33.5557%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1103
FULLY_CONNECTED, 2.268, 2.36888, 0.673368%, 34.2291%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1100
FULLY_CONNECTED, 2.292, 2.29862, 0.653396%, 34.8825%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1098
FULLY_CONNECTED, 2.206, 2.36132, 0.671219%, 35.5537%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1095
SUM, 0.002, 0.00176, 0.00050029%, 35.5542%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1089
FULLY_CONNECTED, 0.85, 0.87242, 0.24799%, 35.8022%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1086
DYNAMIC_UPDATE_SLICE, 0.331, 0.35336, 0.100445%, 35.9026%, 0, 1, [StatefulPartitionedCall:39]:1083
DYNAMIC_UPDATE_SLICE, 0.335, 0.30126, 0.0856349%, 35.9883%, 0, 1, [StatefulPartitionedCall:11]:1082
FULLY_CONNECTED, 1.496, 1.46072, 0.415218%, 36.4035%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1055
SUM, 0.002, 0.00178, 0.000505975%, 36.404%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_19/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:1049
FULLY_CONNECTED, 2.526, 2.37498, 0.675101%, 37.0791%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1046
FULLY_CONNECTED, 2.368, 2.29194, 0.651497%, 37.7306%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1044
FULLY_CONNECTED, 2.313, 2.35756, 0.67015%, 38.4007%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1041
SUM, 0.002, 0.0019, 0.000540086%, 38.4013%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:1035
FULLY_CONNECTED, 0.856, 0.86874, 0.246944%, 38.6482%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:1032
DYNAMIC_UPDATE_SLICE, 0.418, 0.35674, 0.101405%, 38.7496%, 0, 1, [StatefulPartitionedCall:38]:1029
DYNAMIC_UPDATE_SLICE, 0.295, 0.3035, 0.0862716%, 38.8359%, 0, 1, [StatefulPartitionedCall:10]:1028
FULLY_CONNECTED, 1.427, 1.44886, 0.411847%, 39.2478%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:1001
SUM, 0.002, 0.0016, 0.000454809%, 39.2482%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_18/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:995
FULLY_CONNECTED, 2.267, 2.3749, 0.675079%, 39.9233%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:992
FULLY_CONNECTED, 2.212, 2.28736, 0.650195%, 40.5735%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:990
FULLY_CONNECTED, 2.312, 2.34556, 0.666739%, 41.2402%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:987
SUM, 0.002, 0.00174, 0.000494605%, 41.2407%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:981
FULLY_CONNECTED, 0.835, 0.88942, 0.252823%, 41.4935%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:978
DYNAMIC_UPDATE_SLICE, 0.328, 0.35316, 0.100388%, 41.5939%, 0, 1, [StatefulPartitionedCall:37]:975
DYNAMIC_UPDATE_SLICE, 0.306, 0.31008, 0.088142%, 41.6821%, 0, 1, [StatefulPartitionedCall:9]:974
FULLY_CONNECTED, 1.549, 1.45548, 0.413728%, 42.0958%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:947
SUM, 0.002, 0.00174, 0.000494605%, 42.0963%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_17/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:941
FULLY_CONNECTED, 2.472, 2.36682, 0.672782%, 42.7691%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:938
FULLY_CONNECTED, 2.251, 2.3028, 0.654584%, 43.4237%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:936
FULLY_CONNECTED, 2.376, 2.36576, 0.672481%, 44.0961%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:933
SUM, 0.002, 0.00172, 0.00048892%, 44.0966%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:927
FULLY_CONNECTED, 0.876, 0.88464, 0.251464%, 44.3481%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:924
DYNAMIC_UPDATE_SLICE, 0.33, 0.35684, 0.101434%, 44.4495%, 0, 1, [StatefulPartitionedCall:36]:921
DYNAMIC_UPDATE_SLICE, 0.298, 0.30708, 0.0872892%, 44.5368%, 0, 1, [StatefulPartitionedCall:8]:920
FULLY_CONNECTED, 1.393, 1.44292, 0.410158%, 44.947%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:893
SUM, 0.002, 0.00188, 0.000534401%, 44.9475%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_16/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:887
FULLY_CONNECTED, 2.275, 2.3501, 0.668029%, 45.6155%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:884
FULLY_CONNECTED, 2.347, 2.30834, 0.656159%, 46.2717%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:882
FULLY_CONNECTED, 2.254, 2.3578, 0.670218%, 46.9419%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:879
SUM, 0.003, 0.00186, 0.000528716%, 46.9424%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:873
FULLY_CONNECTED, 0.838, 0.8879, 0.252391%, 47.1948%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:870
DYNAMIC_UPDATE_SLICE, 0.347, 0.35884, 0.102002%, 47.2968%, 0, 1, [StatefulPartitionedCall:35]:867
DYNAMIC_UPDATE_SLICE, 0.303, 0.30884, 0.0877895%, 47.3846%, 0, 1, [StatefulPartitionedCall:7]:866
FULLY_CONNECTED, 1.613, 1.44522, 0.410812%, 47.7954%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:839
SUM, 0.002, 0.00174, 0.000494605%, 47.7959%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_15/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:833
FULLY_CONNECTED, 2.437, 2.36132, 0.671219%, 48.4671%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:830
FULLY_CONNECTED, 2.35, 2.30168, 0.654266%, 49.1214%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:828
FULLY_CONNECTED, 2.249, 2.35176, 0.668501%, 49.7899%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:825
SUM, 0.002, 0.00166, 0.000471864%, 49.7904%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:819
FULLY_CONNECTED, 0.856, 0.88356, 0.251157%, 50.0415%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:816
DYNAMIC_UPDATE_SLICE, 0.333, 0.36634, 0.104134%, 50.1457%, 0, 1, [StatefulPartitionedCall:34]:813
DYNAMIC_UPDATE_SLICE, 0.301, 0.31024, 0.0881875%, 50.2339%, 0, 1, [StatefulPartitionedCall:6]:812
FULLY_CONNECTED, 1.414, 1.43762, 0.408652%, 50.6425%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:785
SUM, 0.002, 0.00164, 0.000466179%, 50.643%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_14/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:779
FULLY_CONNECTED, 2.319, 2.34426, 0.666369%, 51.3093%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:776
FULLY_CONNECTED, 2.205, 2.28848, 0.650513%, 51.9599%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:774
FULLY_CONNECTED, 2.331, 2.34946, 0.667847%, 52.6277%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:771
SUM, 0.002, 0.00168, 0.000477549%, 52.6282%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:765
FULLY_CONNECTED, 0.848, 0.86952, 0.247166%, 52.8754%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:762
DYNAMIC_UPDATE_SLICE, 0.39, 0.3536, 0.100513%, 52.9759%, 0, 1, [StatefulPartitionedCall:33]:759
DYNAMIC_UPDATE_SLICE, 0.317, 0.30764, 0.0874484%, 53.0633%, 0, 1, [StatefulPartitionedCall:5]:758
FULLY_CONNECTED, 1.429, 1.44174, 0.409823%, 53.4731%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:731
SUM, 0.002, 0.00182, 0.000517345%, 53.4737%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_13/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:725
FULLY_CONNECTED, 2.265, 2.36724, 0.672901%, 54.1466%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:722
FULLY_CONNECTED, 2.295, 2.2736, 0.646284%, 54.7928%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:720
FULLY_CONNECTED, 2.356, 2.33994, 0.665141%, 55.458%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:717
SUM, 0.002, 0.00174, 0.000494605%, 55.4585%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:711
FULLY_CONNECTED, 0.856, 0.8736, 0.248326%, 55.7068%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:708
DYNAMIC_UPDATE_SLICE, 0.321, 0.34954, 0.0993587%, 55.8062%, 0, 1, [StatefulPartitionedCall:32]:705
DYNAMIC_UPDATE_SLICE, 0.296, 0.31274, 0.0888981%, 55.8951%, 0, 1, [StatefulPartitionedCall:4]:704
FULLY_CONNECTED, 1.508, 1.46662, 0.416895%, 56.312%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:677
SUM, 0.002, 0.00182, 0.000517345%, 56.3125%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_12/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:671
FULLY_CONNECTED, 2.382, 2.37488, 0.675073%, 56.9875%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:668
FULLY_CONNECTED, 2.385, 2.29118, 0.651281%, 57.6388%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:666
FULLY_CONNECTED, 2.334, 2.36486, 0.672225%, 58.311%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:663
SUM, 0.002, 0.00166, 0.000471864%, 58.3115%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:657
FULLY_CONNECTED, 0.856, 0.88438, 0.25139%, 58.5629%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:654
DYNAMIC_UPDATE_SLICE, 0.407, 0.35302, 0.100348%, 58.6633%, 0, 1, [StatefulPartitionedCall:31]:651
DYNAMIC_UPDATE_SLICE, 0.322, 0.30434, 0.0865104%, 58.7498%, 0, 1, [StatefulPartitionedCall:3]:650
FULLY_CONNECTED, 1.422, 1.44838, 0.41171%, 59.1615%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:623
SUM, 0.002, 0.00176, 0.00050029%, 59.162%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_11/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:617
FULLY_CONNECTED, 2.392, 2.35316, 0.668899%, 59.8309%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:614
FULLY_CONNECTED, 2.314, 2.29336, 0.651901%, 60.4828%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:612
FULLY_CONNECTED, 2.222, 2.3693, 0.673487%, 61.1563%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:609
SUM, 0.002, 0.00164, 0.000466179%, 61.1567%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:603
FULLY_CONNECTED, 0.853, 0.88154, 0.250583%, 61.4073%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:600
DYNAMIC_UPDATE_SLICE, 0.389, 0.34816, 0.0989664%, 61.5063%, 0, 1, [StatefulPartitionedCall:30]:597
DYNAMIC_UPDATE_SLICE, 0.304, 0.30786, 0.0875109%, 61.5938%, 0, 1, [StatefulPartitionedCall:2]:596
FULLY_CONNECTED, 1.403, 1.43764, 0.408657%, 62.0024%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:569
SUM, 0.002, 0.00172, 0.00048892%, 62.0029%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_10/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:563
FULLY_CONNECTED, 2.306, 2.34966, 0.667904%, 62.6708%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:560
FULLY_CONNECTED, 2.369, 2.30426, 0.654999%, 63.3258%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:558
FULLY_CONNECTED, 2.254, 2.35106, 0.668302%, 63.9941%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:555
SUM, 0.001, 0.0017, 0.000483235%, 63.9946%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:549
FULLY_CONNECTED, 0.905, 0.87984, 0.250099%, 64.2447%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:546
DYNAMIC_UPDATE_SLICE, 0.35, 0.35554, 0.101064%, 64.3458%, 0, 1, [StatefulPartitionedCall:55]:543
DYNAMIC_UPDATE_SLICE, 0.306, 0.30948, 0.0879714%, 64.4338%, 0, 1, [StatefulPartitionedCall:27]:542
FULLY_CONNECTED, 1.555, 1.45782, 0.414394%, 64.8482%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:515
SUM, 0.002, 0.00172, 0.00048892%, 64.8486%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_9/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:509
FULLY_CONNECTED, 2.421, 2.38862, 0.678979%, 65.5276%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:506
FULLY_CONNECTED, 2.229, 2.30672, 0.655698%, 66.1833%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:504
FULLY_CONNECTED, 2.372, 2.36904, 0.673413%, 66.8567%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:501
SUM, 0.002, 0.0016, 0.000454809%, 66.8572%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:495
FULLY_CONNECTED, 0.858, 0.87172, 0.247791%, 67.105%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:492
DYNAMIC_UPDATE_SLICE, 0.322, 0.34714, 0.0986765%, 67.2037%, 0, 1, [StatefulPartitionedCall:54]:489
DYNAMIC_UPDATE_SLICE, 0.301, 0.30558, 0.0868628%, 67.2905%, 0, 1, [StatefulPartitionedCall:26]:488
FULLY_CONNECTED, 1.422, 1.45898, 0.414723%, 67.7052%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:461
SUM, 0.002, 0.00168, 0.000477549%, 67.7057%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:455
FULLY_CONNECTED, 2.341, 2.37298, 0.674533%, 68.3803%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:452
FULLY_CONNECTED, 2.309, 2.31758, 0.658785%, 69.039%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:450
FULLY_CONNECTED, 2.272, 2.34812, 0.667466%, 69.7065%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:447
SUM, 0.002, 0.00142, 0.000403643%, 69.7069%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:441
FULLY_CONNECTED, 0.869, 0.87582, 0.248957%, 69.9559%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:438
DYNAMIC_UPDATE_SLICE, 0.335, 0.34548, 0.0982046%, 70.0541%, 0, 1, [StatefulPartitionedCall:53]:435
DYNAMIC_UPDATE_SLICE, 0.3, 0.3082, 0.0876076%, 70.1417%, 0, 1, [StatefulPartitionedCall:25]:434
FULLY_CONNECTED, 1.438, 1.44552, 0.410897%, 70.5526%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:407
SUM, 0.002, 0.0018, 0.00051166%, 70.5531%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_7/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:401
FULLY_CONNECTED, 2.283, 2.35756, 0.67015%, 71.2232%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:398
FULLY_CONNECTED, 2.249, 2.28218, 0.648723%, 71.872%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:396
FULLY_CONNECTED, 2.314, 2.3451, 0.666608%, 72.5386%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:393
SUM, 0.001, 0.00174, 0.000494605%, 72.5391%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:387
FULLY_CONNECTED, 0.844, 0.88234, 0.25081%, 72.7899%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:384
DYNAMIC_UPDATE_SLICE, 0.351, 0.36674, 0.104248%, 72.8941%, 0, 1, [StatefulPartitionedCall:52]:381
DYNAMIC_UPDATE_SLICE, 0.305, 0.31048, 0.0882557%, 72.9824%, 0, 1, [StatefulPartitionedCall:24]:380
FULLY_CONNECTED, 1.465, 1.4505, 0.412313%, 73.3947%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:353
SUM, 0.002, 0.00176, 0.00050029%, 73.3952%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_6/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:347
FULLY_CONNECTED, 2.247, 2.35204, 0.668581%, 74.0638%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:344
FULLY_CONNECTED, 2.31, 2.29388, 0.652048%, 74.7158%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:342
FULLY_CONNECTED, 2.35, 2.35098, 0.668279%, 75.3841%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:339
RESHAPE, 0.002, 0.00066, 0.000187609%, 75.3843%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;]:0
EMBEDDING_LOOKUP, 0.003, 0.00164, 0.000466179%, 75.3848%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/torch.nn.modules.sparse.Embedding_tok_embedding;1]:1
CAST, 0.001, 0.00062, 0.000176239%, 75.3849%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;]:3
LESS, 0.002, 0.00074, 0.000210349%, 75.3851%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;5]:8
ADD, 0.001, 0.00106, 0.000301311%, 75.3854%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;6]:9
SELECT, 0.001, 0.00046, 0.000130758%, 75.3856%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;7]:10
RESHAPE, 0, 0.00016, 4.54809e-05%, 75.3856%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;8]:11
CAST, 0.001, 0.00022, 6.25362e-05%, 75.3857%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;9]:12
GREATER_EQUAL, 0, 0.00034, 9.66469e-05%, 75.3858%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;10]:13
LESS_EQUAL, 0.001, 0.00042, 0.000119387%, 75.3859%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;11]:14
LOGICAL_AND, 0, 0.00044, 0.000125072%, 75.386%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;12]:15
REDUCE_ALL, 0.004, 0.001, 0.000284256%, 75.3863%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;13]:16
GATHER_ND, 0.002, 0.00142, 0.000403643%, 75.3867%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;14]:17
RESHAPE, 0, 0.0002, 5.68511e-05%, 75.3868%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;15]:18
SELECT_V2, 0.001, 0.00114, 0.000324051%, 75.3871%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;16]:19
RESHAPE, 0.005, 0.00036, 0.000102332%, 75.3872%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;25]:54
PACK, 0.001, 0.00092, 0.000261515%, 75.3875%, 0, 1, [tfl.pack]:55
Copy (NC, X32), 0.001, 0.000114483, 0.000943729%, 75.3884%, 0, 29, Delegate/Copy (NC	 X32):0
Copy (NC, X32), 0, 0, 0%, 75.3884%, 0, 1, Delegate/Copy (NC	 X32):1
Multiply (ND, F32), 0, 0.00124069, 0.0102275%, 75.3986%, 0, 29, Delegate/Multiply (ND	 F32):2
Multiply (ND, F32), 0, 1.37931e-06, 2.27405e-05%, 75.3986%, 0, 58, Delegate/Multiply (ND	 F32):3
COS, 0.001, 0.0013, 0.000369532%, 75.399%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;3]:6
SIN, 0, 0.00066, 0.000187609%, 75.3992%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module;4]:7
SUM, 0.002, 0.00192, 0.000545771%, 75.3997%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;]:21
Multiply (ND, F32), 0, 0.000308941, 0.00746455%, 75.4072%, 0, 85, Delegate/Multiply (ND	 F32):0
Add (ND, F32), 0, 7.01754e-06, 0.000113702%, 75.4073%, 0, 57, Delegate/Add (ND	 F32):1
Reciprocal Square Root (NC, F32), 0, 5.26316e-06, 8.52767e-05%, 75.4074%, 0, 57, Delegate/Reciprocal Square Root (NC	 F32):2
Multiply (ND, F32), 0.001, 0.000619649, 0.0100399%, 75.4174%, 0, 57, Delegate/Multiply (ND	 F32):4
FULLY_CONNECTED, 1.402, 1.46174, 0.415508%, 75.833%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:27
Slice (ND, X32), 0.001, 1.42857e-06, 1.13702e-05%, 75.833%, 0, 28, Delegate/Slice (ND	 X32):1
Slice (ND, X32), 0, 0, 0%, 75.833%, 0, 28, Delegate/Slice (ND	 X32):2
Slice (ND, X32), 0, 2.14286e-06, 1.70553e-05%, 75.833%, 0, 28, Delegate/Slice (ND	 X32):3
Copy (NC, X32), 0, 1.46429e-05, 0.00023309%, 75.8332%, 0, 56, Delegate/Copy (NC	 X32):4
Slice (ND, X32), 0, 0, 0%, 75.8332%, 0, 28, Delegate/Slice (ND	 X32):5
Slice (ND, X32), 0, 7.14286e-07, 5.68511e-06%, 75.8332%, 0, 28, Delegate/Slice (ND	 X32):6
Multiply (ND, F32), 0, 0, 0%, 75.8332%, 0, 28, Delegate/Multiply (ND	 F32):7
Multiply (ND, F32), 0, 2.85714e-06, 2.27405e-05%, 75.8333%, 0, 28, Delegate/Multiply (ND	 F32):8
Subtract (ND, F32), 0, 4.28571e-06, 3.41107e-05%, 75.8333%, 0, 28, Delegate/Subtract (ND	 F32):9
Multiply (ND, F32), 0, 0, 0%, 75.8333%, 0, 28, Delegate/Multiply (ND	 F32):10
Multiply (ND, F32), 0, 0, 0%, 75.8333%, 0, 28, Delegate/Multiply (ND	 F32):11
Add (ND, F32), 0, 2.85714e-06, 2.27405e-05%, 75.8333%, 0, 28, Delegate/Add (ND	 F32):12
Copy (NC, X32), 0, 1.64286e-05, 0.000261515%, 75.8336%, 0, 56, Delegate/Copy (NC	 X32):13
Copy (NC, X32), 0, 1.14286e-05, 9.09618e-05%, 75.8337%, 0, 28, Delegate/Copy (NC	 X32):14
Copy (NC, X32), 0, 2.5e-06, 3.97958e-05%, 75.8337%, 0, 56, Delegate/Copy (NC	 X32):15
Slice (ND, X32), 0, 2.14286e-06, 1.70553e-05%, 75.8337%, 0, 28, Delegate/Slice (ND	 X32):16
Slice (ND, X32), 0, 3.57143e-06, 2.84256e-05%, 75.8337%, 0, 28, Delegate/Slice (ND	 X32):17
Multiply (ND, F32), 0, 0, 0%, 75.8337%, 0, 28, Delegate/Multiply (ND	 F32):18
Multiply (ND, F32), 0, 1.92857e-05, 0.000153498%, 75.8339%, 0, 28, Delegate/Multiply (ND	 F32):19
Subtract (ND, F32), 0, 0, 0%, 75.8339%, 0, 28, Delegate/Subtract (ND	 F32):20
Multiply (ND, F32), 0, 1.42857e-06, 1.13702e-05%, 75.8339%, 0, 28, Delegate/Multiply (ND	 F32):21
Multiply (ND, F32), 0, 0, 0%, 75.8339%, 0, 28, Delegate/Multiply (ND	 F32):22
Add (ND, F32), 0, 0, 0%, 75.8339%, 0, 28, Delegate/Add (ND	 F32):23
Copy (NC, X32), 0, 0, 0%, 75.8339%, 0, 28, Delegate/Copy (NC	 X32):24
Copy (NC, X32), 0, 2.85714e-06, 2.27405e-05%, 75.8339%, 0, 28, Delegate/Copy (NC	 X32):25
DYNAMIC_UPDATE_SLICE, 0.293, 0.30844, 0.0876758%, 75.9216%, 0, 1, [StatefulPartitionedCall:0]:56
DYNAMIC_UPDATE_SLICE, 0.357, 0.35338, 0.10045%, 76.0221%, 0, 1, [StatefulPartitionedCall:28]:57
Transpose (ND, X32) Transpose, 0, 4.35714e-05, 0.000346792%, 76.0224%, 0, 28, Delegate/Transpose (ND	 X32) Transpose:1
Transpose (ND, X32) Transpose, 0.24, 0.215209, 1.71288%, 77.7353%, 0, 28, Delegate/Transpose (ND	 X32) Transpose:2
Copy (NC, X32), 0, 9.28571e-06, 7.39065e-05%, 77.7354%, 0, 28, Delegate/Copy (NC	 X32):3
Batch Matrix Multiply (NC, F32) GEMM, 0.328, 0.323867, 2.57771%, 80.3131%, 0, 28, Delegate/Batch Matrix Multiply (NC	 F32) GEMM:5
Copy (NC, X32), 0, 0.000158571, 0.0012621%, 80.3143%, 0, 28, Delegate/Copy (NC	 X32):6
Add (ND, F32), 0.001, 0.00135214, 0.0107619%, 80.3251%, 0, 28, Delegate/Add (ND	 F32):7
Softmax (NC, F32), 0.012, 0.0136407, 0.108569%, 80.4337%, 0, 28, Delegate/Softmax (NC	 F32):8
Transpose (ND, X32) Transpose, 0.285, 0.289081, 2.30084%, 82.7345%, 0, 28, Delegate/Transpose (ND	 X32) Transpose:9
Copy (NC, X32), 0, 4.5e-05, 0.000358162%, 82.7349%, 0, 28, Delegate/Copy (NC	 X32):10
Copy (NC, X32), 0, 2.57143e-05, 0.000204664%, 82.7351%, 0, 28, Delegate/Copy (NC	 X32):11
Batch Matrix Multiply (NC, F32) GEMM, 0.312, 0.323652, 2.576%, 85.3111%, 0, 28, Delegate/Batch Matrix Multiply (NC	 F32) GEMM:12
Transpose (ND, X32) Transpose, 0, 2.14286e-06, 1.70553e-05%, 85.3111%, 0, 28, Delegate/Transpose (ND	 X32) Transpose:14
FULLY_CONNECTED, 0.798, 0.86916, 0.247064%, 85.5581%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:60
Add (ND, F32), 0.001, 0.000953929, 0.0151849%, 85.5733%, 0, 56, Delegate/Add (ND	 F32):0
Multiply (ND, F32), 0, 3.97619e-05, 0.000949414%, 85.5743%, 0, 84, Delegate/Multiply (ND	 F32):1
SUM, 0.002, 0.00198, 0.000562826%, 85.5748%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:63
FULLY_CONNECTED, 2.313, 2.2179, 0.630451%, 86.2053%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:69
FULLY_CONNECTED, 2.144, 2.40236, 0.682884%, 86.8882%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:72
Sigmoid (NC, F32), 0.003, 0.00312286, 0.0248553%, 86.913%, 0, 28, Delegate/Sigmoid (NC	 F32):0
FULLY_CONNECTED, 2.69, 2.51822, 0.715818%, 87.6289%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:74
SUM, 0.002, 0.00188, 0.000534401%, 87.6294%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:77
FULLY_CONNECTED, 1.614, 1.57888, 0.448806%, 88.0782%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:83
DYNAMIC_UPDATE_SLICE, 0.328, 0.35356, 0.100501%, 88.1787%, 0, 1, [StatefulPartitionedCall:1]:110
DYNAMIC_UPDATE_SLICE, 0.344, 0.40082, 0.113935%, 88.2926%, 0, 1, [StatefulPartitionedCall:29]:111
FULLY_CONNECTED, 0.858, 0.91526, 0.260168%, 88.5528%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:114
SUM, 0.002, 0.00182, 0.000517345%, 88.5533%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:117
FULLY_CONNECTED, 2.39, 2.36794, 0.6731%, 89.2264%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:123
FULLY_CONNECTED, 2.315, 2.35804, 0.670286%, 89.8967%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:126
FULLY_CONNECTED, 2.447, 2.41118, 0.685392%, 90.5821%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:128
SUM, 0.002, 0.0017, 0.000483235%, 90.5826%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:131
FULLY_CONNECTED, 1.395, 1.48308, 0.421574%, 91.0042%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:137
DYNAMIC_UPDATE_SLICE, 0.295, 0.31156, 0.0885627%, 91.0927%, 0, 1, [StatefulPartitionedCall:12]:164
DYNAMIC_UPDATE_SLICE, 0.326, 0.35416, 0.100672%, 91.1934%, 0, 1, [StatefulPartitionedCall:40]:165
FULLY_CONNECTED, 0.866, 0.8962, 0.25475%, 91.4481%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:168
SUM, 0.002, 0.0018, 0.00051166%, 91.4486%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:171
FULLY_CONNECTED, 2.3, 2.34086, 0.665403%, 92.114%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:177
FULLY_CONNECTED, 2.218, 2.32404, 0.660621%, 92.7747%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:180
SUM, 0.002, 0.00172, 0.00048892%, 92.7752%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:333
FULLY_CONNECTED, 0.873, 0.8795, 0.250003%, 93.0252%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:330
DYNAMIC_UPDATE_SLICE, 0.386, 0.35126, 0.0998476%, 93.125%, 0, 1, [StatefulPartitionedCall:51]:327
DYNAMIC_UPDATE_SLICE, 0.329, 0.30434, 0.0865104%, 93.2115%, 0, 1, [StatefulPartitionedCall:23]:326
FULLY_CONNECTED, 1.556, 1.44618, 0.411085%, 93.6226%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:299
SUM, 0.002, 0.00166, 0.000471864%, 93.6231%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_5/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:293
FULLY_CONNECTED, 2.346, 2.37186, 0.674215%, 94.2973%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:290
FULLY_CONNECTED, 2.418, 2.31674, 0.658546%, 94.9558%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:288
FULLY_CONNECTED, 2.32, 2.38348, 0.677518%, 95.6334%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:285
SUM, 0.003, 0.00184, 0.00052303%, 95.6339%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:279
FULLY_CONNECTED, 0.857, 0.87498, 0.248718%, 95.8826%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:276
FULLY_CONNECTED, 2.294, 2.38526, 0.678024%, 96.5606%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:182
SUM, 0.002, 0.00172, 0.00048892%, 96.5611%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:185
FULLY_CONNECTED, 1.593, 1.45818, 0.414496%, 96.9756%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:191
DYNAMIC_UPDATE_SLICE, 0.299, 0.30452, 0.0865615%, 97.0622%, 0, 1, [StatefulPartitionedCall:21]:218
DYNAMIC_UPDATE_SLICE, 0.341, 0.36144, 0.102741%, 97.1649%, 0, 1, [StatefulPartitionedCall:49]:219
FULLY_CONNECTED, 0.842, 0.8689, 0.24699%, 97.4119%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_output_projection;1]:222
SUM, 0.002, 0.00166, 0.000471864%, 97.4124%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.normalization.RMSNorm_post_atten_norm;1]:225
FULLY_CONNECTED, 2.33, 2.34386, 0.666255%, 98.0786%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:231
FULLY_CONNECTED, 2.524, 2.30556, 0.655368%, 98.734%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:234
FULLY_CONNECTED, 2.238, 2.35476, 0.669354%, 99.4033%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_3/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:236
SUM, 0.001, 0.0019, 0.000540086%, 99.4039%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.normalization.RMSNorm_pre_atten_norm;1]:239
FULLY_CONNECTED, 1.414, 1.44554, 0.410903%, 99.8148%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_4/ai_edge_torch.generative.layers.attention.CausalSelfAttention_atten_func/torch.nn.modules.linear.Linear_qkv_projection;]:245
DYNAMIC_UPDATE_SLICE, 0.326, 0.34264, 0.0973974%, 99.9122%, 0, 1, [StatefulPartitionedCall:50]:273
DYNAMIC_UPDATE_SLICE, 0.31, 0.30892, 0.0878123%, 100%, 0, 1, [StatefulPartitionedCall:22]:272

============================== Top by Computation Time ==============================
node type, first, avg_ms, %, cdf%, mem KB, times called, name
FULLY_CONNECTED, 36.628, 37.333, 10.6121%, 10.6121%, 0, 1, [StatefulPartitionedCall:56]:1541
FULLY_CONNECTED, 2.69, 2.51822, 0.715818%, 11.3279%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:74
FULLY_CONNECTED, 2.447, 2.41118, 0.685392%, 12.0133%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_1/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:128
FULLY_CONNECTED, 2.44, 2.40328, 0.683146%, 12.6965%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_21/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1208
FULLY_CONNECTED, 2.144, 2.40236, 0.682884%, 13.3793%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w3;;ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_0/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:72
FULLY_CONNECTED, 2.414, 2.40216, 0.682828%, 14.0622%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_22/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1262
FULLY_CONNECTED, 2.305, 2.40074, 0.682424%, 14.7446%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_26/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:1478
FULLY_CONNECTED, 2.36, 2.39382, 0.680457%, 15.4251%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_20/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w1;]:1149
FULLY_CONNECTED, 2.421, 2.38862, 0.678979%, 16.104%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_8/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:506
FULLY_CONNECTED, 2.294, 2.38526, 0.678024%, 16.7821%, 0, 1, [ai_edge_torch.generative.utilities.converter.ExportableModule/ai_edge_torch.generative.examples.llama.llama.Llama_module/ai_edge_torch.generative.layers.attention.TransformerBlock_2/ai_edge_torch.generative.layers.feed_forward.GatedFeedForward_ff/torch.nn.modules.linear.Linear_w2;]:182

Number of nodes executed: 321
============================== Summary by node type ==============================
node type, count, avg_ms, avg %, cdf %, mem KB, times called
FULLY_CONNECTED, 141, 299.99, 85.3131%, 85.3131%, 0, 141
DYNAMIC_UPDATE_SLICE, 56, 18.665, 5.30808%, 90.6212%, 0, 56
Batch Matrix Multiply (NC, F32) GEMM, 2, 18.13, 5.15593%, 95.7771%, 0, 56
Transpose (ND, X32) Transpose, 4, 14.12, 4.01554%, 99.7927%, 0, 112
Softmax (NC, F32), 1, 0.381, 0.108351%, 99.901%, 0, 28
Multiply (ND, F32), 13, 0.099, 0.0281543%, 99.9292%, 0, 537
Add (ND, F32), 5, 0.09, 0.0255948%, 99.9548%, 0, 197
Sigmoid (NC, F32), 1, 0.087, 0.0247416%, 99.9795%, 0, 28
SUM, 57, 0.058, 0.0164944%, 99.996%, 0, 57
Copy (NC, X32), 12, 0.008, 0.00227509%, 99.9983%, 0, 394
SELECT_V2, 1, 0.001, 0.000284387%, 99.9986%, 0, 1
REDUCE_ALL, 1, 0.001, 0.000284387%, 99.9989%, 0, 1
GATHER_ND, 1, 0.001, 0.000284387%, 99.9991%, 0, 1
EMBEDDING_LOOKUP, 1, 0.001, 0.000284387%, 99.9994%, 0, 1
COS, 1, 0.001, 0.000284387%, 99.9997%, 0, 1
ADD, 1, 0.001, 0.000284387%, 100%, 0, 1
Subtract (ND, F32), 2, 0, 0%, 100%, 0, 56
Slice (ND, X32), 7, 0, 0%, 100%, 0, 196
SIN, 1, 0, 0%, 100%, 0, 1
SELECT, 1, 0, 0%, 100%, 0, 1
Reciprocal Square Root (NC, F32), 1, 0, 0%, 100%, 0, 57
RESHAPE, 4, 0, 0%, 100%, 0, 4
PACK, 1, 0, 0%, 100%, 0, 1
LOGICAL_AND, 1, 0, 0%, 100%, 0, 1
LESS_EQUAL, 1, 0, 0%, 100%, 0, 1
LESS, 1, 0, 0%, 100%, 0, 1
GREATER_EQUAL, 1, 0, 0%, 100%, 0, 1
CAST, 2, 0, 0%, 100%, 0, 2

Timings (microseconds): count=50 first=349984 curr=353875 min=347989 max=363172 avg=351796 std=3018
Memory (bytes): count=0
321 nodes observed


